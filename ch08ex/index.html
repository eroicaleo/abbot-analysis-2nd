<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Chapter 08 Exercises - Understanding Analysis by Stephen Abbot (2nd Ed)</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Chapter 08 Exercises";
        var mkdocs_page_input_path = "ch08ex.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Understanding Analysis by Stephen Abbot (2nd Ed)
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch02ex/">Chapter 02 Exercises</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch03notes/">Chapter 03 Notes</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch03ex/">Chapter 03 Exercises</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch04notes/">Chapter 04 Notes</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch04ex/">Chapter 04 Exercises</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch05notes/">Chapter 05 Notes</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch05ex/">Chapter 05 Exercises</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch06notes/">Chapter 06 Notes</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch06ex/">Chapter 06 Exercises</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch07notes/">Chapter 07 Notes</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch07ex/">Chapter 07 Exercises</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">Chapter 08 Exercises</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#81-the-generalized-riemann-integral">8.1 The Generalized Riemann Integral</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-811">Exercise 8.1.1</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#812">8.1.2.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#813">8.1.3.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#814">8.1.4.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#815">8.1.5.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#definition-813">Definition 8.1.3.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#definition-814">Definition 8.1.4.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#816">8.1.6.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#theorem-815">Theorem 8.1.5.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-817">Exercise 8.1.7.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#definition-816">Definition 8.1.6.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#theorem-817">Theorem 8.1.7.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-818">Exercise 8.1.8.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-819">Exercise 8.1.9</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#theorem-818">Theorem 8.1.8.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-8110">Exercise 8.1.10.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#theorem-819">Theorem 8.1.9.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-8111">Exercise 8.1.11.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-8112">Exercise 8.1.12.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-8113">Exercise 8.1.13.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#theorem-8110-change-of-variable-formula">Theorem 8.1.10 (Change-of-variable Formula).</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-8114">Exercise 8.1.14.</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#83-eulers-sum">8.3 Euler’s Sum</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#walliss-product">Wallis’s Product</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-831">Exercise 8.3.1.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-832">Exercise 8.3.2.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-833">Exercise 8.3.3.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-834">Exercise 8.3.4.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-835">Exercise 8.3.5.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#taylor-series">Taylor Series</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-836">Exercise 8.3.6.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-837">Exercise 8.3.7.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-838">Exercise 8.3.8.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#theorem-831-integral-remainder-theorem">Theorem 8.3.1 (Integral Remainder Theorem).</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-839">Exercise 8.3.9.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-8310">Exercise 8.3.10.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-8311">Exercise 8.3.11.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-8312">Exercise 8.3.12.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#summing-sum_n-1infty-1n2">Summing \sum_{n = 1}^{\infty} 1/n^2</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-8313">Exercise 8.3.13.</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#84-inventing-the-factorial-function">8.4 Inventing the Factorial Function</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-842">Exercise 8.4.2.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-843">Exercise 8.4.3.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-844">Exercise 8.4.4.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#definition-841">Definition 8.4.1.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-845">Exercise 8.4.5.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-846">Exercise 8.4.6.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#definition-842">Definition 8.4.2.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-847">Exercise 8.4.7.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-848">Exercise 8.4.8.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#improper-riemann-integrals">Improper Riemann Integrals</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#definition-843">Definition 8.4.3.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-849">Exercise 8.4.9.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-8410">Exercise 8.4.10.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#exercise-8411">Exercise 8.4.11.</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch0802ex/">Chapter 0802 Exercises</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch0806ex/">Chapter 0806 Exercises</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../misc/">Misc info</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../unsolved/">Unsolved Problems</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Understanding Analysis by Stephen Abbot (2nd Ed)</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a> &raquo;</li>
      <li class="breadcrumb-item active">Chapter 08 Exercises</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/eroicaleo/abbot-analysis-2nd/blob/main/docs/ch08ex.md" class="icon icon-github"> Edit on Github</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="chapter-08-additional-topics">Chapter 08 Additional Topics</h1>
<h2 id="81-the-generalized-riemann-integral">8.1 The Generalized Riemann Integral</h2>
<h3 id="exercise-811">Exercise 8.1.1</h3>
<p>Let <script type="math/tex">(P,{c_k})</script> be an arbitrary tagged partition of <script type="math/tex">[a,b]</script> that
is <script type="math/tex">δ</script>-fine, and let <script type="math/tex">P' = P ∪ P_ϵ</script>.</p>
<p>(a) Explain why both the Riemann sum <script type="math/tex">R(f,P)</script> and <script type="math/tex">\int_{a}^{b}f</script>
fall between <script type="math/tex">L(f,P)</script> and <script type="math/tex">U(f,P)</script>.</p>
<p><strong>Proof</strong>: Since <script type="math/tex">\int_{a}^{b}f</script> is an upper bound of <script type="math/tex">L(f,P)</script>
and a lower bound of <script type="math/tex">U(f,P)</script>, so <script type="math/tex">\int_{a}^{b}f</script>
fall between <script type="math/tex">L(f,P)</script> and <script type="math/tex">U(f,P)</script>.</p>
<p>Since <script type="math/tex">m_k \leq c_k \leq M_k</script>, <script type="math/tex">R(f,P)</script> also
fall between <script type="math/tex">L(f,P)</script> and <script type="math/tex">U(f,P)</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Explain why <script type="math/tex">U(f,P')−L(f,P') < ϵ/3</script>.</p>
<p><strong>Proof</strong>:</p>
<p>Since <script type="math/tex">P' = P ∪ P_ϵ</script>, we have</p>
<p>
<script type="math/tex; mode=display"> 
L(f, P_ϵ) \leq L(f, P') \leq U(f, P') \leq  U(f, P_ϵ)
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="812">8.1.2.</h3>
<p>Explain why <script type="math/tex">U(f,P)−U(f,P') ≥ 0</script>.</p>
<p><strong>Proof</strong>: See previous exercise.</p>
<h3 id="813">8.1.3.</h3>
<p>(a) In terms of <script type="math/tex">n</script>, what is the largest number of terms of the
form <script type="math/tex">M_k(x_k - x_{k-1})</script> that could appear in one of <script type="math/tex">U(f,P)</script> or <script type="math/tex">U(f,P')</script> but not the other?</p>
<p>Solution: Note that <script type="math/tex">P \subseteq P' = P \cup P_{\epsilon }</script>, and
since <script type="math/tex">P_{\epsilon}</script> has <script type="math/tex">n</script> segments, so <script type="math/tex">P'</script> has at most <script type="math/tex">n</script> points more than <script type="math/tex">P</script>.</p>
<p>If these <script type="math/tex">n</script> points fall into <script type="math/tex">n</script> different
segments of <script type="math/tex">P</script>, then we can achive the
largest number of terms of the
form <script type="math/tex">M_k(x_k - x_{k-1})</script> that appears in one of <script type="math/tex">U(f,P)</script> or <script type="math/tex">U(f,P')</script> but not the other, which is <script type="math/tex">3n</script>.</p>
<p>(b) Finish the proof in this direction by arguing that</p>
<p>
<script type="math/tex; mode=display"> 
U(f, P) - U(f, P') < \epsilon / 3.
</script>
</p>
<p>Proof: Now we can bound</p>
<p>
<script type="math/tex; mode=display"> 
U(f, P) - U(f, P') < 3n \cdot M \cdot \frac{\epsilon}{9nM}
= \epsilon / 3
</script>
</p>
<p>Combine the previous exercises, we have</p>
<p>
<script type="math/tex; mode=display"> 
R(f, P), \int_{a}^{b}f \leq U(f, P) < U(f, P') + \epsilon / 3 \\
R(f, P), \int_{a}^{b}f \geq L(f, P) > L(f, P') - \epsilon / 3
</script>
</p>
<p>So <script type="math/tex">\left| R(f, P) - \int_{a}^{b} f \right| < \epsilon</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="814">8.1.4.</h3>
<p>(a) Show that if <script type="math/tex">f</script> is continuous, then it is possible to pick tags
<script type="math/tex">\{c_k\}^n_{k=1}</script>
so that <script type="math/tex">R(f,P) = U(f,P)</script>.</p>
<p><strong>Proof</strong>: Since <script type="math/tex">f</script> is continuous, for each segment
<script type="math/tex">[x_{k-1}, x_k]</script>, because of extreme value theorem, it is possible to find <script type="math/tex">c_k</script> such that
<script type="math/tex">f(x_k) = M_k</script>.
Pick those <script type="math/tex">c_k</script>, we have <script type="math/tex">R(f,P) = U(f,P)</script>.</p>
<p>(b) If <script type="math/tex">f</script> is not continuous, it may not be possible to find tags for which <script type="math/tex">R(f,P) = U(f,P)</script>.
Show, however, that given an arbitrary <script type="math/tex">ϵ > 0</script>, it
is possible to pick tags for <script type="math/tex">P</script> so that</p>
<p>
<script type="math/tex; mode=display"> 
U(f,P) - R(f,P) < \epsilon.
</script>
</p>
<p>The analogous statement holds for lower sums.</p>
<p><strong>Proof</strong>: For each segment <script type="math/tex">[x_{k-1}, x_k]</script>, <script type="math/tex">M_k</script> is the
supremum of <script type="math/tex">f(x)</script> for <script type="math/tex">x \in [x_{k-1}, x_k]</script>. So we can find
<script type="math/tex">c_k</script> such that <script type="math/tex">M_k - c_k < \epsilon / (b-a)</script>.</p>
<p>Pick those <script type="math/tex">c_k</script>, we have <script type="math/tex">U(f,P) - R(f,P) < \epsilon</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="815">8.1.5.</h3>
<p>Use the results of the previous exercise to finish the proof of Theorem 8.1.2.</p>
<p><strong>Proof</strong>: Given <script type="math/tex">\epsilon</script>, we can find partition <script type="math/tex">\delta</script>,
such that any <script type="math/tex">\delta</script>-fine tagged partition <script type="math/tex">|R(f, P) - A| < \epsilon /4</script>.
 <script type="math/tex">P</script>, such
that <script type="math/tex">U(f,P) - R_1(f,P) < \epsilon / 4</script>. Similarly,
<script type="math/tex">R_2(f,P) - L(f,P) < \epsilon / 4</script>.</p>
<p>Let <script type="math/tex">P_{\epsilon} = P_1 \cup P_2</script>, so</p>
<p>
<script type="math/tex; mode=display"> 
U(f, P) - L (f, P)
= U(f, P) - R_1(f,P) + R_1(f,P) - A + A - R_2(f,P) + R_2(f,P) - L (f, P) \\
< \epsilon / 4 + \epsilon / 4 + \epsilon / 4 + \epsilon / 4
< \epsilon
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p><strong>Gauges and δ(x)-fine Partitions</strong></p>
<h3 id="definition-813">Definition 8.1.3.</h3>
<p>A function <script type="math/tex">δ : [a,b] → \mathbf{R}</script> is called a gauge on <script type="math/tex">[a,b]</script> if <script type="math/tex">δ(x) > 0</script> for all <script type="math/tex">x ∈ [a,b]</script>.</p>
<h3 id="definition-814">Definition 8.1.4.</h3>
<p>Given a particular gauge <script type="math/tex">δ(x)</script>, a tagged partition
<script type="math/tex">(P, {c_k}_{k=1}^n)</script> is <script type="math/tex">\delta(x)</script>-fine if every subinterval
<script type="math/tex">[x_{k−1},x_k]</script> satisfies <script type="math/tex">x_k - x_{k−1} < \delta(c_k)</script>.</p>
<p>In other words, each subinterval <script type="math/tex">[x_{k−1},x_k]</script> has width less 
than <script type="math/tex">\delta(c_k)</script>.</p>
<h3 id="816">8.1.6.</h3>
<p>Consider the interval [0,1].</p>
<p>(a) If <script type="math/tex">\delta(x) = 1/9</script>, find a <script type="math/tex">\delta(x)</script>-fine tagged partition of <script type="math/tex">[0,1]</script>. Does the choice of tags matter in this case?</p>
<p><strong>Solution</strong>:</p>
<p>Let <script type="math/tex">P = \{0, 0.1, 0.2, \cdots, 0.9, 1.0\}</script>.
The choice of tags does not matter.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Let</p>
<p>
<script type="math/tex; mode=display"> 
\delta (x) = \begin{cases}
    1/4 &\text{if } x = 0\\
    x/3 &\text{if } 0 < x \leq 1\\
\end{cases} 
</script>
</p>
<p>Construct a <script type="math/tex">δ(x)</script>-fine tagged partition of <script type="math/tex">[0,1]</script>.</p>
<p><strong>Solution</strong>:</p>
<p>Let <script type="math/tex">x_0 = 0, x_1 = 1, c_1 = 0</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="theorem-815">Theorem 8.1.5.</h3>
<p>Given a gauge <script type="math/tex">δ(x)</script> on an interval <script type="math/tex">[a,b]</script>, there exists a tagged
partition <script type="math/tex">(P,\{c_k\}^n_{k=1})</script> that is <script type="math/tex">δ(x)</script>-fine.</p>
<p><strong>Proof</strong>. Let <script type="math/tex">I_0 = [a,b]</script>. It may be possible to find a tag such that the trivial partition
<script type="math/tex">P= \{a,b\}</script> works.</p>
<p>Specifically, if <script type="math/tex">b−a < δ(x)</script> for some <script type="math/tex">x ∈ [a,b]</script>, then
we can set <script type="math/tex">c_1</script> equal to such an <script type="math/tex">x</script> and notice that
<script type="math/tex">(P,{c_1})</script> is <script type="math/tex">δ(x)</script>-fine. If no
such <script type="math/tex">x</script> exists, then bisect <script type="math/tex">[a,b]</script> into two equal halves.</p>
<h3 id="exercise-817">Exercise 8.1.7.</h3>
<p>Finish the proof of Theorem 8.1.5.</p>
<p><strong>Proof</strong>: Assume otherwise, then this process continuous
indefinitely, then we get a nested intervals.
Because of NIP, we can find <script type="math/tex">c</script> in all these intervals.
That means <script type="math/tex">\delta (c) \geq b_n - a_n</script> for all <script type="math/tex">n</script>.
But
<script type="math/tex">\lim_{n \to \infty} b_n - a_n =
\lim_{n \to \infty}\frac{b-a}{2^n} = 0
</script>
So we have a contradiction.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="definition-816">Definition 8.1.6.</h3>
<p>A function <script type="math/tex">f</script> on <script type="math/tex">[a,b]</script> has generalized Riemann integral <script type="math/tex">A</script>
if, for every <script type="math/tex">ϵ > 0</script>, there exists a gauge <script type="math/tex">δ(x)</script> on <script type="math/tex">[a,b]</script> such that for each tagged partition <script type="math/tex">(P,\{c_k\}^n_{k=1})</script> that is
<script type="math/tex">δ(x)</script>-fine, it is true that</p>
<p>
<script type="math/tex; mode=display"> 
|R(f,P)−A| < ϵ
</script>
</p>
<p>In this case, we write <script type="math/tex">A = \int_{a}^{b}f</script>.</p>
<h3 id="theorem-817">Theorem 8.1.7.</h3>
<p>If a function has a generalized Riemann integral, then the
value of the integral is unique.</p>
<h3 id="exercise-818">Exercise 8.1.8.</h3>
<p>Finish the argument.</p>
<p><strong>Proof</strong>: Assume that a function <script type="math/tex">f</script> has generalized Riemann 
integral <script type="math/tex">A1</script> and that
it also has generalized Riemann integral <script type="math/tex">A2</script>.
We must prove <script type="math/tex">A1 = A2</script>.</p>
<p>Since <script type="math/tex">f</script> is generalized Riemann integrable, given <script type="math/tex">\epsilon</script>, we
can find <script type="math/tex">\delta_1(x)</script>, such that if a tagged partition <script type="math/tex">P_1</script> is 
<script type="math/tex">\delta_1(x)</script>-fine, then <script type="math/tex">|R(f, P_1) - A_1| < \epsilon</script>.</p>
<p>Similarly, we can find <script type="math/tex">\delta_2(x)</script>, such that if a tagged partition <script type="math/tex">P_2</script> is 
<script type="math/tex">\delta_2(x)</script>-fine, then <script type="math/tex">|R(f, P_2) - A_2| < \epsilon</script>.</p>
<p>Now we can define <script type="math/tex">\delta (x) = \min \{\delta_1(x), \delta_2(x)\}</script>.
From Theorem 8.1.5, we can find a tagged partition <script type="math/tex">(P,\{c_k\}^n_{k=1})</script> that is <script type="math/tex">\delta(x)</script>-fine.</p>
<p>If <script type="math/tex">(P,\{c_k\}^n_{k=1})</script> is <script type="math/tex">\delta(x)</script>-fine, it has to be
<script type="math/tex">\delta_1(x)</script>-fine. This is because</p>
<p>
<script type="math/tex; mode=display"> 
x_k - x_{k-1} < \delta (c_k) \leq \delta_1(c_k)
</script>
</p>
<p>So <script type="math/tex">|R(f, P) - A_1| < \epsilon</script>.</p>
<p>For the same reason, <script type="math/tex">(P,\{c_k\}^n_{k=1})</script> is <script type="math/tex">\delta(x)</script>-fine, it has to be <script type="math/tex">\delta_2(x)</script>-fine, and <script type="math/tex">|R(f, P) - A_2| < \epsilon</script>.</p>
<p>Since</p>
<p>
<script type="math/tex; mode=display"> 
|A_1 - A_2| < |R(f, P) - A_1| + |R(f, P) - A_2| < \epsilon /2
</script>
</p>
<p>And <script type="math/tex">\epsilon</script> can be arbitrary, so <script type="math/tex">A_1 = A_2</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-819">Exercise 8.1.9</h3>
<p>Explain why every function that is Riemann-integrable
with <script type="math/tex">\int_{a}^{b}f = A</script> must also have generalized Riemann
integral <script type="math/tex">A</script>.</p>
<p><strong>Proof</strong>: If <script type="math/tex">f</script> is Riemann-integrable, then for any
<script type="math/tex">\epsilon</script>, we can find <script type="math/tex">\delta</script>, any tagged partition <script type="math/tex">P</script> is <script type="math/tex">\delta</script>-fine
then <script type="math/tex">|R(f, P) - A| \leq \epsilon</script>.</p>
<p>Let this <script type="math/tex">\delta(x) = \delta</script> be the gauge, we can see
<script type="math/tex">f</script> is generalized Riemann integrable.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="theorem-818">Theorem 8.1.8.</h3>
<p>Dirichlet’s function <script type="math/tex">g(x)</script> is generalized Riemann-integrable on
<script type="math/tex">[0,1]</script> with <script type="math/tex">\int_{0}^{1} g = 0</script>.</p>
<p><strong>Proof</strong>: Let ϵ &gt; 0. By Definition 8.1.6, we must construct a 
gauge <script type="math/tex">δ(x)</script> on [0,1] such that whenever
<script type="math/tex">(P,\{c_k\}^n_{k=1})</script> is <script type="math/tex">\delta(x)</script>-fine tagged partition, it 
follows that</p>
<p>
<script type="math/tex; mode=display"> 
0 \leq \sum_{k=1}^{n} g(c_k)(x_k - x_{k-1}) < \epsilon
</script>
</p>
<p>The gauge represents a restriction on the size of
<script type="math/tex">Δx_k = x_k−x_{k−1}</script> in the sense that <script type="math/tex">Δx_k < δ(c_k)</script>.</p>
<p>The Riemann sum consists of products of the form <script type="math/tex">g(c_k)Δx_k</script>.
Thus, for irrational tags, there is nothing to worry about because 
<script type="math/tex">g(c_k) = 0</script> in this case. Our task is to make sure that any time 
a tag <script type="math/tex">c_k</script> is rational, it comes from a suitably thin subinterval.</p>
<p>Let <script type="math/tex">\{r_1,r_2,r_3,...\}</script> be an enumeration of the countable set of rational numbers contained in <script type="math/tex">[0,1]</script>.
For each <script type="math/tex">r_k</script>, set <script type="math/tex">δ(r_k) = ϵ/2^{k+1}</script>. For x irrational, set
<script type="math/tex">δ(x) = 1</script>.</p>
<h3 id="exercise-8110">Exercise 8.1.10.</h3>
<p>Show that if <script type="math/tex">(P,\{c_k\}^n_{k=1})</script> is a <script type="math/tex">δ(x)</script>-fine tagged partition, then <script type="math/tex">R(g,P) < ϵ</script>.</p>
<p><strong>Proof</strong>:</p>
<p>If <script type="math/tex">c_k</script> is irrational, then <script type="math/tex">g(c_k)Δx_k = 0</script>.
Otherwise, <script type="math/tex">g(c_k)Δx_k < δ(r_k) = ϵ/2^{k+1}</script>.
So <script type="math/tex">\sum_{k=1}^{n} g(c_k)(x_k - x_{k-1}) < \epsilon</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="theorem-819">Theorem 8.1.9.</h3>
<p>Assume <script type="math/tex">F : [a,b] → \mathbf{R}</script> is diﬀerentiable at each point in <script type="math/tex">[a,b]</script>, and set <script type="math/tex">f(x) = F'(x)</script>. Then, <script type="math/tex">f</script> has the generalized Riemann integral</p>
<p>
<script type="math/tex; mode=display"> 
\int_{a}^{b} f = F(b) - F(a)
</script>
</p>
<p>Proof. Let <script type="math/tex">P= {x_0,x_1,x_2,...,x_n}</script> be a partition of <script type="math/tex">[a,b]</script>. Both this proof and
the proof of Theorem 7.5.1 make use of the following fact.</p>
<h3 id="exercise-8111">Exercise 8.1.11.</h3>
<p>Show that</p>
<p>
<script type="math/tex; mode=display"> 
F(b) - F(a) = \sum_{k=1}^{n} [F(x_k) - F(x_{k-1})]
</script>
</p>
<p><strong>Proof</strong>: It is obvious. <script type="math/tex">\square</script>
</p>
<p>If <script type="math/tex">\{c_k\}^n_{k=1}</script> is a set of tags for <script type="math/tex">P</script>, then we can estimate the diﬀerence between
the Riemann sum <script type="math/tex">R(f,P)</script> and <script type="math/tex">F(b)−F(a)</script> by</p>
<p>
<script type="math/tex; mode=display"> 
|F(b) - F(a) - R(f, P)| =
\left| 
\sum_{k = 1}^{n} [F(x_k) - F(x_{k-1}) - f(c_k)(x_k - x_{k-1})]
\right| \\
\leq
\sum_{k = 1}^{n} |F(x_k) - F(x_{k-1}) - f(c_k)(x_k - x_{k-1})|
</script>
</p>
<p>Let <script type="math/tex">ϵ > 0</script>. To prove the theorem, we must construct a gauge <script type="math/tex">δ(c)</script>
such that</p>
<p>
<script type="math/tex; mode=display"> 
|F(b) - F(a) - R(f, P)| < ϵ
</script>
</p>
<p>for all <script type="math/tex">(P,{c_k})</script> that are <script type="math/tex">δ(c)</script>-fine. (Using the variable <script type="math/tex">c</script> in the gauge function is more convenient than <script type="math/tex">x</script> in this case.)</p>
<h3 id="exercise-8112">Exercise 8.1.12.</h3>
<p>For each <script type="math/tex">c ∈ [a,b]</script>, explain why there exists a <script type="math/tex">δ(c) > 0</script>
(a <script type="math/tex">δ > 0</script> depending on <script type="math/tex">c</script>) such that</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
\frac{F(x) - F(c)}{x - c} - f(c)
\right|
< \epsilon
</script>
</p>
<p>for all <script type="math/tex">0 < |x-c| < \delta (c)</script>.</p>
<p><strong>Proof</strong>:</p>
<p>Since <script type="math/tex">F(x)</script> is differential at <script type="math/tex">c</script>, that means</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{x \to c} \frac{F(x) - F(c)}{x - c} = f(c)
</script>
</p>
<p>i.e. given <script type="math/tex">\epsilon</script>, for <script type="math/tex">c</script>, we can find a <script type="math/tex">\delta (c)</script>, as
long as <script type="math/tex">0 < |x-c| < \delta (c)</script>,</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
\frac{F(x) - F(c)}{x - c} - f(c)
\right|
< \epsilon
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-8113">Exercise 8.1.13.</h3>
<p>(a) For a particular <script type="math/tex">c_k ∈ [x_{k−1},x_k]</script> of <script type="math/tex">P</script>, show that</p>
<p>
<script type="math/tex; mode=display"> 
|F(x_k)−F(c_k)−f(c_k)(x_k−c_k)| < ϵ(x_k−c_k)
</script>
</p>
<p>and</p>
<p>
<script type="math/tex; mode=display"> 
|F(c_k)−F(x_{k−1})−f(c_k)(c_k−x_{k−1})| < ϵ(c_k−x_{k−1}).
</script>
</p>
<p><strong>Proof</strong>: Since <script type="math/tex">0 < x_k - c_k < \delta (c_k)</script>, then</p>
<p>
<script type="math/tex; mode=display">
\left| 
\frac{F(x_k) - F(c_k)}{x_k - c_k} - f(c_k)
\right| < \epsilon
</script>
</p>
<p>i.e.</p>
<p>
<script type="math/tex; mode=display"> 
|F(x_k)−F(c_k)−f(c_k)(x_k−c_k)| < ϵ(x_k−c_k)
</script>
</p>
<p>The other part is the same.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Now, argue that</p>
<p>
<script type="math/tex; mode=display"> 
|F(x_k)−F(x_{k−1})−f(c_k)(x_k−x_{k−1})| < ϵ(x_k−x_{k−1})
</script>
</p>
<p>and use this fact to complete the proof of the theorem.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
|F(x_k)−F(x_{k−1})−f(c_k)(x_k−x_{k−1})| =\\
\left| 
F(x_k)−F(c_k)−f(c_k)(x_k−c_k) +
F(c_k)−F(x_{k−1})−f(c_k)(c_k−x_{k−1})
\right| \\
\leq
|F(x_k)−F(c_k)−f(c_k)(x_k−c_k)| + |F(x_k)−F(c_k)−f(c_k)(x_k−c_k)| \\
\leq
ϵ(x_k−c_k) + ϵ(c_k−x_{k−1})\\
= ϵ(x_k−x_{k−1})
</script>
</p>
<p>Then we have</p>
<p>
<script type="math/tex; mode=display"> 
|F(b) - F(a) - R(f, P)| \\
\leq
\sum_{k = 1}^{n} |F(x_k) - F(x_{k-1}) - f(c_k)(x_k - x_{k-1})|
\\
\leq
\sum_{k = 1}^{n} ϵ(x_k−x_{k−1}) \\
= \epsilon
</script>
</p>
<p>Then we proved Theorem 8.1.9.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>If we consider the function</p>
<p>
<script type="math/tex; mode=display"> 
F(x) =
\begin{cases}
    x^{3/2} \sin (1/x) &\text{if } x \not = 0\\
    0 &\text{if } x = 0\\
\end{cases} 
</script>
</p>
<p>then it is not too diﬃcult to show that <script type="math/tex">F</script> is diﬀerentiable everywhere, including <script type="math/tex">x = 0</script>, with</p>
<p>
<script type="math/tex; mode=display"> 
F'(x) =
\begin{cases}
    (3/2) \sqrt[]{x} \sin (1/x) - (1/\sqrt[]{x}) \cos (1/x) &\text{if } x \not = 0\\
    0 &\text{if } x = 0\\
\end{cases} 
</script>
</p>
<p>What is notable here is that the derivative is unbounded near the origin.
The theory of the ordinary Riemann integral begins with the assumption that we only consider bounded functions on closed intervals, but there is no such restriction for the generalized Riemann integral.
Theorem 8.1.9 proves that <script type="math/tex">F'</script> has a generalized integral.</p>
<p>Now, <em>improper</em> Riemann integrals have been created to extend Riemann integration to some unbounded functions, but it is another
interesting fact about the generalized Riemann integral that any function having an improper integral must already be integrable in the sense described in Definition 8.1.6.</p>
<h3 id="theorem-8110-change-of-variable-formula">Theorem 8.1.10 (Change-of-variable Formula).</h3>
<p>Let <script type="math/tex">g : [a,b] → \mathbf{R}</script> be
diﬀerentiable at each point of <script type="math/tex">[a,b]</script>, and assume <script type="math/tex">F</script> is diﬀerentiable on the set <script type="math/tex">g([a,b])</script>.
If <script type="math/tex">f(x) = F'(x)</script> for all <script type="math/tex">x ∈ g([a,b])</script>, then</p>
<p>
<script type="math/tex; mode=display"> 
\int_{a}^{b} (f◦g)·g' =
\int_{g(a)}^{g(b)} f.
</script>
</p>
<p><strong>Proof</strong>. The hypothesis of the theorem guarantees that the function <script type="math/tex">(F ◦g)(x)</script>
is diﬀerentiable for all <script type="math/tex">x ∈ [a,b]</script>.</p>
<h3 id="exercise-8114">Exercise 8.1.14.</h3>
<p>(a) Why are we sure that <script type="math/tex">f</script> and <script type="math/tex">(F◦g)'</script> have generalized
Riemann integrals?</p>
<p><strong>Proof</strong>: This is because <script type="math/tex">F</script> is diﬀerentiable and
<script type="math/tex">f(x) = F'(x)</script>. Since <script type="math/tex">g</script> is also differentialble, then
<script type="math/tex">F◦g</script> is differentialble. And <script type="math/tex">(F◦g)'</script> is its derivative.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Use Theorem 8.1.9 to finish the proof.</p>
<p><strong>Proof</strong>:</p>
<p>On the left side</p>
<p>
<script type="math/tex; mode=display">
(F◦g)' = (f◦g) \cdot g'
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\int_{a}^{b} (f◦g)·g' = F(g(b)) - F(g(a))
</script>
</p>
<p>On the right side</p>
<p>
<script type="math/tex; mode=display"> 
\int_{g(a)}^{g(b)} f = F(g(b)) - F(g(a))
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h2 id="83-eulers-sum">8.3 Euler’s Sum</h2>
<p>In Section 6.1 we saw Euler’s first and most famous derivation of the formula</p>
<p>
<script type="math/tex; mode=display"> 
1 + \frac{1}{4} + \frac{1}{9} +
\frac{1}{16} + \frac{1}{25} + \cdots = \frac{\pi ^2}{6}
</script>
</p>
<p>At the crux of this argument are two representations for the function <script type="math/tex">sin(x)</script>.
The first is the standard Taylor series representation</p>
<p>
<script type="math/tex; mode=display"> 
\tag{1}
\sin x = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!}
+ \cdots ,
</script>
</p>
<p>and the second is an infinite product representation</p>
<p>
<script type="math/tex; mode=display"> 
\tag{2}
\sin x = x
\left( 1 - \frac{x}{\pi } \right) 
\left( 1 + \frac{x}{\pi } \right) 
\left( 1 - \frac{x}{2 \pi } \right) 
\left( 1 + \frac{x}{2 \pi } \right)
\cdots .
</script>
</p>
<h3 id="walliss-product">Wallis’s Product</h3>
<h3 id="exercise-831">Exercise 8.3.1.</h3>
<p>Supply the details to show that when <script type="math/tex">x = π/2</script> the product
formula in (2) is equivalent to</p>
<p>
<script type="math/tex; mode=display"> 
\tag{3}
\frac{\pi }{2}
=\lim_{n \to \infty}
\left( \frac{2 \cdot 2}{1 \cdot 3} \right) 
\left( \frac{4 \cdot 4}{3 \cdot 5} \right) 
\left( \frac{6 \cdot 6}{5 \cdot 7} \right) 
\cdots 
\left( \frac{2n \cdot 2n}{(2n - 1) \cdot (2n + 1)} \right) 
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>We plug the <script type="math/tex">\frac{\pi}{2}</script> into equation (2).</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-832">Exercise 8.3.2.</h3>
<p>Assume <script type="math/tex">h(x)</script> and <script type="math/tex">k(x)</script> have continuous derivatives on
<script type="math/tex">[a,b]</script> and derive the familiar integration-by-parts
formula</p>
<p>
<script type="math/tex; mode=display"> 
\int_{a}^{b} h(t) k'(t) dt
= h(b) k(b) - h(a) k (a)
- \int_{a}^{b} h'(t) k(t) dt .
</script>
</p>
<p><strong>Proof</strong>: See exercise 7.5.6.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-833">Exercise 8.3.3.</h3>
<p>(a) Using the simple identity <script type="math/tex">\sin^n(x) = \sin^{n−1}(x)\sin(x)</script> and
the previous exercise, derive the recurrence relation</p>
<p>
<script type="math/tex; mode=display"> 
b_n = \frac{n-1}{n} b_{n-2} \text{ for all } n \geq 2
</script>
</p>
<p><strong>Proof</strong>: </p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{\frac{\pi}{2}}
\sin^n(x)
= 
\int_{0}^{\frac{\pi}{2}}
\sin^{n-1} (x) \sin (x)\\
= \sin^{n-1} (\frac{\pi}{2}) (-\cos (\frac{\pi}{2}))
- \sin^{n-1} (0) (-\cos (0))
- \int_{0}^{\frac{\pi}{2}} (n - 1) \sin ^{n-2} (x) \cos (x) (-\cos (x))\\
= (n - 1)\int_{0}^{\frac{\pi}{2}}
\sin ^{n-2} (x) \cos ^2 (x) \\
= (n - 1) \int_{0}^{\frac{\pi}{2}}
\sin ^{n-2} (x) - \sin ^{n} (x)
</script>
</p>
<p>So we have</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{\frac{\pi}{2}}
\sin^n(x) +
(n - 1) \int_{0}^{\frac{\pi}{2}}
\sin^n(x) = (n - 1) \int_{0}^{\frac{\pi}{2}}
\sin^{n-2}(x)
</script>
</p>
<p>So,</p>
<p>
<script type="math/tex; mode=display"> 
b_n = \frac{n-1}{n} b_{n-2} \text{ for all } n \geq 2
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Use this relation to generate the first three even terms and the first three odd terms of the sequence <script type="math/tex">(b_n)</script>.</p>
<p>
<script type="math/tex; mode=display"> 
b_2 = \frac{1}{2} b_0 = \frac{\pi }{4}\\
b_4 = \frac{3}{4} b_2 = \frac{3 \pi }{16}\\
b_6 = \frac{5}{6} b_4 = \frac{15 \pi }{96}\\
b_3 = \frac{2}{3} b_1 = \frac{2}{3}\\
b_5 = \frac{4}{5} b_3 = \frac{8}{15}\\
b_7 = \frac{6}{7} b_4 = \frac{48}{105}\\
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Write a general expression for <script type="math/tex">b_{2n}</script> and <script type="math/tex">b_{2n+1}</script>
</p>
<p>
<script type="math/tex; mode=display">
b_{2n} = \frac{\pi}{2} \cdot \frac{1}{2}
\cdot \frac{3}{4}
\cdot \frac{5}{6} \cdots
\cdot \frac{2n-1}{2n}
</script>
</p>
<p>and </p>
<p>
<script type="math/tex; mode=display"> 
b_{2n+1} = 1
\cdot \frac{2}{3}
\cdot \frac{4}{5}
\cdot \frac{6}{7}
\cdots
\cdot \frac{2n}{2n+1}
</script>
</p>
<h3 id="exercise-834">Exercise 8.3.4.</h3>
<p>Show</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{n \to \infty} \frac{b_{2n}}{b_{2n+1}} = 1
</script>
</p>
<p>and use this fact to finish the proof of Wallis’s product formula in (3).</p>
<p><strong>Proof</strong>:</p>
<p>Because <script type="math/tex">b_{2n} \geq b_{2n+1} \geq b_{2n+2}</script>, so</p>
<p>
<script type="math/tex; mode=display"> 
1 \leq \frac{b_{2n}}{b_{2n+1}} \leq \frac{b_{2n}}{b_{2n+2}}
= \frac{2n+2}{2n+1}
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{n \to \infty} \frac{b_{2n}}{b_{2n+1}}
\leq 
\lim_{n \to \infty} \frac{2n+2}{2n+1} = 1
\\
\lim_{n \to \infty} \frac{b_{2n}}{b_{2n+1}}
\geq
\lim_{n \to \infty} 1 = 1
</script>
</p>
<p>Then it's easy to see product formula in (3) holds.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-835">Exercise 8.3.5.</h3>
<p>Derive the following alternative form of Wallis’s product formula:</p>
<p>
<script type="math/tex; mode=display"> 
\sqrt[]{\pi} =
\lim_{n \to \infty}
\frac{
2^{2n} (n!)^2
}{
(2n)! \sqrt[]{n}
}
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>We know</p>
<p>
<script type="math/tex; mode=display"> 
\frac{\pi }{2}
=\lim_{n \to \infty}
\left( \frac{2 \cdot 2}{1 \cdot 3} \right) 
\left( \frac{4 \cdot 4}{3 \cdot 5} \right) 
\left( \frac{6 \cdot 6}{5 \cdot 7} \right) 
\cdots 
\left( \frac{2n \cdot 2n}{(2n - 1) \cdot (2n + 1)} \right) \\
= \frac{
(2^{2n} (n!)^2)^2
}{
(2n!)^2 (2n+1)
}
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\pi = \lim_{n \to \infty} 
\frac{
(2^{2n} (n!)^2)^2 2
}{
(2n!)^2 (2n+1)
}
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\sqrt[]{\pi} =
\lim_{n \to \infty}
\frac{
2^{2n} (n!)^2
}{
(2n)! \sqrt[]{n}
}
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="taylor-series">Taylor Series</h3>
<h3 id="exercise-836">Exercise 8.3.6.</h3>
<p>Show that <script type="math/tex">1/\sqrt[]{1−x}</script> has Taylor expansion
<script type="math/tex">\sum_{n=0}^{∞} c_nx_n</script>, where <script type="math/tex">c_0 = 1</script> and</p>
<p>
<script type="math/tex; mode=display"> 
c_n = \frac{
(2n)!
}{2^{2n}(n!)^2}
= \frac{
1 \cdot 3 \cdot 5 \cdots (2n - 1)
}{
2 \cdot 4 \cdot 6 \cdots 2n
}
</script>
</p>
<p>for <script type="math/tex">n \geq 1</script>.</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
f'(0) = \frac{1}{2} (1 - x)^{-3/2} = \frac{1}{2} \\
f''(0) = \frac{3}{4} (1-x)^{-5/2} = \frac{3}{4} \\
\cdots \\
f^{(n)}(0) = \frac{1 \cdot 3 \cdots(2n-1)}{2^n}
</script>
</p>
<p>Then</p>
<p>
<script type="math/tex; mode=display"> 
c_n = \frac{f^{(n)}(0)}{n!} =
\frac{
1 \cdot 3 \cdot 5 \cdots (2n - 1)
}{
2 \cdot 4 \cdot 6 \cdots 2n
}
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-837">Exercise 8.3.7.</h3>
<p>Show that <script type="math/tex">\lim c_n = 0</script> but <script type="math/tex">\sum_{n=0}^{∞} c_n</script> diverges.</p>
<p><strong>Proof</strong>: </p>
<p>
<script type="math/tex; mode=display"> 
c_n = \frac{
1 \cdot 3 \cdot 5 \cdots (2n - 1)
}{
2 \cdot 4 \cdot 6 \cdots 2n
}
</script>
</p>
<p>
<script type="math/tex">c_n</script> is a decreasing and bigger than <script type="math/tex">0</script>, so <script type="math/tex">c_n</script> converges.
if <script type="math/tex">(c_n) \rightarrow c > 0</script>, then</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{n \to \infty} \frac{1}{c_n \sqrt[]{n}} \\
= \frac{1}{c} \times 0 = 0 \not = \sqrt[]{\pi}
</script>
</p>
<p>Now note</p>
<p>
<script type="math/tex; mode=display"> 
c_n >
\frac{
1 \cdot 2 \cdot 4 \cdots (2n - 2)
}{
2 \cdot 4 \cdot 6 \cdots 2n
} = \frac{1}{2n}
</script>
</p>
<p>So we have</p>
<p>
<script type="math/tex; mode=display"> 
\sum_{k=1}^{n} c_n > \frac{1}{2} (1 + 1/2 + 1/4 +
\cdots + 1/n)
</script>
</p>
<p>So <script type="math/tex">\sum_{n=0}^{∞} c_n</script> diverges.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>The divergence of <script type="math/tex">\sum_{n=0}^{∞} c_n</script> makes sense when we consider the Taylor series
for <script type="math/tex">1/</script>. We want to determine the values of <script type="math/tex">x</script> for which</p>
<p>
<script type="math/tex; mode=display"> 
\tag{4}
\frac{1}{\sqrt[]{1−x}} 
= \sum_{n = 1}^{\infty} c_nx^n,
</script>
</p>
<h3 id="exercise-838">Exercise 8.3.8.</h3>
<p>Using the expression for <script type="math/tex">E_N(x)</script> from Lagrange’s Remainder
Theorem, show that equation (4) is valid for all <script type="math/tex">|x| < 1/2</script>.
What goes wrong
when we try to use this method to prove (4) for <script type="math/tex">x ∈ (1/2,1)</script>?</p>
<p><strong>Solution</strong>:</p>
<p>The Lagrange's Remainder is</p>
<p>
<script type="math/tex; mode=display"> 
E_N(x) = \frac{f^{(N+1)}(c)}{(N+1)!}x^{N+1} =
\frac{1 \cdot 3 \cdots (2N+1) }{2^{N+1} (N+1)!}
\frac{x^{N+1}}{(1-c)^{N+1} \sqrt[]{1-c}}
</script>
</p>
<p>Fix <script type="math/tex">x < 1/2</script>, then <script type="math/tex">c < x < 1/2</script>. So <script type="math/tex">1 - c > x</script>.
<script type="math/tex">1 - c > 1/2</script>. So <script type="math/tex">\frac{1}{\sqrt[]{1-c}} < \frac{1}{\sqrt[]{2}}</script>.</p>
<p>
<script type="math/tex; mode=display"> 
\frac{x}{1-c} < 1
</script>
</p>
<p>So <script type="math/tex">E_N(x) \rightarrow 0</script>.</p>
<p>When <script type="math/tex">x ∈ (1/2,1)</script>, we cannot guarantee</p>
<p>
<script type="math/tex; mode=display"> 
\frac{x}{1-c} < 1.
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="theorem-831-integral-remainder-theorem">Theorem 8.3.1 (Integral Remainder Theorem).</h3>
<p>Let <script type="math/tex">f</script> be diﬀerentiable <script type="math/tex">N + 1</script> times on <script type="math/tex">(−R,R)</script> and assume
<script type="math/tex">f^{(N+1)}</script> is continuous. Define <script type="math/tex">a_n = f^{(n)}(0)/n!</script>
for <script type="math/tex">n = 0,1,...,N</script>, and let</p>
<p>
<script type="math/tex; mode=display"> 
S_N(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \cdots + a_N x^N
</script>
</p>
<p>For all <script type="math/tex">x ∈ (−R,R)</script>, the error function <script type="math/tex">E_N(x) = f(x)−S_N(x)</script> satisfies</p>
<p>
<script type="math/tex; mode=display"> 
E_N(x) = \frac{1}{N!}
\int_{0}^{x} f^{(N+1)}(t) (x - t)^N dt .
</script>
</p>
<p><strong>Proof</strong>. The case <script type="math/tex">x = 0</script> is easy to check, so let’s take
<script type="math/tex">x \not = 0</script> in <script type="math/tex">(−R,R)</script> and keep
in mind that <script type="math/tex">x</script> is a fixed constant in what follows. To avoid a few technical distractions, let’s just consider the case
<script type="math/tex">x > 0</script>.</p>
<h3 id="exercise-839">Exercise 8.3.9.</h3>
<p>(a) Show</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = f(0) + \int_{0}^{x} f'(t) dt
</script>
</p>
<p><strong>Proof</strong>: <script type="math/tex">f'(t)</script> is differentiable, so it's continuous.
So it's integrable. From theorem 7.5.1, then</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{x} f'(t) dt = f(x) - f(0)
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Now use a previous result from this section to show</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = f(0)+f'(0)x + \int_{0}^{x} f''(t) (x-t) dt .
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>We use integration-by-parts, and let <script type="math/tex">h(x) = f'(x), k(x) = (x-t)</script>
</p>
<p>
<script type="math/tex; mode=display">
-\int_{0}^{x} f'(t) dt = \int_{0}^{x} h(t) k'(t) dt
\\
=h(x)k(x) - h(0)k(0) - \int_{0}^{x} h'(t) k(t) dt \\
= -f'(0) x- \int_{0}^{x} f''(t) (x-t) dt \\
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{x} f'(t) dt = f'(0)x + \int_{0}^{x} f''(t) (x-t) dt
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Continue in this fashion to complete the proof of the theorem.</p>
<p><strong>Proof</strong>:</p>
<p>Let <script type="math/tex">h(t) = f^{(N)}(t), k(t) = -\frac{(x-t)^{N}}{N}</script>.</p>
<p>Consider</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{x} f^{(N)}(t) (x - t)^{N-1} dt
= \int_{0}^{x} h(t) k'(t) dt
= h(x)k(x) - h(0)k(0) - \int_{0}^{x} h''(t) k(t) dt \\
= \frac{1}{N} f^{(N)}(0) x^N +
\frac{1}{N} \int_{0}^{x} f^{(N+1)}(t) (x-t)^N dt
</script>
</p>
<p>So we have</p>
<p>
<script type="math/tex; mode=display"> 
E_N(x) = \frac{1}{N!}
\int_{0}^{x} f^{(N+1)}(t) (x - t)^N dt .
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-8310">Exercise 8.3.10.</h3>
<p>(a) Make a rough sketch of <script type="math/tex">1/\sqrt[]{1-x}</script>
and <script type="math/tex">S_2(x)</script> over the interval <script type="math/tex">(−1,1)</script>,
and compute <script type="math/tex">E_2(x)</script> for <script type="math/tex">x = 1/2,3/4</script>, and <script type="math/tex">8/9</script>.</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
a_0 = 1\\
a_1 = \frac{f'(0)}{1!} = \frac{1}{2} \\
a_2 = \frac{f''(0)}{2!} = \frac{1 \cdot 3}{2 \cdot 4} \\
</script>
</p>
<p>So <script type="math/tex">S_2(x) = 1 + \frac{1}{2}x + \frac{3}{8} x^2</script>.</p>
<p>Here are the python code to plot and compute <script type="math/tex">E_2(x)</script>.</p>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# Define the range of x values, avoiding the point where the function is undefined
x = np.linspace(-1, 0.99, 400)  # 400 points between -1 and 0.99

# Compute the function values
y = 1 / np.sqrt(1 - x)
z = 1 + (1/2) * x + (3/8) * (x**2)
# Plot the function
plt.plot(x, y)
plt.plot(x, z)
plt.title('Plot of $1/\sqrt{1-x}$ and $1 + (1/2)x + (3/8)x^2$')
plt.xlabel('x')
plt.ylabel('1/sqrt(1-x)')
plt.grid(True)
plt.show()

x = np.array([1/2, 3/4, 8/9])
y = 1 / np.sqrt(1 - x)
z = 1 + (1/2) * x + (3/8) * (x**2)
e = y - z
print(e)
</code></pre>
<p>The <script type="math/tex">E_2(x)</script> for <script type="math/tex">x = 1/2,3/4</script>, and <script type="math/tex">8/9</script> are
<script type="math/tex">[0.07046356, 0.4140625, 1.25925926]</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) For a general <script type="math/tex">x</script> satisfying <script type="math/tex">−1 < x < 1</script>, show</p>
<p>
<script type="math/tex; mode=display"> 
E_2(x) = \frac{15}{16}
\int_{0}^{x}
\left( 
\frac{x-t}{1-t}
\right) ^ 2
\frac{1}{
(1-t)^{3/2}
} dt
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
E_2(x) =
\frac{1}{2!}
\int_{0}^{x} f^{(2+1)}(t) (x - t)^2 dt
</script>
</p>
<p>
<script type="math/tex; mode=display"> 
f^{(1)}(t) = \frac{1}{2} (1-x)^{-\frac{3}{2}} \\
f^{(2)}(t) = \frac{1 \cdot 3}{2 \cdot 2} (1-x)^{-\frac{5}{2}} \\
f^{(3)}(t) = \frac{1 \cdot 3 \cdot 5}{2 \cdot 2 \cdot 2}
(1-x)^{-\frac{7}{2}} \\
</script>
</p>
<p>So we proved.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Explain why the inequality</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
\frac{x-t}{1-t}
\right| \leq |x|
</script>
</p>
<p>is valid, and use this to find an overestimate for
<script type="math/tex">|E_2(x)|</script> that no longer
involves an integral. Note that this estimate will necessarily depend on <script type="math/tex">x</script>.
Confirm that things are going well by checking that this overestimate is
in fact larger than <script type="math/tex">|E_2(x)|</script> at the three computed values from part (a).</p>
<p><strong>Proof</strong>: </p>
<p>Assume <script type="math/tex">0 \leq t \leq x < 1</script>. Then <script type="math/tex">xt \leq  t</script>,
<script type="math/tex">x - xt \geq x - t</script>, so <script type="math/tex">\frac{x-t}{1-t} \leq x</script>
</p>
<p>If <script type="math/tex">-1 < x \leq t \leq 0</script>, then <script type="math/tex">xt \geq t</script> so
<script type="math/tex">x - xt \leq x - t</script>, so <script type="math/tex">x \leq \frac{x-t}{1-t}</script>, i.e.
<script type="math/tex">-x \geq -\frac{x-t}{1-t}</script>
</p>
<p>In both cases, we proved it.</p>
<p>
<script type="math/tex; mode=display"> 
|E_2(x)| = \frac{15}{16}
\left| 
\int_{0}^{x}
\left( 
\frac{x-t}{1-t}
\right) ^ 2
\frac{1}{
(1-t)^{3/2}
} dt
\right| \\
\leq
\frac{15}{16} x^3 \frac{1}{(1-|x|)^{3/2}}
</script>
</p>
<p>For <script type="math/tex">x = 1/2,3/4</script>, and <script type="math/tex">8/9</script> are, the errors are</p>
<p>
<script type="math/tex; mode=display"> 
[0.3314563, 3.1640625, 17.77777778]
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(d) Finally, show
<script type="math/tex">E_N(x) → 0</script> as <script type="math/tex">N → ∞</script> for an arbitrary <script type="math/tex">x ∈ (−1,1)</script>.</p>
<p><strong>Proof</strong>:</p>
<p>We have</p>
<p>
<script type="math/tex; mode=display"> 
f^{(N+1)}(t) =
\frac{1 \cdot 3 \cdots (2N+1) }{2^{N+1}}
\cdot
\frac{1}{(1-t)^{N}}
\cdot
\frac{1}{(1-t)^{3/2}}
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
E_N(x) = \frac{1}{N!}
\int_{0}^{x}
\frac{1 \cdot 3 \cdots (2N+1) }{2^{N+1}}
\cdot
\frac{1}{(1-t)^{N}}
\cdot
\frac{1}{(1-t)^{3/2}}
(x-t)^N dt \\
\leq 
C_N \cdot (2N+1)|x|^N \frac{|x|}{(1-|x|)^{3/2}}
</script>
</p>
<p>Since <script type="math/tex">C_N \rightarrow 0</script> and <script type="math/tex">(2N+1)|x|^N \rightarrow 0</script>,
then <script type="math/tex">E_N(x)</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>The next step is to take the term-by-term anti-derivative of
this series.
Any time we start manipulating infinite series as though they 
were finite in nature we need to pause and make sure we are on 
solid footing.</p>
<h3 id="exercise-8311">Exercise 8.3.11.</h3>
<p>Assuming that the derivative of <script type="math/tex">\arcsin (x)</script> is indeed
<script type="math/tex">1 / \sqrt[]{1−x^2}</script>
supply the justification that allows us to conclude</p>
<p>
<script type="math/tex; mode=display">
\tag{5}
\arcsin (x) =
\sum_{n = 0}^{\infty}
\frac{c_n}{2n+1} x^{2n+1} \text{ for all } |x| < 1.
</script>
</p>
<p><strong>Proof</strong>: Since <script type="math/tex">\sum_{n = 0}^{\infty}c_nx^{2n}</script> converges
for <script type="math/tex">|x| < 1</script>, and <script type="math/tex">\frac{c_n}{2n+1} x^{2n+1} < c_nx^{2n}</script>,
then <script type="math/tex">\sum_{n = 0}^{\infty} \frac{c_n}{2n+1} x^{2n+1}</script>
converges for <script type="math/tex">|x| < 1</script>.</p>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
f(x) =
\sum_{n = 0}^{\infty}
\frac{c_n}{2n+1} x^{2n+1}
</script>
</p>
<p>From theorem 6.5.7, <script type="math/tex">f(x)</script> is differentiable and
<script type="math/tex">f'(x) = \arcsin' (x)</script>. So <script type="math/tex">f(x) = \arcsin (x) + C</script>.
Since <script type="math/tex">f(0) = \arcsin (0) = 0</script>, then <script type="math/tex">f(x) = \arcsin (x)</script>,
for <script type="math/tex">|x| < 1</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-8312">Exercise 8.3.12.</h3>
<p>Our work thus far shows that the Taylor series in (5) is valid
for all <script type="math/tex">|x| < 1</script>, but note that <script type="math/tex">\arcsin(x)</script> is continuous for all <script type="math/tex">|x| ≤ 1</script>. Carefully
explain why the series in (5) converges uniformly to
<script type="math/tex">\arcsin(x)</script> on the closed interval <script type="math/tex">[−1,1]</script>.</p>
<p>Proof: Consider</p>
<p>
<script type="math/tex; mode=display"> 
f(1) =
\sum_{n = 0}^{\infty}
\frac{c_n}{2n+1}
</script>
</p>
<p>Since</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{n \to \infty} \frac{1}{c_n \sqrt[]{n}}
= \sqrt[]{\pi }
</script>
</p>
<p>Then</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{n \to \infty} c_n \sqrt[]{n}
= 1/\sqrt[]{\pi }
</script>
</p>
<p>when <script type="math/tex">n</script> is large,
<script type="math/tex">c_n < \frac{1 + 1/\sqrt[]{\pi}}{\sqrt[]{n}} < \frac{2}{\sqrt[]{n}}</script>.</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\frac{c_n}{2n+1} < \frac{2}{(2n+1)\sqrt[]{n}}
\lt n^{-3/2} 
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\sum_{n = 0}^{\infty}
\frac{c_n}{2n+1}
</script>
</p>
<p>converges. Since it's all positive, it converges absolutely.
Then (5) also converges in <script type="math/tex">-1</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="summing-sum_n-1infty-1n2">Summing <script type="math/tex">\sum_{n = 1}^{\infty} 1/n^2</script>
</h3>
<p>Every proof of Euler’s sum contains a moment of genuine
ingenuity at some point, and this is where our proof takes
an unanticipated turn.</p>
<p>Let’s make the substitution
<script type="math/tex">x = \sin(θ)</script> in (5) where we restrict our attention
to <script type="math/tex">−π/2 ≤ θ ≤ π/2</script>. The result is</p>
<p>
<script type="math/tex; mode=display"> 
\theta = \arcsin (\sin (\theta) ) =
\sum_{n = 1}^{\infty}
\frac{c_n}{2n+1} \sin ^{2n+1} (\theta )
</script>
</p>
<p>which converges uniformly on <script type="math/tex">[−π/2,π/2]</script>.</p>
<h3 id="exercise-8313">Exercise 8.3.13.</h3>
<p>(a) Show</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{\pi /2} \theta d \theta 
= \sum_{n = 1}^{\infty} \frac{c_n}{2n+1} b_{2n+1}
</script>
</p>
<p>being careful to justify each step in the argument. The term
<script type="math/tex">b_{2n+1}</script> refers
back to our earlier work on Wallis’s product.</p>
<p><strong>Proof</strong>: let</p>
<p>
<script type="math/tex; mode=display">
f_n(\theta ) =
\frac{c_n}{2n+1} \sin ^{2n+1} (\theta ) \\
f(\theta ) = \theta
</script>
</p>
<p>So <script type="math/tex">\sum_{n = 1}^{\infty}f_n(\theta ) \rightarrow f(\theta )</script>
uniformly, then</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{\pi /2} \theta d \theta =
\sum_{n = 1}^{\infty} \int_{0}^{\pi /2} f_n(\theta)
= \sum_{n = 1}^{\infty} 
\frac{c_n}{2n+1} \int_{0}^{\pi /2} \sin ^{2n+1} (\theta ) \\
= \sum_{n = 1}^{\infty} 
\frac{c_n}{2n+1} b_{2n+1}
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Deduce</p>
<p>
<script type="math/tex; mode=display"> 
\frac{\pi ^2}{8} = \sum_{n = 0}^{\infty} \frac{1}{(2n+1)^2},
</script>
</p>
<p>and use this to finish the proof that <script type="math/tex">\frac{\pi ^2}{6} = \sum_{n = 1}^{\infty} 1/n^2</script>.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
c_n = \frac{
1 \cdot 3 \cdot 5 \cdots (2n - 1)
}{
2 \cdot 4 \cdot 6 \cdots 2n
}
</script>
</p>
<p>
<script type="math/tex; mode=display"> 
b_{2n+1} = 1
\cdot \frac{2}{3}
\cdot \frac{4}{5}
\cdot \frac{6}{7}
\cdots
\cdot \frac{2n}{2n+1}
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\frac{c_n}{2n+1} b_{2n+1} = \frac{1}{(2n+1)^2}
</script>
</p>
<p>On the left side, <script type="math/tex">\int_{0}^{\pi /2} \theta d \theta = \frac{1}{2}(\frac{\pi}{2})^2 - 0 = \frac{\pi ^2}{8}</script>.</p>
<p>So we proved the first part.</p>
<p>Let</p>
<p>
<script type="math/tex; mode=display">
A = \frac{1}{1^2} + \frac{1}{2^2} + \frac{1}{3^2} + \frac{1}{4^2}
+ \cdots
</script>
</p>
<p>Then</p>
<p>
<script type="math/tex; mode=display"> 
A = (\frac{1}{1^2} + \frac{1}{3^2} + \cdots) +
(\frac{1}{2^2} + \frac{1}{4^2} + \cdots) \\
= \frac{\pi^2}{8} +  \frac{1}{4} A
</script>
</p>
<p>So <script type="math/tex">A = \frac{\pi ^2}{6}</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h2 id="84-inventing-the-factorial-function">8.4 Inventing the Factorial Function</h2>
<h3 id="exercise-842">Exercise 8.4.2.</h3>
<p>Verify that the series converges absolutely for all
<script type="math/tex">x ∈ R</script>, that <script type="math/tex">E(x)</script> is diﬀerentiable on <script type="math/tex">R</script>, and
<script type="math/tex">E'(x) = E(x)</script>.</p>
<p><strong>Proof</strong>: Fix any <script type="math/tex">x \in \mathbf{R}</script>, we can find 
<script type="math/tex">N > 2x</script>. Let <script type="math/tex">a_n = \frac{x^n}{n!}</script> and</p>
<p>
<script type="math/tex; mode=display">
A =
\left| 
\frac{x^N}{N!}
\right| 
</script>
</p>
<p>For <script type="math/tex">n > N</script>, <script type="math/tex">|a_n| < \frac{A}{2^{n-N}}</script>. So <script type="math/tex">\sum_{k = 1}^{\infty}|a_n|</script> converges absolutely. Then we can apply
Theorem 6.5.7 to know that <script type="math/tex">E(x)</script> is diﬀerentiable on <script type="math/tex">R</script>,
and <script type="math/tex">E'(x) = E(x)</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-843">Exercise 8.4.3.</h3>
<p>(a) Use the results of Exercise 2.8.7 and the binomial formula
to show that <script type="math/tex">E(x+y) = E(x)E(y)</script> for all <script type="math/tex">x,y ∈ \mathbf{R}</script>.</p>
<p><strong>Proof</strong>: Fix <script type="math/tex">x</script> and <script type="math/tex">y</script>. Let</p>
<p>
<script type="math/tex; mode=display"> 
a_n = \frac{x^n}{n!} \\
b_n = \frac{y^n}{n!} \\
</script>
</p>
<p>Then note</p>
<p>
<script type="math/tex; mode=display"> 
d_k = a_{0}b_{k} + a_{1}b_{k-1} + \cdots + a_{k-1}b_{1} + a_k b_0 \\
= \frac{y^k}{0!k!} + \frac{xy^{k-1}}{1!(k-1)!} + \cdots 
+ \frac{x^{k-1}y}{(k-1)!1!} + \frac{x^k}{k!0!} \\
= \frac{(x+y)^k}{k!}
</script>
</p>
<p>Use the results of Exercise 2.8.7, <script type="math/tex">\sum_{k = 1}^{\infty}d_k</script>
converges and it converges <script type="math/tex">E(x)E(y)</script>.</p>
<p>On the other hand, <script type="math/tex">\sum_{k = 1}^{\infty}d_k = E(x+y)</script>.</p>
<p>So <script type="math/tex">E(x+y) = E(x)E(y)</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Show that <script type="math/tex">E(0) = 1, E(−x) = 1/E(x)</script>, and <script type="math/tex">E(x) > 0</script> for all <script type="math/tex">x ∈ \mathbf{R}</script>.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
E(0) = 1 + \frac{0}{1!} + \frac{0^2}{2!} + \cdots = 1
</script>
</p>
<p>Also</p>
<p>
<script type="math/tex; mode=display"> 
1 = E(0) = E(x + (-x)) = E(x)E(-x)
</script>
</p>
<p>So <script type="math/tex">E(-x)=1/E(x)</script>.</p>
<p>Also since if <script type="math/tex">x > 0</script>, then <script type="math/tex">a_n = \frac{x^n}{n!} > 0</script>,
then <script type="math/tex">E(x) > 0</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-844">Exercise 8.4.4.</h3>
<p>Define <script type="math/tex">e = E(1)</script>. Show <script type="math/tex">E(n) = e^n</script> and <script type="math/tex">E(m/n) = (\sqrt[n]{e})^m</script> for all <script type="math/tex">m,n ∈ Z</script>.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
E(n) = E(1+1+\cdots +1) = E(1)\cdot E(1) \cdots E(1)\\
= e^n
</script>
</p>
<p>We also have</p>
<p>
<script type="math/tex; mode=display"> 
e = E(1) = E(1/n + \cdots +1/n) = E(1/n)^n
</script>
</p>
<p>So <script type="math/tex">E(1/n) = \sqrt[n]{e}</script>. So <script type="math/tex">E(m/n) = (\sqrt[n]{e})^n</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="definition-841">Definition 8.4.1.</h3>
<p>Given <script type="math/tex">f : [a,∞] → R</script>, we say that <script type="math/tex">\lim_{x \to \infty} f(x) = L</script> if for all <script type="math/tex">ϵ > 0</script>, there exists <script type="math/tex">M > a</script> such that whenever <script type="math/tex">x ≥ M</script> it follows that</p>
<p>
<script type="math/tex; mode=display"> 
|f(x) - L| < \epsilon
</script>
</p>
<h3 id="exercise-845">Exercise 8.4.5.</h3>
<p>Show <script type="math/tex">\lim_{x \to \infty}  x^ne^{−x} = 0</script>
for all <script type="math/tex">n = 0,1,2,...</script>.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display">
\frac{x^n}{e^x} = 
\frac{x^n}{1 + \frac{x}{1} + \frac{x^2}{2!}+ \cdots + \frac{x^{n+1}}{(n+1)!} + \cdots} \leq
\frac{(n+1)!}{x} \rightarrow 0
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-846">Exercise 8.4.6.</h3>
<p>(a) Explain why we know <script type="math/tex">e^x</script> has an inverse function—let’s
call it <script type="math/tex">\log x</script>—defined on the strictly positive real numbers and satisfying</p>
<p>(i) <script type="math/tex">\log (e^y) = y</script> for all <script type="math/tex">y \in \mathbf{R}</script> and</p>
<p>(ii) <script type="math/tex">e^{\log x} = x</script>, for all <script type="math/tex">x > 0</script>.</p>
<p>(b) Prove <script type="math/tex">(\log x)' = 1/x</script>. (See Exercise 5.2.12.)</p>
<p><strong>Proof</strong>:</p>
<p>Let <script type="math/tex">y = e^x</script>
<script type="math/tex; mode=display"> 
\log'y = \frac{1}{(e^x)'} = \frac{1}{e^x} = 1/y
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Fix <script type="math/tex">y > 0</script> and diﬀerentiate <script type="math/tex">\log(xy)</script> with respect to <script type="math/tex">x</script>. Conclude that</p>
<p>
<script type="math/tex; mode=display"> 
\log_{} (xy) = \log x + \log y \text{ for all } x, y > 0.
</script>
</p>
<p><strong>Proof</strong>: Also see exercise
Exercise 7.5.8 (Natural Logarithm and Euler’s Constant).</p>
<p>
<script type="math/tex; mode=display"> 
\log_{}' (xy) = \frac{1}{xy} \cdot y = \frac{1}{x}
</script>
</p>
<p>Since <script type="math/tex">\log_{}' x = \frac{1}{x}</script>, so</p>
<p>
<script type="math/tex; mode=display"> 
\log xy = \log x + C
</script>
</p>
<p>Since <script type="math/tex">\log 1 = 0</script>, we can plug <script type="math/tex">x = 1</script> and get
<script type="math/tex">\log y = C</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(d) For <script type="math/tex">t > 0</script> and <script type="math/tex">n ∈ N</script>, <script type="math/tex">t_n</script> has the usual interpretation as <script type="math/tex">t·t···t</script> (<script type="math/tex">n</script> times). Show that</p>
<p>
<script type="math/tex; mode=display"> 
\tag{2}
t^n = e^{n \log_{} t} \text{ for all } n \in \mathbf{N}
</script>
</p>
<p><strong>Proof</strong>: </p>
<p>From (c), we know</p>
<p>
<script type="math/tex; mode=display"> 
n \log_{} t = \log_{} t^n 
</script>
</p>
<p>And from (a), we know</p>
<p>
<script type="math/tex; mode=display"> 
e^ {\log_{} t^n } = t^n
</script>
</p>
<p>So (2) holds.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="definition-842">Definition 8.4.2.</h3>
<p>Given <script type="math/tex">t > 0</script>, define the exponential function <script type="math/tex">t^x</script> to be</p>
<p>
<script type="math/tex; mode=display"> 
t^x = e^{x \log_{} t} \text{ for all } x \in \mathbf{R}
</script>
</p>
<h3 id="exercise-847">Exercise 8.4.7.</h3>
<p>(a) Show <script type="math/tex">t^{m/n} = (\sqrt[n]{t})^m</script> for all <script type="math/tex">m, n \in \mathbf{N}</script>.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
(\sqrt[n]{t})^m =
e^{m \log_{} \sqrt[n]{t}}
</script>
</p>
<p>Let <script type="math/tex">p = \log_{} \sqrt[n]{t}</script>, then <script type="math/tex">e^p = \sqrt[n]{t}</script>,
<script type="math/tex">e^{pn} = t</script>, i.e. <script type="math/tex">n \log_{} e^p = \log_{} t</script>,
i.e. <script type="math/tex">\log_{} e^p = \frac{1}{n} \log_{} t</script>, i.e.
<script type="math/tex">\log_{} \sqrt[n]{t} = \frac{1}{n} \log_{} t</script>.</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
e^{m \log_{} \sqrt[n]{t}} = e^{\frac{m}{n} \log_{} t}\\
= t^{\frac{m}{n}}
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Show <script type="math/tex">\log(t^x) = x\log t</script>, for all <script type="math/tex">t > 0</script> and <script type="math/tex">x ∈ \mathbf{R}</script>.</p>
<p><strong>Proof</strong>: Note</p>
<p>
<script type="math/tex; mode=display"> 
e^{x\log t} = t^x \\
e^{\log(t^x)} = t^x
</script>
</p>
<p>So <script type="math/tex">\log(t^x) = x\log t</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Show <script type="math/tex">t^x</script> is diﬀerentiable on <script type="math/tex">\mathbf{R}</script> and find the derivative.</p>
<p><strong>Proof</strong>: Because <script type="math/tex">t^x = e^{x \log_{} t}</script>, let</p>
<p>
<script type="math/tex; mode=display"> 
g(x) = x \log_{} t
</script>
</p>
<p>which is differentiable, and let <script type="math/tex">f(x) = e^x</script> which is also
differentiable, then their composite function <script type="math/tex">f \circ g</script>
is also differentiable.</p>
<p>
<script type="math/tex; mode=display"> 
(e^{x \log_{} t})' = e^{x \log_{} t} \log_{} t = t^x \log_{} t
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-848">Exercise 8.4.8.</h3>
<p>Inspired by the fact that <script type="math/tex">0! = 1</script> and <script type="math/tex">1! = 1</script>, let <script type="math/tex">h(x)</script> satisfy</p>
<p>(i) <script type="math/tex">h(x) = 1</script> for all <script type="math/tex">0 ≤ x ≤ 1</script>, and</p>
<p>(ii) <script type="math/tex">h(x) = xh(x−1)</script> for all <script type="math/tex">x ∈ \mathbf{R}</script>.</p>
<p>(a) Find a formula for <script type="math/tex">h(x)</script> on <script type="math/tex">[1,2]</script>, <script type="math/tex">[2,3]</script>, and <script type="math/tex">[n,n + 1]</script> for arbitrary <script type="math/tex">n \in \mathbf{N}</script>.</p>
<p>
<script type="math/tex; mode=display"> 
h(x) = x h(x - 1) = x, x \in [1,2] \\
h(x) = x h(x - 1) = x(x-1), x \in [2,3] \\
h(x) = x h(x - 1) = x(x-1) \cdots 1, x \in [n, n+1] \\
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) (c) skipped</p>
<h3 id="improper-riemann-integrals">Improper Riemann Integrals</h3>
<h3 id="definition-843">Definition 8.4.3.</h3>
<p>Assume <script type="math/tex">f</script> is defined on <script type="math/tex">[a,∞)</script> and integrable on every
interval of the form <script type="math/tex">[a,b]</script>. Then define <script type="math/tex">\int_{a}^{\infty }f</script> to be</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{b \to \infty} \int_{a}^{b}f,
</script>
</p>
<p>provided the limit exists. In this case we say the improper integral <script type="math/tex">\int_{a}^{\infty }f</script> converges.</p>
<h3 id="exercise-849">Exercise 8.4.9.</h3>
<p>(a) Show that the improper integral <script type="math/tex">\int_{a}^{\infty }f</script>
converges if and only if, for all <script type="math/tex">ϵ > 0</script> there exists
<script type="math/tex">M > a</script> such that whenever <script type="math/tex">d > c \geq M</script> it follows that</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
\int_{c}^{d} f
 \right| < \epsilon
</script>
</p>
<p>(In one direction it will be useful to consider the sequence
<script type="math/tex">a_n = \int_{a}^{a+n} f</script>.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex">\Rightarrow</script> Assume <script type="math/tex">\int_{a}^{\infty }f</script>
converges, and assume <script type="math/tex">\lim_{b \to \infty} \int_{a}^{b}f = B</script>,
then we can find <script type="math/tex">M</script>, if <script type="math/tex">b \geq M</script>, then</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
\int_{a}^{b} f - B
 \right| < \epsilon / 2
</script>
</p>
<p>Consider <script type="math/tex">d > c \geq M</script>,</p>
<p>
<script type="math/tex; mode=display">
\left| \int_{c}^{d} f \right| 
=
\left| \int_{a}^{d} f - \int_{a}^{c} f \right|
\leq
\left| \int_{a}^{d} f - B \right| +
\left| B - \int_{a}^{c} \right| <
\epsilon / 2 + \epsilon / 2 = \epsilon 
</script>
</p>
<p>
<script type="math/tex">\Leftarrow</script> Consider <script type="math/tex">a_n = \int_{a}^{a+n} f</script> then
<script type="math/tex">a_n</script> is Cauchy sequence and assume <script type="math/tex">\lim_{n \to \infty} a_n = B</script>.</p>
<p>For <script type="math/tex">\epsilon</script>, we can find <script type="math/tex">M_1</script>, such that <script type="math/tex">d > c \geq M_1</script>,</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
\int_{c}^{d} f
 \right| < \epsilon / 2
</script>
</p>
<p>We can also find <script type="math/tex">M_2</script>, if <script type="math/tex">a+n > M_2</script>, then
<script type="math/tex">|a_n - B| < \epsilon / 2</script>. Then let <script type="math/tex">M = \max \{M_1, M_2\}</script>.</p>
<p>If <script type="math/tex">b > M</script>, and find <script type="math/tex">n</script> such that <script type="math/tex">a+n > M</script>  then</p>
<p>
<script type="math/tex; mode=display"> 
\left| \int_{a}^{b} f - B \right| =
\left| \int_{a}^{b} f - \int_{a}^{a+n} f + \int_{a}^{a+n} f - B \right| < \\
\left| \int_{a}^{b} f - \int_{a}^{a+n} f \right| +
\left| \int_{a}^{a+n} f - B \right| < \\
\epsilon / 2 + \epsilon / 2 = \epsilon
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{b \to \infty} \int_{a}^{b} f = B
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Show that if <script type="math/tex">0 ≤ f ≤ g</script> and <script type="math/tex">\int_{a}^{b}g</script> converges
then <script type="math/tex">\int_{a}^{b}f</script> converges.</p>
<p><strong>Proof</strong>: Since <script type="math/tex">\int_{a}^{b}g</script> converges, then
we can find <script type="math/tex">M</script>, if <script type="math/tex">d > c \geq M</script> then
<script type="math/tex">|\int_{c}^{d} g | = \int_{c}^{d} g < \epsilon</script>.
Since <script type="math/tex">0 ≤ f ≤ g</script>, then
<script type="math/tex">|\int_{c}^{d} f | = \int_{c}^{d} f \leq
\int_{c}^{d} g < \epsilon</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Part (a) is a Cauchy criterion, and part (b) is a comparison 
test. State and prove an absolute convergence test for improper 
integrals.</p>
<p><strong>Proof</strong>: The absolute convergence test for improper 
integrals is: if <script type="math/tex">f</script> is integrable on any interval <script type="math/tex">[a,b]</script> and <script type="math/tex">\lim_{b \to \infty} \int_{a}^{b} |f|</script> converges,
then <script type="math/tex">\lim_{b \to \infty} \int_{a}^{b} f</script> converges.</p>
<p>Since <script type="math/tex">f</script> is integrable on any interval <script type="math/tex">[a,b]</script>, then from Theorem 7.4.2. (v), <script type="math/tex">|f|</script> is also integrable on any interval <script type="math/tex">[a,b]</script>. Since <script type="math/tex">\lim_{b \to \infty} \int_{a}^{b} f</script> converges,
we can find a <script type="math/tex">M</script> such that <script type="math/tex">d > c \geq M</script>, then</p>
<p>
<script type="math/tex; mode=display"> 
\int_{c}^{d} |f| < \epsilon
</script>
</p>
<p>Again from Theorem 7.4.2. (v)</p>
<p>
<script type="math/tex; mode=display"> 
\left| \int_{c}^{d} f \right| \leq
\int_{c}^{d} |f| < \epsilon 
</script>
</p>
<p>Then from part (a) <script type="math/tex">\lim_{b \to \infty} \int_{a}^{b} f</script> converges.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-8410">Exercise 8.4.10.</h3>
<p>(a) Use the properties of <script type="math/tex">e^t</script> previously discussed to show</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{\infty} e^{-t} dt = 1
</script>
</p>
<p><strong>Proof</strong>: <script type="math/tex">e^t</script> is continuous on <script type="math/tex">[0,b]</script>, so it's integrable.
Then we can use the first part of theorem 7.5.1, let</p>
<p>
<script type="math/tex; mode=display"> 
F(t) = - e^{-t}
</script>
</p>
<p>and <script type="math/tex">F'(t) = e^{-t}</script>, so</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{\infty} e^{-t} dt = \lim_{b \to \infty} F(b) - F(0)
= 1 - e^{-b} = 1
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Show</p>
<p>
<script type="math/tex; mode=display"> 
\tag{3}
\frac{1}{\alpha }
= \int_{0}^{\infty}e^{-\alpha t} dt,
\text{ for all } \alpha > 0.
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex">e^{-\alpha t}</script> is continuous on <script type="math/tex">[0,b]</script>, so it's integrable.</p>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
F(t) = - \frac{1}{\alpha} e^{-\alpha t}
</script>
</p>
<p>and <script type="math/tex">F'(t) = f(t)</script>.</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{\infty} e^{-\alpha t} dt =
\lim_{b \to \infty} F(b) - F(0) = \frac{1}{\alpha}
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-8411">Exercise 8.4.11.</h3>
<p>(a) Evaluate <script type="math/tex">\int_{0}^{b} t e^{-\alpha t}</script> using the integration-by-parts formula from Exercise 7.5.6. The result will be an expression in α and b.</p>
<p><strong>Solution</strong>:</p>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
h(t) = - \frac{1}{\alpha } e^{-\alpha t} \\
k(t) = t
</script>
</p>
<p>Then</p>
<p>$$ 
\int_{0}^{b} t e^{-\alpha t} =
\int_{0}^{b} k(t) h'(t) =
h(b) k(b) - h(0) k(0) - \int_{0}^{b} k'(t) h(t) = \
- \frac{1}{\alpha } e^{-\alpha b} \cdot b -</p>
<h1 id="int_0b-frac1alpha-e-alpha-t-dt">\int_{0}^{b} -\frac{1}{\alpha } e^{-\alpha t} dt \</h1>
<p>\frac{1}{\alpha } \int_{0}^{b} e^{-\alpha t} dt -
\frac{b}{\alpha } e^{-\alpha b} \
=
\frac{1}{\alpha } (\frac{1}{\alpha} -
\frac{1}{\alpha } e^{-\alpha b}) -
\frac{b}{\alpha } e^{-\alpha b}
$$</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Now compute</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{\infty} t e^{-\alpha t}
</script>
</p>
<p>and verify equation (4).</p>
<p>
<script type="math/tex; mode=display"> 
\tag{4}
\frac{1}{\alpha ^2} =
\int_{0}^{\infty} t e^{-\alpha t} dt
</script>
</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{b \to \infty} 
\frac{1}{\alpha } (\frac{1}{\alpha} -
\frac{1}{\alpha } e^{-\alpha b}) -
\frac{b}{\alpha } e^{-\alpha b} = \frac{1}{\alpha ^2}
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="differentiating-under-the-integral">Diﬀerentiating Under the Integral</h3>
<ul>
<li>Our sense of distance
between points <script type="math/tex">(x_0,t_0)</script> and <script type="math/tex">(x,t)</script> with the familiar Euclidean distance formula</li>
</ul>
<p>
<script type="math/tex; mode=display"> 
\| (x,t) - (x_0,t_0) \| =
\sqrt[]{(x - x_0^2) + (t - t_0)^2}
</script>
</p>
<h3 id="definition-844">Definition 8.4.4.</h3>
<p>A function <script type="math/tex">f : D → \mathbf{R}</script> is continuous at <script type="math/tex">(x_0,t_0)</script> if for all
<script type="math/tex">ϵ > 0</script>, there exists <script type="math/tex">δ > 0</script> such that whenever
<script type="math/tex">\| (x,t) - (x_0,t_0) \| < \delta</script>, it follows
that</p>
<p>
<script type="math/tex; mode=display"> 
\left| f(x, t) - f(x_0, t_0) \right| < \epsilon.
</script>
</p>
<h3 id="exercise-8412">Exercise 8.4.12.</h3>
<p>Assume the function <script type="math/tex">f(x,t)</script> is continuous on the rectangle
<script type="math/tex">D = \{(x,t) : a \leq x \leq b, c \leq t \leq d\}</script>.
Explain why the function</p>
<p>
<script type="math/tex; mode=display"> 
F(x) = \int_{c}^{d} f(x, t)dt
</script>
</p>
<p>is properly defined for all <script type="math/tex">x \in [a,b]</script>.</p>
<p><strong>Proof</strong>: Fix <script type="math/tex">x</script>, <script type="math/tex">f(x, t)</script> is a continuous function
defined on <script type="math/tex">[c,d]</script>. So it is integrable. So</p>
<p>
<script type="math/tex; mode=display"> 
\int_{c}^{d} f(x, t)dt
</script>
</p>
<p>exists.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>It should not be too surprising that Theorem 4.4.7
has an analogue in the
<script type="math/tex">\mathbf{R}^2</script> setting.
The set <script type="math/tex">D</script> is compact in <script type="math/tex">\mathbf{R}^2</script>, and a continuous 
function on <script type="math/tex">D</script> is
uniformly continuous in the sense that the
<script type="math/tex">δ</script> in Definition 8.4.4 can be chosen
independently of the point <script type="math/tex">(x_0,t_0)</script>.</p>
<h3 id="theorem-845">Theorem 8.4.5.</h3>
<p>If <script type="math/tex">f(x,t)</script> is continuous on <script type="math/tex">D</script>, then
<script type="math/tex">F(x) = \int_{c}^{d} f(x,t) dt</script> is uniformly continuous on
<script type="math/tex">[a,b]</script>.</p>
<h3 id="exercise-8413">Exercise 8.4.13.</h3>
<p>Prove Theorem 8.4.5.</p>
<p><strong>Proof</strong>: We will prove <script type="math/tex">F(x)</script> is continuous first.
Given <script type="math/tex">x_0</script> in <script type="math/tex">[a, b]</script> and <script type="math/tex">\epsilon > 0</script>, since <script type="math/tex">f(x,t)</script>
is uniformly continuous on <script type="math/tex">D</script>, we can find <script type="math/tex">\delta</script>,
as long as <script type="math/tex">x \in U_{\delta}(x_0)</script>,
<script type="math/tex">\left| f(x, t) - f(x_0, t) \right| < \frac{\epsilon}{d-c}</script> for
all <script type="math/tex">t \in [c,d]</script>.</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
|F(x) - F(x_0)| =
\left| \int_{c}^{d} f(x, t) -
\int_{c}^{d} f(x_0, t) \right| 
\leq
\int_{c}^{d}
\left| f(x, t) -
f(x_0, t) \right| \\
\leq
\frac{\epsilon }{d-c} (d-c) = \epsilon
</script>
</p>
<p>Since <script type="math/tex">F(x)</script> is continuous then <script type="math/tex">F(x)</script> is uniformly continuous.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>Taking inspiration from equations (3) and (4), let’s add the 
assumption that
for each fixed value of <script type="math/tex">t</script> in <script type="math/tex">[c,d]</script>, the function
<script type="math/tex">f(x,t)</script> is a diﬀerentiable function of <script type="math/tex">x</script>; that is,</p>
<p>
<script type="math/tex; mode=display"> 
f_x(x, t) = \lim_{z \to x}
\frac{
f(z,t) - f(x,t)
}{z-x}
</script>
</p>
<p>exists for all <script type="math/tex">(x,t) ∈ D</script>.
In addition, let’s assume that the derivative function
<script type="math/tex">f_x(x,t)</script> is continuous.</p>
<h3 id="theorem-846">Theorem 8.4.6.</h3>
<p>If <script type="math/tex">f(x,t)</script> and <script type="math/tex">f_x(x,t)</script> are continuous on <script type="math/tex">D</script>, then the
function <script type="math/tex">F(x) = \int_{c}^{d} f(x,t) dt</script> is diﬀerentiable and</p>
<p>
<script type="math/tex; mode=display"> 
F'(x) = \int_{c}^{d} f_x(x,t) dt.
</script>
</p>
<p><strong>Proof</strong>. Fix <script type="math/tex">x</script> in <script type="math/tex">[a,b]</script> and let <script type="math/tex">ϵ > 0</script> be arbitrary.
Our task is to find a <script type="math/tex">δ > 0</script> such that</p>
<p>
<script type="math/tex; mode=display">
\tag{5}
\left| 
\frac{F(z) - F(x)}{z-x}
-
\int_{c}^{d} f_x(x,t)dt
 \right| < \epsilon
</script>
</p>
<p>whenever <script type="math/tex">0 < |z-x| < \delta</script>.</p>
<h3 id="exercise-8414">Exercise 8.4.14.</h3>
<p>Finish the proof of Theorem 8.4.6</p>
<p><strong>Proof</strong>:</p>
<p>Because</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
\frac{F(z) - F(x)}{z-x}
-
\int_{c}^{d} f_x(x,t)dt
 \right| \\
=
\left| 
\frac{\int_{c}^{d} f(z,t) - \int_{c}^{d} f(x,t)}{z-x}
- f_x(x,t)
 \right| \\
=
\left| 
\int_{c}^{d}
\frac{f(z,t) - f(x,t)}{z-x} - f_x(x,t)
 \right| \\
 \leq
\int_{c}^{d}
\left| 
\frac{f(z,t) - f(x,t)}{z-x} - f_x(x,t)
\right| <
\frac{\epsilon}{d-c}(d-c) = \epsilon
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="improper-integrals-revisited">Improper Integrals, Revisited</h3>
<p>Theorem 8.4.6 is a formal justification for diﬀerentiating under 
the integral sign,
but we need to extend this result to the case where the integral 
is improper.
Looking back one more time to our motivating example in equation 
(3), we see
that what we have is a function <script type="math/tex">f(x,t)</script> where the domain of the 
variable <script type="math/tex">t</script> is the
unbounded interval <script type="math/tex">c ≤ t < ∞</script>.</p>
<p>Let’s fix <script type="math/tex">x</script> from some set <script type="math/tex">A ⊆ R</script>. For such an <script type="math/tex">x</script>, we define</p>
<p>
<script type="math/tex; mode=display"> 
\tag{6}
F(x) = \int_{c}^{\infty} f(x,t)dt =
\lim_{d \to \infty} \int_{c}^{d} f(x,t)dt,
</script>
</p>
<p>provided the limit exists.</p>
<p>As we have seen on numerous occasions, the elixir required
to ensure that good behavior in the finite setting extends to
the infinite setting is uniformity.</p>
<h3 id="definition-847">Definition 8.4.7.</h3>
<p>Given <script type="math/tex">f(x,t)</script> defined on <script type="math/tex">D= \{(x,t) : x ∈ A,c ≤ t\}</script>, assume
<script type="math/tex">F(x) = \int_{c}^{\infty}f(x,t)dt</script> exists for all <script type="math/tex">x ∈ A</script>.
We say the improper integral converges
uniformly to <script type="math/tex">F(x)</script> on <script type="math/tex">A</script> if for all <script type="math/tex">ϵ > 0</script>, there exists
<script type="math/tex">M > c</script> such that</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
F(x) - \int_{c}^{d} f(x,t) dt
 \right| < \epsilon 
</script>
</p>
<p>for all <script type="math/tex">d ≥ M</script> and all <script type="math/tex">x ∈ A</script>.</p>
<h3 id="exercise-8415">Exercise 8.4.15.</h3>
<p>(a) Show that the improper integral
<script type="math/tex">\int_{0}^{\infty} e^{-xt} dt</script> converges
uniformly to <script type="math/tex">1/x</script> on the set <script type="math/tex">[1/2,∞)</script>.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{b} e^{-xt} dt =
1 - \frac{1}{x} e^{-xb} \geq 1 - 2 e ^{-b/2}
</script>
</p>
<p>It does not depend on <script type="math/tex">x</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Is the convergence uniform on <script type="math/tex">(0,∞)</script>?</p>
<p><strong>Solution</strong>: No. For any fixed <script type="math/tex">x</script>,
<script type="math/tex">\int_{0}^{\infty} e^{-xt} dt = 1</script>, but give any <script type="math/tex">b</script>,
let <script type="math/tex">x = 1/b</script>
</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{b} e^{-xt} dt = 1 - b/e
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-8416">Exercise 8.4.16.</h3>
<p>Prove the following analogue of the Weierstrass M-Test for
improper integrals: If <script type="math/tex">f(x,t)</script> satisfies <script type="math/tex">|f(x,t)| ≤ g(t)</script>
for all <script type="math/tex">x ∈ A</script> and <script type="math/tex">\int_{a}^{\infty} g(t)dt</script> converges, then
<script type="math/tex">\int_{a}^{\infty} f(x,t)dt</script> converges uniformly on <script type="math/tex">A</script>.</p>
<p><strong>Proof</strong>:</p>
<p>Given <script type="math/tex">\epsilon</script>, since <script type="math/tex">\int_{a}^{\infty} g(t)dt</script> converges,
we can find <script type="math/tex">M</script>, if <script type="math/tex">d > c \geq M</script>, we have
<script type="math/tex">|\int_{c}^{d} g(t) dt | = \int_{c}^{d} |g(t)| dt < \epsilon / 2</script>.</p>
<p>Then</p>
<p>
<script type="math/tex; mode=display"> 
\left| \int_{c}^{d} f(x,t) dt \right|  \leq
\int_{c}^{d} |f(x,t)| dt \leq
\int_{c}^{d} g(t) dt < \epsilon / 2
</script>
</p>
<p>Then given any <script type="math/tex">x_0</script>, we can find <script type="math/tex">d_{x_0}</script>, such that</p>
<p>
<script type="math/tex; mode=display"> 
\left| \int_{a}^{d_{x_0}} f(x_0, t) dt - F(x_0)
 \right| < \epsilon / 2
</script>
</p>
<p>Then</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
\int_{a}^{c} f(x_0, t) dt - F(x_0)
 \right| \leq 
\left| 
\int_{a}^{c} f(x_0, t) dt - \int_{a}^{d_{x_0}} f(x_0, t) dt
 \right| +
\left| 
\int_{a}^{d_{x_0}} f(x_0, t) dt - F(x_0)
 \right| \\
\leq \epsilon / 2 + \epsilon / 2 = \epsilon 
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>An immediate consequence of Definition 8.4.7 is that if the 
improper integral
converges uniformly then the sequence of functions defined by</p>
<p>
<script type="math/tex; mode=display"> 
F_n(x) = \int_{c}^{c+n} f(x,t) dt
</script>
</p>
<p>converges uniformly to <script type="math/tex">F(x)</script> on <script type="math/tex">[a,b]</script>. This observation gives us access to the
host of useful results we developed in Chapter 6.</p>
<h3 id="theorem-848">Theorem 8.4.8.</h3>
<p>If <script type="math/tex">f(x,t)</script> is continuous on <script type="math/tex">D= \{(x,t) : a ≤ x ≤ b,c ≤ t\}</script>,
then</p>
<p>
<script type="math/tex; mode=display"> 
F(x) = \int_{c}^{\infty} f(x,t)dt
</script>
</p>
<p>is uniformly continuous on <script type="math/tex">[a,b]</script>, provided the integral converges uniformly.</p>
<p><strong>Proof</strong>:</p>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
F_n(x) = \int_{c}^{c+n} f(x,t) dt
</script>
</p>
<p>From theorem 8.4.5., then <script type="math/tex">F_n(x)</script> is continuous.
Since the integral converges uniformly, then <script type="math/tex">F_n(x)</script> converges
to <script type="math/tex">F(x)</script> uniformly.
Then according to theorem 6.2.6, <script type="math/tex">F(x)</script> is continuous.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="theorem-849">Theorem 8.4.9.</h3>
<p>Assume the function <script type="math/tex">f(x,t)</script> is continuous on
<script type="math/tex">D= \{(x,t) : a ≤ x ≤ b,c ≤ t\}</script> and
<script type="math/tex">F(x) = \int_{c}^{\infty} f(x,t)dt</script> exists for each <script type="math/tex">x ∈ [a,b]</script>.
If the derivative function
<script type="math/tex">f_x(x,t)</script> exists and is continuous, then</p>
<p>
<script type="math/tex; mode=display"> 
\tag{7}
F'(x) =
\int_{c}^{\infty} f_x(x,t) dt,
</script>
</p>
<p>provided the integral in (7) converges uniformly.</p>
<h3 id="exercise-8418">Exercise 8.4.18.</h3>
<p>Prove Theorem 8.4.9.</p>
<p><strong>Proof</strong>:</p>
<p>Let <script type="math/tex">G(x) = \int_{c}^{\infty} f_x(x,t) dt</script>.</p>
<p>Again, consider</p>
<p>
<script type="math/tex; mode=display"> 
F_n(x) = \int_{c}^{c+n} f(x,t) dt \text{ and }
G_n(x) = \int_{c}^{c+n} f_x(x,t) dt
</script>
</p>
<p>And let <script type="math/tex">D_n = \{(x,t) : a ≤ x ≤ b,c ≤ t ≤ c+n\}</script>.</p>
<p>Since <script type="math/tex">f(x,t)</script> and <script type="math/tex">f_x(x,t)</script> are continuous on <script type="math/tex">D_n</script>, then from theorem 8.4.6, <script type="math/tex">F_n'(x) = G_n(x)</script>.</p>
<p>Since <script type="math/tex">F_n(x)</script> converges to <script type="math/tex">F(x)</script> and <script type="math/tex">G_n(x)</script> converges
uniformly to <script type="math/tex">G(x)</script>, then from theorem 6.3.1,
<script type="math/tex">F(x)</script> is differentiable and <script type="math/tex">F'(x) = G(x)</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="the-factorial-function">The Factorial Function</h3>
<p>It’s time to return our attention to equation (3) from earlier in this section:</p>
<p>
<script type="math/tex; mode=display"> 
\frac{1}{\alpha }
= \int_{0}^{\infty}e^{-\alpha t} dt,
\text{ for all } \alpha > 0.
</script>
</p>
<h3 id="exercise-8419">Exercise 8.4.19.</h3>
<p>(a) Although we verified it directly, show how to use the
theorems in this section to give a second justification for the formula</p>
<p>
<script type="math/tex; mode=display"> 
\frac{1}{\alpha ^2} =
\int_{0}^{\infty} t e^{-\alpha t} dt,
\text{ for all } \alpha > 0.
</script>
</p>
<p><strong>Proof</strong>: Consider <script type="math/tex">f(x,t) = e^{-xt}</script>, and
<script type="math/tex">D = \{(x,t) : 1/2 ≤ x ≤ 3/2, 0 ≤ t\}</script>.</p>
<p>
<script type="math/tex; mode=display"> 
f_x(x,t) = -t e^{-xt}
</script>
</p>
<p>is also continuous on <script type="math/tex">D</script>.</p>
<p>$$
\int_{0}^{b} t e^{-x t} =
\int_{0}^{b} k(t) h'(t) =
h(b) k(b) - h(0) k(0) - \int_{0}^{b} k'(t) h(t) = \
- \frac{1}{x } e^{-x b} \cdot b -</p>
<h1 id="int_0b-frac1x-e-x-t-dt">\int_{0}^{b} -\frac{1}{x } e^{-x t} dt \</h1>
<p>\frac{1}{x } \int_{0}^{b} e^{-x t} dt -
\frac{b}{x } e^{-x b} \
=
\frac{1}{x } (\frac{1}{x} -
\frac{1}{x } e^{-x b}) -
\frac{b}{x } e^{-x b} \
= \frac{1}{x^2} - \frac{1}{x^2} e^{-x b} - \frac{b}{x } e^{-x b}
$$</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{\infty} f_x(x, t) dt
</script>
</p>
<p>converges uniformly. We can apply theorem 8.4.9:</p>
<p>
<script type="math/tex; mode=display"> 
-\frac{1}{x^2} = F'(x) = \int_{0}^{\infty} f_x(x,t) dt
= \int_{0}^{\infty} -t e^{-xt} dt
</script>
</p>
<p>So,</p>
<p>
<script type="math/tex; mode=display"> 
\frac{1}{x^2} = \int_{0}^{\infty} t e^{-xt} dt
</script>
</p>
<p>Then we can plug <script type="math/tex">\alpha</script> back.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Now derive the formula</p>
<p>
<script type="math/tex; mode=display"> 
\tag{8}
\frac{n!}{\alpha ^ {n+1}} =
\int_{0}^{\infty}t^n e^{-\alpha t} dt
\text{ for all } \alpha > 0.
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>First, we prove <script type="math/tex">\int_{0}^{\infty}t^n e^{- x t} dt</script> for any
<script type="math/tex">0 < a \leq x \leq b</script>.</p>
<p>
<script type="math/tex; mode=display"> 
\left| t^n e^{- x t} \right|
= t^n e^{- x t} \leq t^n e^{- a t}
</script>
</p>
<p>Since</p>
<p>
<script type="math/tex; mode=display"> 
e^{at} = 1 + (at) + \frac{(at)^2}{2!} + \cdots
+ \frac{(at)^{n+2}}{(n+2)!} + \cdots >
\frac{(at)^{n+2}}{(n+2)!}
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display">
t^n e^{- a t} \leq g(t) = \begin{cases}
    1 &\text{if } 0 \leq t \leq 1\\
    \frac{(n+2)!}{a^{n+2} t^2} &\text{if } t > 1\\
\end{cases} 
</script>
</p>
<p>The improper integral <script type="math/tex">\lim_{t \to \infty} g(t)</script> converges.
So from exercise 8.4.16, <script type="math/tex">\int_{0}^{\infty}t^n e^{- x t} dt</script>
converges uniformly.</p>
<p>We can use induction, assume the improper integral holds</p>
<p>
<script type="math/tex; mode=display">
\frac{(n-1)!}{x^{n}} = \int_{0}^{\infty}
t^{n-1} e^{-xt} dt
</script>
</p>
<p>Then <script type="math/tex">f(x,t)</script> is continuous,
<script type="math/tex">f_x(x,t) = -t^n e^{-xt}</script> continuous and
<script type="math/tex">\int_{0}^{\infty}f_x(x,t) dt</script> converges uniformly.</p>
<p>So we have</p>
<p>
<script type="math/tex; mode=display"> 
\frac{n!}{x^{n+1}} = \int_{0}^{\infty} t^n e^{-xt} dt
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="definition-8410">Definition 8.4.10.</h3>
<p>For <script type="math/tex">x ≥ 0</script>, define the factorial function</p>
<p>
<script type="math/tex; mode=display"> 
x! = \int_{0}^{\infty} t^x e^{-t} dt .
</script>
</p>
<h3 id="exercise-8420">Exercise 8.4.20.</h3>
<p>(a) Show that <script type="math/tex">x!</script> is an infinitely diﬀerentiable function on
<script type="math/tex">(0,∞)</script> and produce a formula for the nth derivative.
In particular show that <script type="math/tex">(x!)'' > 0</script>.</p>
<p><strong>Proof</strong>: Let <script type="math/tex">f(x,t) = t^x e^{-t}</script> . Given <script type="math/tex">x</script>, since <script type="math/tex">t^x</script> and <script type="math/tex">e^{-t}</script> are continuous
functions on <script type="math/tex">[0, c]</script>, so they are integrable.</p>
<p>Also, if <script type="math/tex">0 < a \leq x \leq b</script>, we can find <script type="math/tex">k</script>,
such that <script type="math/tex">0 < 1/k < a \leq x \leq b < k</script>.
then for <script type="math/tex">t > 1</script>,</p>
<p>
<script type="math/tex; mode=display"> 
t^x e^{-t} =
\frac{
    t^x
}{1 + \frac{t}{1!} + \frac{t^2}{2!} + \cdots +
\frac{t^{k+2}}{(k+2)!} + \cdots} \\
< \frac{(k+2)!}{t^2}
</script>
</p>
<p>define <script type="math/tex">g(x)</script> as</p>
<p>
<script type="math/tex; mode=display">
g(t) = \begin{cases}
    1 &\text{if } 0 \leq t \leq 1\\
    \frac{(k+2)!}{t^2} &\text{if } t > 1\\
\end{cases} 
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
|t^x e^{-t}| = t^x e^{-t} \leq g(x)
</script>
</p>
<p>Since the improper integral <script type="math/tex">\lim_{t \to \infty} g(t)</script>
converges, then <script type="math/tex">f(x,t)</script> converges uniformly.</p>
<p>Now, let's consider the nth derivative of <script type="math/tex">f(x,t)</script> w.r.t <script type="math/tex">x</script>:</p>
<p>
<script type="math/tex; mode=display"> 
f_x^{(n)}(x, t) = t^x (\log_{} (t))^n e^{-t}
</script>
</p>
<p>Note that <script type="math/tex">f_x^{(n)}(x, t)</script> is not defined at <script type="math/tex">t = 0</script>.
But we can use L’Hospital’s Rule: ∞/∞ case:</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{t \to 0} \frac{(\log_{} (t))^n}{t^{-x}}
=
\lim_{t \to 0}
\frac{n (\log_{} (t))^{n-1} (1/t)}{(-x)t^{-1-x}} \\
=
\lim_{t \to 0}
\frac{n}{(-x)} \frac{\log_{} (t))^{n-1}}{t^{-x}} \\
\lim_{t \to 0}
= \frac{n!}{(-x)^n} \frac{1}{t^{-x}} = 0
</script>
</p>
<p>Thus we can define <script type="math/tex">f_x^{(n)}(x, 0) = 0</script>.</p>
<p>When <script type="math/tex">x \in [a,b]</script>, and <script type="math/tex">t > 1</script>
</p>
<p>
<script type="math/tex; mode=display"> 
\left| t^x (\log_{} (t))^n e^{-t} \right|
= t^x (\log_{} (t))^n e^{-t} \\
\leq
t^b t^n e^{-t} \leq \frac{C}{t^2}
</script>
</p>
<p>where <script type="math/tex">C</script> is a constant independent of <script type="math/tex">x</script>.
So the improper integral
<script type="math/tex">\int_{0}^{\infty} t^x (\log_{} (t))^n e^{-t}</script>
converges uniformly.</p>
<p>So the nth derivative is</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{\infty} t^x (\log_{} (t))^n e^{-t} dt
</script>
</p>
<p>And the 2nd derivative is</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{\infty} t^x (\log_{} (t))^2 e^{-t} dt
</script>
</p>
<p>For any <script type="math/tex">x > 0</script>, <script type="math/tex">t^x (\log_{} (t))^2 e^{-t} >0</script>,
so <script type="math/tex">(x!)'' > 0</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Use the integration-by-parts formula employed earlier to show 
that <script type="math/tex">x!</script> satisfies the functional equation.</p>
<p>
<script type="math/tex; mode=display"> 
(x+1)! = (x+1)x! 
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
(x+1)! = \int_{0}^{\infty} t^{x+1} e^{-t} dt
</script>
</p>
<p>So let <script type="math/tex">h(t) = \frac{t^{x+1}}{(x+1)}, k(t) = e^{-t}</script>
then</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{b} t^{x} e^{-t} =
\int_{0}^{b} h'(t) k(t) \\
= h(b) k(b) - h(0) k(0) - \int_{0}^{b} h(t) k'(t)
\\ =
\frac{b^{x+1} e^{-b}}{x+1} - 0 +
\int_{0}^{b} \frac{t^{x+1}}{x+1} e^{-t} dt
</script>
</p>
<p>When <script type="math/tex">b \rightarrow \infty</script>, we have</p>
<p>
<script type="math/tex; mode=display"> 
x! = \frac{(x+1)!}{x+1}
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="theorem-8411-bohrmollerup-theorem">Theorem 8.4.11 (Bohr–Mollerup Theorem).</h3>
<p>There is a unique positive
function <script type="math/tex">f</script> defined on <script type="math/tex">x ≥ 0</script> satisfying</p>
<p>(i) <script type="math/tex">f(0) = 1</script>
</p>
<p>(ii) <script type="math/tex">f(x+1) = (x+1)f(x)</script>, and</p>
<p>(iii) <script type="math/tex">\log(f(x))</script> is convex.</p>
<p>Because <script type="math/tex">x!</script> satisfies properties (i), (ii), and (iii), it follows that <script type="math/tex">f(x) = x!</script>.</p>
<p><strong>Proof</strong>: We need one more geometrically plausible fact about convex functions.
If <script type="math/tex">[a,b]</script> and <script type="math/tex">[a',b']</script> are two intervals in the domain of a convex function <script type="math/tex">φ</script>, and
<script type="math/tex">a ≤ a'</script> and <script type="math/tex">b ≤ b'</script>, then the slopes of the chords over these intervals satisfy</p>
<p>
<script type="math/tex; mode=display"> 
\frac{\phi(b)-\phi(a)}{b-a}
\leq
\frac{\phi(b')-\phi(a')}{b'-a'}
</script>
</p>
<p>Because <script type="math/tex">f</script> satisfies properties (i) and (ii) we know <script type="math/tex">f(n) = n!</script> for all <script type="math/tex">n ∈ N</script>.
Now fix <script type="math/tex">n ∈ N</script> and <script type="math/tex">x ∈ (0,1]</script>.</p>
<h3 id="exercise-8421">Exercise 8.4.21.</h3>
<p>(a) Use the convexity of <script type="math/tex">\log(f(x))</script> and the three intervals
<script type="math/tex">[n−1,n]</script>, <script type="math/tex">[n,n+x]</script>, and <script type="math/tex">[n,n+1]</script> to show</p>
<p>
<script type="math/tex; mode=display"> 
x \log_{} (n) \leq
\log_{} (f(n+x)) - \log_{} (n!)
\leq
x \log_{} (n+1)
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
\frac{\log(f(n)) - \log_{} f((n-1))}{1}
\leq
\frac{\log(f(n+x)) - \log_{} f((n))}{x}
\leq
\frac{\log(f(n+1)) - \log_{} f((n))}{1}
</script>
</p>
<p>This is the same as it asks.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Show <script type="math/tex">\log(f(n+x)) = \log(f(x))+\log((x+1)(x+2)···(x+n))</script>
</p>
<p><strong>Proof</strong>:</p>
<p>Since</p>
<p>
<script type="math/tex; mode=display"> 
f(x+n) = (x+n)f(x+n-1)
= (x+n)(x+n-1)f(x+n-2)
\cdots
= (x+n)\cdots (x+1) f(x) 
</script>
</p>
<p>Then with exercise 8.4.6 (c), so we proved.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Now establish that</p>
<p>
<script type="math/tex; mode=display"> 
0 \leq
\log_{} (f(x)) -
\log_{}
\left( 
\frac{n^xn!}{(x+1)(x+2)\cdots (x+n)}
 \right)
\leq
x \log_{} (1+\frac{1}{n})
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>We use (a) - <script type="math/tex">x \log_{} n</script> and get</p>
<p>
<script type="math/tex; mode=display"> 
\log_{} (f(n+x)) - \log_{} (n!) - x\log_{} n =\\
\log_{} f(x) + \log_{} ((x+1)(x+2)\cdots (x+n))
- \log_{} (n!) - x\log_{} n \\
= \log_{} f(x) -
\log_{}
\left( 
\frac{n^xn!}{(x+1)(x+2)\cdots (x+n)}
 \right)
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(d) Conclude that</p>
<p>
<script type="math/tex; mode=display">
f(x) = \lim_{n \to \infty} 
\frac{n^xn!}{(x+1)(x+2)\cdots (x+n)}
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>This is because</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{n \to \infty} x \log_{} (1 + \frac{1}{n}) = 0
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(e) Finally, show that the conclusion in (d) holds for all
<script type="math/tex">x ≥ 0</script>.</p>
<p><strong>Proof</strong>:</p>
<p>Assume <script type="math/tex">x \in (1, 2]</script> then <script type="math/tex">x = 1 + x_0</script>, <script type="math/tex">x_0 \in (0,1]</script>.</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = f(x_0+1)
= (x_0+1) f(x_0) \\
= (x_0+1)
\lim_{n \to \infty} 
\frac{n^{x_0}n!}{(x_0+1)(x_0+2)\cdots (x_0+n)} \\
=
\lim_{n \to \infty} 
\frac{n^{x_0+1}(n-1)!}{(x_0+2)(x_0+3)\cdots (x_0+n)} \\
=
\lim_{n \to \infty} 
\frac{n^{x}(n-1)!}{(x+1)(x+2)\cdots (x+(n-1))} \\
=
\lim_{n \to \infty} 
\frac{n^{x}n!}{(x+1)(x+2)\cdots (x+n)} \\
</script>
</p>
<p>Then we can use induction for all <script type="math/tex">x > 0</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>Because we have arrived at an explicit formula for <script type="math/tex">f(x)</script>, the function <script type="math/tex">f(x)</script>
must be unique. By virtue of the fact that <script type="math/tex">x!</script> satisfies conditions (i), (ii), and(iii)
of the theorem, we can conclude that <script type="math/tex">x!</script> is this unique function; i.e., <script type="math/tex">f(x) = x!</script>.
Thus, not only have we proved the theorem, but we have also discovered analternate representation for the factorial function called the Gauss product formula:</p>
<p>
<script type="math/tex; mode=display"> 
\tag{9}
x! = \int_{0}^{\infty} t^x e^{-t} dt =
\lim_{n \to \infty} 
\frac{n^{x}n!}{(x+1)(x+2)\cdots (x+n)}
</script>
</p>
<p>For all <script type="math/tex">x \geq 0</script>.</p>
<p>Recall that when <script type="math/tex">x!</script> is extended to all of <script type="math/tex">\mathbf{R}</script> via the functional equation
<script type="math/tex">x! = x(x− 1)!</script> we get asymptotes at every negative integer. Thus, there is a
compelling reason to consider the reciprocal function <script type="math/tex">1/x!</script> which we can take to
be zero for <script type="math/tex">x =−1,−2,−3,...</script>.</p>
<h3 id="exercise-8422">Exercise 8.4.22.</h3>
<p>(a) Where does
<script type="math/tex">g(x) = \frac{x}{x!(−x)!}</script> equal zero? What other
familiar function has the same set of roots?</p>
<p><strong>Solution</strong>: <script type="math/tex">g(x) = 0</script> for every integer.
<script type="math/tex">\sin \pi x</script> also has the same set of roots.</p>
<p>(b) The function <script type="math/tex">e^{−x^2}</script> provides the raw material for the all-important Gaussian bell curve from probability, where it is known that</p>
<p>
<script type="math/tex; mode=display"> 
\int_{-\infty}^{\infty} e^{−x^2} dx = \sqrt[]{\pi}
</script>
</p>
<p>Use this fact (and some standard integration techniques) to evaluate <script type="math/tex">(1/2)!</script>.</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
(1/2)! = \int_{0}^{\infty} t^{1/2} e^{-t} dt
</script>
</p>
<p>Consider the integral</p>
<p>
<script type="math/tex; mode=display"> 
\int_{0}^{b^2} t^{1/2} e^{-t} dt
</script>
</p>
<p>We apply 7.5.10 Change-of-variable Formula and let <script type="math/tex">g(x) = x^2</script>.
So</p>
<p>
<script type="math/tex; mode=display">
\int_{0}^{b} f(g(x)) g'(x) dx =
\int_{0}^{b} (x^2)^{1/2} e^{-x^2} 2x dx \\
= \int_{0}^{b} 2x^2e^{-x^2} dx \\
= \int_{-b}^{b} x^2e^{-x^2} dx
</script>
</p>
<p>Let <script type="math/tex">h(x) = - \frac{1}{2} e^{-x^2}, k(x) = x</script>, then</p>
<p>
<script type="math/tex; mode=display"> 
\int_{-b}^{b} x^2e^{-x^2} =
\int_{-b}^{b} h'(x) k(x) \\
= h(b)k(b) - h(-b)k(-b) - \int_{-b}^{b} (- \frac{1}{2} e^{-x^2}) dx \\
= (-e^{-b^2} \cdot (b)) - (-e^{-b^2} \cdot (-b)) +
\int_{-b}^{b} \frac{1}{2} e^{-x^2} dx
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{b \to \infty} \int_{0}^{b^2} t^{1/2} e^{-t} dt \\
= \lim_{b \to \infty} \int_{-b}^{b} e^{-x^2} dx \\
= \frac{1}{2} \sqrt[]{\pi}
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Now use (a) and (b) to conjecture a striking relationship between the
factorial function and a well-known function from trigonometry.</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
(1/2)! = 1/2 \cdot (-1/2)! \\
(-1/2)! = 2 \cdot (1/2)!
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
g(1/2) = \frac{1/2}{(1/2)! \cdot 2 \cdot (1/2)!} \\
= \frac{1}{\pi}
</script>
</p>
<p>So my conjecture is</p>
<p>
<script type="math/tex; mode=display"> 
\frac{x}{x!(−x)!} = \frac{1}{\pi} \sin (\pi x)
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-8423">Exercise 8.4.23.</h3>
<p>As a parting shot, use the value for <script type="math/tex">(1/2)!</script> and the Gauss
product formula in equation (9) to derive the famous product formula for <script type="math/tex">π</script>
discovered by John Wallis in the 1650s</p>
<p>
<script type="math/tex; mode=display"> 
\frac{\pi }{2}
=\lim_{n \to \infty}
\left( \frac{2 \cdot 2}{1 \cdot 3} \right) 
\left( \frac{4 \cdot 4}{3 \cdot 5} \right) 
\left( \frac{6 \cdot 6}{5 \cdot 7} \right) 
\cdots 
\left( \frac{2n \cdot 2n}{(2n - 1) \cdot (2n + 1)} \right) 
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
x! =
\lim_{n \to \infty} 
\frac{n^{x}n!}{(x+1)(x+2)\cdots (x+n)}
</script>
</p>
<p>We plug <script type="math/tex">x = 1/2</script>, and take square on both side. Then we have</p>
<p>
<script type="math/tex; mode=display">
\frac{\pi}{2} =
\lim_{n \to \infty}
\left( \frac{2 \cdot 2}{1 \cdot 3} \right) 
\left( \frac{4 \cdot 4}{3 \cdot 5} \right) 
\left( \frac{6 \cdot 6}{5 \cdot 7} \right) 
\cdots 
\left( \frac{2n \cdot 2n}{(2n - 1) \cdot (2n + 1)} \right)
\cdot
\frac{2n}{2n+1} \\
=
\lim_{n \to \infty}
\left( \frac{2 \cdot 2}{1 \cdot 3} \right) 
\left( \frac{4 \cdot 4}{3 \cdot 5} \right) 
\left( \frac{6 \cdot 6}{5 \cdot 7} \right) 
\cdots
\lim_{n \to \infty}
\frac{2n}{2n+1} \\
=
\lim_{n \to \infty}
\left( \frac{2 \cdot 2}{1 \cdot 3} \right) 
\left( \frac{4 \cdot 4}{3 \cdot 5} \right) 
\left( \frac{6 \cdot 6}{5 \cdot 7} \right)
\cdots 
\left( \frac{2n \cdot 2n}{(2n - 1) \cdot (2n + 1)} \right)
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h2 id="85-fourier-series">8.5 Fourier Series</h2>
<h3 id="trigonometric-series">Trigonometric Series</h3>
<p>A trigonometric series has the form</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = a_0 +
a_1 \cos (x) + b_1 \sin (x) +
a_2 \cos (2x) + b_2 \sin (2x) +
a_3 \cos (3x) + b_3 \sin (3x) + \cdots \\
= a_0 + \sum_{n = 1}^{\infty} a_n \cos (nx) + b_n \sin (nx)
</script>
</p>
<p>The idea ofrepresenting a function in this way was not completely new when
Fourier first publicly proposed it in 1807. About 50 years earlier, Jean Le Rond
d’Alembert (1717–1783) published the partial diﬀerential equation</p>
<p>
<script type="math/tex; mode=display"> 
\tag{1}
\frac{\partial ^2 u}{\partial x^2}
=
\frac{\partial ^2 u}{\partial t^2}
</script>
</p>
<p>as a means of describing the motion of a vibrating string. In this model, the
function <script type="math/tex">u(x,t)</script> represents the displacement of the string at time <script type="math/tex">t ≥ 0</script> and at
some point <script type="math/tex">x</script>, which we will take to be in the interval <script type="math/tex">[0,π]</script>. Because the string
is understood to be attached at each end of this interval, we have</p>
<p>
<script type="math/tex; mode=display"> 
\tag{2}
u(0,t) = 0 \text{ and } u(\pi, t) = 0
</script>
</p>
<p>for all values of <script type="math/tex">t ≥ 0</script>. Now, at <script type="math/tex">t = 0</script>, the string is 
displaced some initial amount,
and at the moment it is released we assume</p>
<p>
<script type="math/tex; mode=display"> 
\tag{3}
\frac{\partial u}{\partial t} (x, 0) = 0
</script>
</p>
<p>meaning that, although the string immediately starts to move, it is given no
initial velocity at any point. Finding a function <script type="math/tex">u(x,t)</script> that satisfies equations (1), (2), and (3) is not too diﬃcult.</p>
<h3 id="exercise-851">Exercise 8.5.1.</h3>
<p>(a) Verify that</p>
<p>
<script type="math/tex; mode=display"> 
u(x,t) = b_n \sin (nx) \cos (nt)
</script>
</p>
<p>satisfies equations (1), (2), and (3) for any choice of
<script type="math/tex">n ∈ \mathbf{N}</script> and <script type="math/tex">b_n ∈ \mathbf{R}</script>.
What goes wrong if <script type="math/tex">n \not\in N</script>?</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
\frac{\partial u}{\partial x} =
n b_n \cos (nx) \cos (nt) \\
\frac{\partial^2 u}{\partial x^2} =
-n^2 b_n \sin (nx) \cos (nt)
</script>
</p>
<p>On the other hand</p>
<p>
<script type="math/tex; mode=display"> 
\frac{\partial u}{\partial t} =
-n b_n \sin (nx) \sin (nt) \\
</script>
</p>
<p>
<script type="math/tex; mode=display"> 
\frac{\partial^2 u}{\partial t^2} =
-n^2 b_n \sin (nx) \cos (nt)
</script>
</p>
<p>So (1) holds.</p>
<p>
<script type="math/tex; mode=display"> 
u(0, t) = b_n \sin (n \cdot 0) \cos (nt) = 0 \\
u(\pi, t) = b_n \sin (n \cdot \pi) \cos (nt) = 0 \\
</script>
</p>
<p>So (2) holds.</p>
<p>
<script type="math/tex; mode=display"> 
\frac{\partial u}{\partial t} (x, 0)
= -n b_n \sin (nx) \sin (n \cdot 0)
= 0
</script>
</p>
<p>So (3) holds.</p>
<p>if <script type="math/tex">a \not \in \mathbf{N}</script>
<script type="math/tex; mode=display"> 
u(\pi, t) = b_n \sin (a \cdot \pi) \cos (a \cdot t) \not = 0
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Explain why any finite sum of functions of the form given in 
part (a) would also satisfy (1), (2), and (3).</p>
<p><strong>Proof</strong>: We can do the operation (1), (2), and (3) item by item.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>Now, we come to the truly interesting issue. We have just seen 
that any function of the form</p>
<p>
<script type="math/tex; mode=display">
\tag{4}
u(x,t) = \sum_{n = 1}^{N} b_n \sin (nx) \cos (nt)
</script>
</p>
<p>At time <script type="math/tex">t = 0</script>, we will
assume that the string is given some initial displacement
<script type="math/tex">f(x) = u(x,0)</script>. Setting
<script type="math/tex">t = 0</script> in our family of solutions in (4), the hope is that the initial displacement
function <script type="math/tex">f(x)</script> can be expressed as</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \sum_{n = 1}^{N} b_n \sin (nx)
</script>
</p>
<h3 id="periodic-functions">Periodic Functions</h3>
<p>Fourier arrived at the more general
formulation of the problem, which is to find suitable coeﬃcients
<script type="math/tex">(a_n)</script> and <script type="math/tex">(b_n)</script>
to express a function <script type="math/tex">f(x)</script> as</p>
<p>
<script type="math/tex; mode=display"> 
\tag{6}
f(x) = a_0 + \sum_{n = 1}^{\infty}
a_n \cos (nx) + b_n \sin (nx)
</script>
</p>
<p>We will give primary attention to the interval <script type="math/tex">(−π,π]</script>.</p>
<h3 id="types-of-convergence">Types of Convergence</h3>
<p>Our usual course of action with infinite series is first to define the partial sum</p>
<p>
<script type="math/tex; mode=display">
\tag{7}
S_N(x) = a_0 + \sum_{n = 1}^{N}
a_n \cos (nx) + b_n \sin (nx)
</script>
</p>
<p>To "express <script type="math/tex">f(x)</script> as a trigonometric series" then means finding coeﬃcients <script type="math/tex">(a_n)_{n=0}^{\infty}</script> and <script type="math/tex">(b_n)_{n=0}^{\infty}</script>
so that</p>
<p>
<script type="math/tex; mode=display"> 
\tag{8}
f(x) = \lim_{N \to \infty} S_N(x)
</script>
</p>
<p>The question remainsas to what kind of limit this is.</p>
<ul>
<li>Fourier probably imagined something akin to a pointwise limit.</li>
<li>
<script type="math/tex">L^2</script> convergence:</li>
</ul>
<p>
<script type="math/tex; mode=display"> 
\int_{-\pi }^{\pi }
|S_N(x) - f(x)|^2 dx \rightarrow 0
</script>
</p>
<ul>
<li>Cesaro mean convergence, relies on demonstrating that the
averages of the partial sums converge, in our case uniformly, to
<script type="math/tex">f(x)</script>.</li>
</ul>
<h3 id="fourier-coefficients">Fourier Coeﬃcients</h3>
<p>Exercise 8.5.2. Using trigonometric identities when necessary, verify the following integrals.</p>
<p>(a) For all <script type="math/tex">n \in \mathbf{N}</script>,</p>
<p>
<script type="math/tex; mode=display"> 
\int_{-\pi }^{\pi }
\cos (nx) = 0
\text{ and }
\int_{-\pi }^{\pi }
\sin (nx) = 0
</script>
</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
F(x) = \frac{1}{n} \sin (nx)
</script>
</p>
<p>Then <script type="math/tex">F'(x) = \cos (nx)</script>
</p>
<p>
<script type="math/tex; mode=display"> 
F(\pi) - F(-\pi ) = 0 - 0 = 0
</script>
</p>
<p>Similarly, <script type="math/tex">F(x) = \frac{1}{n} \cos (nx)</script>,
then <script type="math/tex">F'(x) = \sin (nx)</script>
</p>
<p>
<script type="math/tex; mode=display">
F(\pi) - F(-\pi ) = \frac{1}{n} ( \cos (n \pi ) - \cos (-n \pi) )
= 0
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) For all <script type="math/tex">n \in \mathbf{N}</script>,</p>
<p>
<script type="math/tex; mode=display"> 
\int_{-\pi }^{\pi }
\cos ^2 (nx) = \pi 
\text{ and }
\int_{-\pi }^{\pi }
\sin ^2 (nx) = \pi 
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
\cos ^2 (nx) =
\frac{1 + \cos (2nx)}{2}
</script>
</p>
<p>
<script type="math/tex; mode=display"> 
\sin ^2 (nx) =
\frac{1 - \cos (2nx)}{2}
</script>
</p>
<p>Then from (a), it's done.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) For all <script type="math/tex">m, n \in \mathbf{N}</script>,</p>
<p>
<script type="math/tex; mode=display"> 
\int_{-\pi }^{\pi }
\cos (mx) \sin (nx) = 0.
</script>
</p>
<p>For <script type="math/tex">m \not = n</script>,</p>
<p>
<script type="math/tex; mode=display"> 
\int_{-\pi }^{\pi }
\cos (mx) \cos (nx) = 0
\text{ and }
\int_{-\pi }^{\pi }
\sin (mx) \sin (nx) = 0
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
\cos (mx) \sin (nx)
=
\frac{\sin ((m+n)x) + \sin ((m-n)x) }{2}
</script>
</p>
<p>Then we can use (a). And similarly for the other 2.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>The consequences of these results are much more interesting than their
proofs. The intuition from inner-product spaces is useful. Interpreting the
integral as a kind of dot product, this exercise can be summarized by saying
that the functions</p>
<p>
<script type="math/tex; mode=display"> 
\{
1,
\cos (x), \sin (x),
\cos (2x), \sin (2x),
\cos (3x), \sin (3x),
\cdots
\}
</script>
</p>
<p>are all orthogonal to each other. The content of what follows is that they in
fact form a basis for a large class of functions.</p>
<p>To compute <script type="math/tex">a_0</script>, integrate each side of equation (6) from
<script type="math/tex">−π</script> to <script type="math/tex">π</script>, brazenly
take the integral inside the infinite sum, and use
Exercise 8.5.2 to get</p>
<p>
<script type="math/tex; mode=display"> 
\int_{-\pi }^{\pi }
f(x)
=
\int_{-\pi }^{\pi }
\left[ 
a_0 + \sum_{n = 1}^{\infty}
a_n \cos (nx) + b_n \sin (nx)
 \right] dx \\
=
\int_{-\pi }^{\pi } a_0 dx +
\sum_{n = 1}^{\infty}
\int_{-\pi }^{\pi }
[a_n \cos (nx) + b_n \sin (nx)] dx \\
= a_0(2 \pi ) +
\sum_{n = 1}^{\infty}
a_n 0 + b_n 0 = a_0(2 \pi )
</script>
</p>
<p>Thus</p>
<p>
<script type="math/tex; mode=display">
\tag{9}
a_0 =
\frac{1}{2 \pi }
\int_{-\pi}^{\pi}
f(x) dx
</script>
</p>
<h3 id="exercise-853">Exercise 8.5.3.</h3>
<p>Derive the formulas</p>
<p>
<script type="math/tex; mode=display"> 
\tag{10}
a_m = \frac{1}{\pi } \int_{-\pi}^{\pi}
f(x) \cos (mx) dx
\text{ and }
b_m =
\frac{1}{\pi }
\int_{-\pi}^{\pi}
f(x) \sin (mx) dx
</script>
</p>
<p>for all <script type="math/tex">m \geq 1</script>.</p>
<p>Proof:</p>
<p>We can directly use exercise 8.5.2 (b) (c).</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="example-851">Example 8.5.1.</h3>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \begin{cases}
    1 &\text{if } 0 < x < \pi \\
    0 &\text{if } x = 0 \text{ or } x = \pi \\
    -1 &\text{if } -\pi < x < 0 \\
\end{cases} 
</script>
</p>
<p>The fact that <script type="math/tex">f</script> is an odd function (i.e., <script type="math/tex">f(−x) =−f(x)</script>) means we can avoid
doing any integrals for the moment and just appeal to a symmetry argument to conclude</p>
<p>
<script type="math/tex; mode=display"> 
a_0 = \frac{1}{2 \pi }
\int_{-\pi}^{\pi}
f(x)dx = 0
</script>
</p>
<p>
<script type="math/tex; mode=display"> 
a_n = \frac{1}{\pi }
\int_{-\pi}^{\pi}
f(x) \cos (nx) dx = 0
</script>
</p>
<p>
<script type="math/tex; mode=display"> 
b_n = \begin{cases}
    4/n \pi  &\text{if } n \text{ is odd}\\
    0 &\text{if } n \text{ is even}\\
\end{cases} 
</script>
</p>
<p>Proceeding on blind faith, we plug these results into equation 
(6) to get the representation</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \frac{4}{\pi }
\sum_{n = 0}^{\infty}
\frac{1}{2n+1} \sin ((2n+1)x)
</script>
</p>
<p>The code to plot it:</p>
<pre><code class="language-python">x = np.linspace(-np.pi, np.pi, 500)
y = np.zeros(x.shape)

# Compute the function values
N = 100
for i in range(1, N, 2):
    y += 4 / (i * np.pi) * np.sin(i * x)

# Plot the function
plt.plot(x, y)
plt.title('Plot of fourier series')
plt.xlabel('x')
plt.ylabel('y')
plt.grid(True)
plt.show()
</code></pre>
<h3 id="exercise-854">Exercise 8.5.4.</h3>
<p>(a) Referring to the previous example, explain why we can
be sure that the convergence of the partial sums to <script type="math/tex">f(x)</script> is not 
uniform on any interval containing 0.</p>
<p><strong>Proof</strong>:</p>
<p>This is because <script type="math/tex">f(x) = 0</script>, and <script type="math/tex">\frac{1}{2n+1} \sin ((2n+1)x)</script>
are all continuous function, so we can find <script type="math/tex">U_{\delta}(0)</script>,
such that <script type="math/tex">S_N(x) < 0.5</script>.
Then <script type="math/tex">|f(x) - S_N(x)| > 0.5</script>. Therefore, the convergence
is not uniform.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Repeat the computations of Example 8.5.1 for the function <script type="math/tex">g(x) = |x|</script> and examine graphs for some partial sums.
This time, make use of the fact that g is even <script type="math/tex">(g(x) = g(−x))</script>
to simplify the calculations. By just looking at the coeﬃcients, 
how do we know this series converges uniformly to something?</p>
<p><strong>Solution</strong>:</p>
<p>This time we can be sure <script type="math/tex">b_n = 0</script>.</p>
<p>
<script type="math/tex; mode=display"> 
a_0 = \frac{1}{2 \pi } \int_{-\pi}^{\pi} |x| dx
= \frac{1}{\pi } \int_{0}^{\pi} x dx \\
= \frac{1}{\pi } \frac{x^2}{2} \Big|_0^{\pi } \\
= \frac{\pi }{2}
</script>
</p>
<p>And</p>
<p>
<script type="math/tex; mode=display"> 
a_n = \frac{1}{\pi } \int_{-\pi}^{\pi}
f(x) \cos (nx) dx \\
=
\frac{2}{\pi } \int_{0}^{\pi}
x \cos (nx) dx \\
=
\frac{2}{\pi }
\left( 
\frac{x \sin (nx)}{n} + \frac{\cos (nx)}{n^2}
 \right) \Big|_0^{\pi }
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
a_n = \begin{cases}
    0 &\text{if } n \text{ is even}\\
    -\frac{4}{n^2 \pi } &\text{if } n \text{ is odd}\\
\end{cases}
</script>
</p>
<p>So, we have</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \frac{\pi }{2} -
\frac{4}{\pi }
\sum_{n = 0}^{\infty} \frac{1}{(2n+1)^2} \cos ((2n+1)x)
</script>
</p>
<p>The code to plot is here:</p>
<pre><code class="language-python"># Exercise 8.5.4 (b)
x = np.linspace(-np.pi, np.pi, 500)
y = np.zeros(x.shape) + (np.pi / 2)

# Compute the function values
N = 100
for i in range(0, N):
    y += -4 / (((2*i+1)**2) * np.pi) * np.cos((2*i+1) * x)

# Plot the function
plt.plot(x, y)
plt.title('Plot of fourier series')
plt.xlabel('x')
plt.ylabel('y')
plt.grid(True)
plt.show()
</code></pre>
<p>The coeﬃcients are <script type="math/tex">1/(2n+1)^2</script>, so it converges.
Since it's independent of <script type="math/tex">x</script>, then it converges uniformly.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Use graphs to collect some empirical evidence regarding the 
question of term-by-term diﬀerentiation in our two examples to 
this point. Is it possible to conclude convergence or divergence 
of either diﬀerentiated series by looking at the resulting 
coeﬃcients? Theorem 6.4.3 is about the legitimacy of
term-by-term diﬀerentiation. Can it be applied to either of
these examples?</p>
<p><strong>Proof</strong>:</p>
<p>If we look at the example 8.5.1, the coefficients
are diverge, but from our graph, it does seem to converge.</p>
<p>For exercise 8.5.4 (b), just from the coefficients, we know
it's uniformly converging.</p>
<p>Theorem 6.4.3 cannot be applied here. Since the direvative
is not convergence uniformly.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="the-riemannlebesgue-lemma">The Riemann–Lebesgue Lemma</h3>
<h3 id="theorem-852-riemannlebesgue-lemma">Theorem 8.5.2 (Riemann–Lebesgue Lemma).</h3>
<p>Assume <script type="math/tex">h(x)</script> is continuous on <script type="math/tex">(-\pi, \pi ]</script>. Then</p>
<p>
<script type="math/tex; mode=display"> 
\int_{-\pi}^{\pi} h(x) \sin (nx) dx \rightarrow 0
</script>
</p>
<p>and</p>
<p>
<script type="math/tex; mode=display"> 
\int_{-\pi}^{\pi} h(x) \cos (nx) dx \rightarrow 0
</script>
</p>
<p>as <script type="math/tex">n \rightarrow \infty</script>.</p>
<p><strong>Proof</strong>: Remember that, like all of our functions from here on, we are mentally
extending <script type="math/tex">h</script> to be <script type="math/tex">2π</script>-periodic. Thus, while our attention is generally focused
on the interval <script type="math/tex">(−π,π]</script>, the assumption of continuity is intended to mean that
the periodically extended <script type="math/tex">h</script> is continuous on all of <script type="math/tex">\mathbf{R}</script>. Note that in addition to
continuity on <script type="math/tex">(−π,π]</script>, this amounts to insisting that</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{x \to -\pi ^{+}} h(x) = h(\pi ).
</script>
</p>
<h3 id="exercise-855">Exercise 8.5.5.</h3>
<p>Explain why <script type="math/tex">h</script> is uniformly continuous on <script type="math/tex">\mathbf{R}</script>.</p>
<p><strong>Proof</strong>: <script type="math/tex">h</script> is uniform continuous on <script type="math/tex">[−π,π]</script> and
it is <script type="math/tex">2π</script>-periodic. So it is uniform continuous on <script type="math/tex">\mathbf{R}</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>Given <script type="math/tex">ϵ > 0</script>, choose <script type="math/tex">δ > 0</script> such that <script type="math/tex">|x−y| < δ</script> implies
<script type="math/tex">|h(x)−h(y)| < ϵ/2</script>.
The period of <script type="math/tex">\sin(nx)</script> is <script type="math/tex">2π/n</script>, so choose <script type="math/tex">N</script> large enough
so that <script type="math/tex">2π/n < δ</script> whenever
<script type="math/tex">n ≥ N</script>.
Now, consider a particular interval <script type="math/tex">[a,b]</script> of length
<script type="math/tex">2π/n</script> over which <script type="math/tex">\sin(nx)</script> moves through one complete 
oscillation.</p>
<h3 id="exercise-856">Exercise 8.5.6.</h3>
<p>Show that</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
\int_{a}^{b}
h(x) \sin(nx)dx
\right| 
< ϵ/n
</script>
</p>
<p>and use this fact to complete the proof.</p>
<p><strong>Proof</strong>: To simplify the discussion, let's first assume</p>
<p>
<script type="math/tex; mode=display"> 
a = \frac{2k \pi }{n} \\
c = \frac{(2k + 1) \pi }{n} \\
b = \frac{(2k + 2) \pi }{n}
</script>
</p>
<p>Assume</p>
<p>
<script type="math/tex; mode=display">
A \leq h(x) \leq B, x \in [a,c] \\
D \leq h(x) \leq C, x \in [c,d] \\
</script>
</p>
<p>
<script type="math/tex; mode=display"> 
\int_{a}^{c} h(x) \sin (nx) \geq A \int_{a}^{c} \sin (nx)
= A \frac{- \cos (nx)}{n} \Bigg|_a^c = \frac{2A}{n}
</script>
</p>
<p>For the same reason, <script type="math/tex">\int_{a}^{c} h(x) \sin (nx) \leq \frac{2B}{n}</script>.</p>
<p>Similarly</p>
<p>
<script type="math/tex; mode=display"> 
-\frac{2C}{n} \leq \int_{c}^{b} h(x) \sin (nx)
\leq -\frac{2D}{n}
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\frac{2(A-C)}{n} \leq
\int_{a}^{b} h(x) \sin (nx)
\leq
\frac{2(B-D)}{n}
</script>
</p>
<p>Then we have</p>
<p>
<script type="math/tex; mode=display"> 
\left| \frac{2(A-C)}{n} \right| <
\frac{2 \epsilon / 2}{n} = \frac{\epsilon }{n}
</script>
</p>
<p>For the same reason
<script type="math/tex">\left| \frac{2(B-D)}{n} \right| < \epsilon / n</script>.</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
\int_{a}^{b} h(x) \sin (nx)
\right| < \epsilon / n
</script>
</p>
<p>There are <script type="math/tex">n</script> segments with length of <script type="math/tex">\frac{2 \pi }{n}</script>
between <script type="math/tex">[-\pi , \pi]</script>. So we proved theorem 8.5.2.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="a-pointwise-convergence-proof">A Pointwise Convergence Proof</h3>
<p>Note that the coeﬃcients of the Fourier series are</p>
<p>
<script type="math/tex; mode=display">
a_0 =
\frac{1}{2 \pi }
\int_{-\pi}^{\pi}
f(x) dx
</script>
</p>
<p>
<script type="math/tex; mode=display"> 
a_m = \frac{1}{\pi } \int_{-\pi}^{\pi}
f(x) \cos (mx) dx
\text{ and }
b_m =
\frac{1}{\pi }
\int_{-\pi}^{\pi}
f(x) \sin (mx) dx
</script>
</p>
<p>So it requires that our function be integrable.
The natural question to ask now is whether Riemann integrability 
is enough or whether we need to make some additional assumptions 
about <script type="math/tex">f</script> in order to guarantee that the Fourier series converges 
back to <script type="math/tex">f</script>. The answer depends on
the type of convergence we hope to establish.</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = a_0 + \sum_{n = 1}^{\infty}
a_n \cos (nx) + b_n \sin (nx)
</script>
</p>
<p>The <script type="math/tex">f</script> can have the following properties:
* bounded
* integrable
* continuous
* differentiable
* <script type="math/tex">f'</script> continuous</p>
<p>The type of convergence can be:
* pointwise
* uniform
* <script type="math/tex">L^2</script>
* Cesaro mean</p>
<h3 id="theorem-853">Theorem 8.5.3.</h3>
<p>Let <script type="math/tex">f(x)</script> be continuous on <script type="math/tex">(−π,π]</script>, and let <script type="math/tex">S_N(x)</script> be the
Nth partial sum of the Fourier series described in equation (7), 
where the coeﬃcients <script type="math/tex">(a_n)</script> and <script type="math/tex">(b_n)</script> are given by equations 
(9) and (10). It follows that</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{N \to \infty} S_N(x) = f(x)
</script>
</p>
<p>pointwise at any <script type="math/tex">x ∈ (−π,π]</script> where <script type="math/tex">f'(x)</script> exists.</p>
<p><strong>Proof</strong>:</p>
<p>Cataloging a few preliminary facts makes for a smoother
argument.</p>
<p>Fact 1: trigonometric identities</p>
<p>
<script type="math/tex; mode=display"> 
\cos(α−θ) = \cos(α)\cos(θ)+\sin(α)\sin(θ) \\
\sin(α+θ) = \sin(α)\cos(θ)+\cos(α)\sin(θ) \\
</script>
</p>
<p>Fact 2: Dirichlet kernel</p>
<p>
<script type="math/tex; mode=display"> 
\frac{1}{2} + \cos(θ) + \cos(2θ) + \cos(3θ) +··· + \cos(Nθ)
=
\frac{\sin((N +1/2)θ)}{2\sin(θ/2)}
\text{ for } θ \not = 2n \pi
</script>
</p>
<p>One proof from <a href="https://en.wikipedia.org/wiki/Dirichlet_kernel#Alternative_proof_of_the_trigonometric_identity">wikipedia</a></p>
<p>Note that</p>
<p>
<script type="math/tex; mode=display"> 
2 \sin(θ/2) \cos(nθ) =
\sin \frac{n + 1/2}{2} θ -
\sin \frac{n - 1/2}{2} θ
</script>
</p>
<p>Then multiply each side by <script type="math/tex">2 \sin(θ/2)</script>, then the equation holds.</p>
<p>Furthermore, notice</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{\theta \to 0} 
\frac{\sin((N +1/2)θ)}{2\sin(θ/2)}
=
\frac{N +1/2}{2 \cdot 1/2}
\lim_{\theta \to 0}
\frac{\cos ((N +1/2)θ)}{\cos (θ/2)}
= N + 1/2 \\
=
\frac{1}{2} + \cos(0) + \cos(2 \cdot 0) + \cos(3 \cdot 0) +··· + \cos(N \cdot 0)
</script>
</p>
<p>Fact 3: Setting</p>
<p>
<script type="math/tex; mode=display"> 
D_N(θ) =
\begin{cases}
    \frac{\sin((N +1/2)θ)}{2\sin(θ/2)}, &\text{if } \theta \not = 2n \pi \\
    1/2 + N, &\text{if } \theta = 2n \pi \\
\end{cases} 
</script>
</p>
<p>from Fact 2, we see that</p>
<p>
<script type="math/tex; mode=display"> 
\int_{-\pi}^{\pi}
D_N(θ) dθ = \pi
</script>
</p>
<p>Using Fact (1) and (2), we get</p>
<p>
<script type="math/tex; mode=display">
\begin{split}
S_N(x) &= a_0 + \sum_{n = 1}^{N}
a_n \cos (nx) + b_n \sin (nx) \\
&=
\left[ \frac{1}{2 \pi } \int_{-\pi}^{\pi} f(t) dt \right] 
+
\sum_{n = 1}^{N}
\left[ \frac{1}{\pi } \int_{-\pi}^{\pi}f(t) \cos (nt) dt \right]
\cos (nx)
+
\left[ \frac{1}{\pi } \int_{-\pi}^{\pi}f(t) \sin (nt) dt \right]
\sin (nx) \\
&=
\frac{1}{\pi } \int_{-\pi}^{\pi} f(t)
\left[ 
\frac{1}{2}
+ \sum_{n = 1}^{N}
\cos (nt) \cos (nx)
+ 
\sin (nt) \sin (nx)
\right] dt \\
&=
\frac{1}{\pi } \int_{-\pi}^{\pi} f(t)
\left[ 
\frac{1}{2}
+ \sum_{n = 1}^{N} \cos (n(t-x))
\right] dt \\
&=
\frac{1}{\pi } \int_{-\pi}^{\pi} f(t)
D_N(t-x) dt \\
\end{split}
</script>
</p>
<p>Replace <script type="math/tex">u = t-x</script>, we have</p>
<p>
<script type="math/tex; mode=display"> 
\frac{1}{\pi } \int_{-\pi}^{\pi} f(t)
D_N(t-x) dt =
\frac{1}{\pi } \int_{-x-\pi}^{-x+\pi} f(u+x)
D_N(u) du
</script>
</p>
<p>Since <script type="math/tex">f(u), D_N(u)</script> are periodic function with period of
<script type="math/tex">2 \pi</script>,</p>
<p>
<script type="math/tex; mode=display"> 
\frac{1}{\pi } \int_{-x-\pi}^{-x+\pi} f(u+x)
D_N(u) du
=
\frac{1}{\pi } \int_{-\pi}^{\pi} f(u+x)
D_N(u) du
</script>
</p>
<p>By the fact of (3),</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \frac{1}{\pi }
\int_{-\pi}^{\pi}
f(x) D_N(u) du,
</script>
</p>
<p>And then it follows</p>
<p>
<script type="math/tex; mode=display">
\tag{11}
S_N(x) - f(x) =
\frac{1}{\pi } \int_{-\pi}^{\pi}
(f(u+x) - f(x)) D_N(u) du
</script>
</p>
<p>Using Fact 1(b), we can rewrite the Dirichlet kernel as</p>
<p>
<script type="math/tex; mode=display">
\begin{split}
D_N(u) &= \frac{\sin((N +1/2)u)}{2\sin(u/2)}
= \frac{
\sin (Nu) \cos (u/2) + \cos (Nu) \sin (u/2)
}{2\sin(u/2)} \\
&=
\frac{\sin (Nu) \cos (u/2)}{2\sin(u/2)} +
\frac{\cos (Nu)}{2}    
\end{split}
</script>
</p>
<p>Then equation (11) becomes</p>
<p>
<script type="math/tex; mode=display"> 
\begin{split}
S_N(x) - f(x)
&=
\frac{1}{2\pi } \int_{-\pi}^{\pi}
(f(u+x) - f(x))
\left[ 
\frac{\sin (Nu) \cos (u/2)}{\sin(u/2)}
+
\cos (Nu)
\right] du \\
&=
\frac{1}{2\pi } \int_{-\pi}^{\pi}
p_x(u) \sin (Nu) du +
\frac{1}{2\pi } \int_{-\pi}^{\pi}
q_x(u) \cos (Nu) du
\end{split}
</script>
</p>
<p>where in the last step we have set</p>
<p>
<script type="math/tex; mode=display"> 
p_x(u) = \frac{
(f(u+x)-f(x)) \cos (u/2)
}{\sin (u/2)}
\text{ and }
q_x(u) =
f(u+x)-f(x)
</script>
</p>
<h3 id="exercise-857">Exercise 8.5.7.</h3>
<p>(a) First, argue why the integral involving <script type="math/tex">q_x(u)</script> tends to
zero as <script type="math/tex">N → ∞</script>.</p>
<p><strong>Proof</strong>: <script type="math/tex">q_x(u)</script> is a continuous function.
So we directly apply the Riemann–Lebesgue Lemma.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) The first integral is a little more subtle because the 
function <script type="math/tex">p_x(u)</script> has the
<script type="math/tex">\sin(u/2)</script> term in the denominator. Use the fact that <script type="math/tex">f</script> is diﬀerentiable at
<script type="math/tex">x</script> (and a familiar limit from calculus)
to prove that the first integral goes to zero as well.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display">
\lim_{u \to 0} 
\frac{
(f(u+x)-f(x)) \cos (u/2)
}{\sin (u/2)} =\\
\lim_{u \to 0} \frac{f(u+x) - f(x)}{u}
\cdot
\lim_{u \to 0} \frac{u}{\sin (u/2)}
\cdot
\cos (u/2) \\
= 2f'(x)
</script>
</p>
<p>So <script type="math/tex">p_x(u)</script> is also continuous <script type="math/tex">(-\pi, \pi]</script>.
So again we directly apply the Riemann–Lebesgue Lemma.</p>
<h3 id="cesaro-mean-convergence">Cesaro Mean Convergence</h3>
<h3 id="exercise-858">Exercise 8.5.8.</h3>
<p>Prove that if a sequence of real numbers <script type="math/tex">(x_n)</script> converges, then
the arithmetic means</p>
<p>
<script type="math/tex; mode=display"> 
y_n = \frac{x_1 + x_2 + x_3 + \cdots + x_n}{n}
</script>
</p>
<p>also converge to the same limit. Give an example to show that it 
is possible for the sequence of means <script type="math/tex">(y_n)</script> to converge even if 
the original sequence <script type="math/tex">(x_n)</script> does not.</p>
<p><strong>Proof</strong>:</p>
<p>Assume <script type="math/tex">\lim_{n \to \infty} x_n = c</script>, and given <script type="math/tex">\epsilon</script> we
can find a <script type="math/tex">N_1</script> such that <script type="math/tex">|x_n - c| < \epsilon /2</script> for
<script type="math/tex">n > N_1</script>.
For</p>
<p>
<script type="math/tex; mode=display"> 
S_{N_1} = \sum_{n=1}^{N_1} x_1 + x_2 + x_3 + \cdots + x_{N_1}
</script>
</p>
<p>Let <script type="math/tex">A = S_{N_1} - N_1 c</script>, then we can find <script type="math/tex">N_2</script> such that
<script type="math/tex">|A/N_2| < \epsilon / 2</script>.</p>
<p>Let <script type="math/tex">N = \max \{N_1, N_2\}</script>. For <script type="math/tex">n > N</script>,</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
\frac{x_1 + x_2 + x_3 + \cdots + x_n}{n} - c
 \right|
 =
\left| 
\frac{A + (x_{N_1+1}-c) + (x_{N_1 + 2} -c)
+ (x_n - c)}{n}
 \right| \\
<
\frac{A}{N_2} + \frac{n - N_1 + 1}{n} \cdot \epsilon / 2
< \epsilon / 2 + \epsilon / 2 = \epsilon 
</script>
</p>
<p>Consider <script type="math/tex">x_n = (-1)^n</script>, <script type="math/tex">(x_n)</script> does not converge,
but <script type="math/tex">(y_n)</script> does converge.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="theorem-854-fejers-theorem">Theorem 8.5.4 (Fejer’s Theorem).</h3>
<p>Let <script type="math/tex">S_n(x)</script> be the <script type="math/tex">n</script>th partial sum of the
Fourier series for a function f on <script type="math/tex">(−π,π]</script>. Define</p>
<p>
<script type="math/tex; mode=display"> 
σ_N(x) = \frac{1}{N+1} \sum_{n = 0}^{N} S_n(x).
</script>
</p>
<p>If <script type="math/tex">f</script> is continuous on <script type="math/tex">(−π,π]</script>, then <script type="math/tex">σ_N(x) → f(x)</script> uniformly.</p>
<p><strong>Proof</strong>:</p>
<p>We will use the following fact</p>
<p>
<script type="math/tex; mode=display"> 
\sin (1 \theta) + \sin (2 \theta) + \sin (3 \theta) + \cdots + \sin (N \theta) =
\frac{
\sin (\frac{N \theta}{2}) \sin ((N+1) \frac{\theta }{2})
}{\sin ( \frac{\theta}{2} )}
</script>
</p>
<p>Note that</p>
<p>
<script type="math/tex; mode=display"> 
\sin (θ) \sin (\frac{θ}{2}) = \frac{1}{2}
(\cos (θ/2) - \cos (3θ/2))
</script>
</p>
<p>So we get</p>
<p>
<script type="math/tex; mode=display"> 
\cos (θ/2) - \cos ((N+1/2)θ) = - 2
\sin (-\frac{N}{2} θ) \sin (\frac{(N+1)θ}{2})
= \sin (\frac{Nθ}{2}) \sin (\frac{(N+1)θ}{2})
</script>
</p>
<h3 id="exercise-859">Exercise 8.5.9.</h3>
<p>Use the previous identity to show that</p>
<p>
<script type="math/tex; mode=display"> 
\frac{
1/2 + D_1(θ) + D_2(θ) + D_3(θ) + \cdots + D_N(θ)
}{N+1} =
\frac{1}{2(N+1)}
\left[ 
\frac{\sin ((N+1)\frac{θ}{2})}{\sin (\frac{θ}{2})}
 \right] ^ 2
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>Note that</p>
<p>
<script type="math/tex; mode=display"> 
D_N(θ) =
\frac{\sin (Nθ) \cos (θ/2)}{2\sin(θ/2)} +
\frac{\cos (Nθ)}{2}
</script>
</p>
<p>So
<script type="math/tex; mode=display"> 
\begin{split}
1/2 + D_1(θ) + D_2(θ) + D_3(θ) + \cdots + D_N(θ) = \\
1/2(1 + \cos(1 \theta) + \cos(2 \theta) + \cdots + \cos(N \theta)) + \\
\frac{\cos (θ/2)}{2\sin(θ/2)}
(\sin(1 \theta) + \sin(2 \theta) + \cdots + \sin(N \theta))
\\
&= 1/2(1/2 + D_N(θ)) +
\frac{\cos (θ/2)}{2\sin(θ/2)}
\frac{
\sin (\frac{N \theta}{2}) \sin ((N+1) \frac{\theta }{2})
}{\sin ( \frac{\theta}{2} )}
\end{split}
</script>
</p>
<p>Then let's see</p>
<p>
<script type="math/tex; mode=display"> 
\begin{split}
1/2 + D_N(\theta)
\\
&= 1/2 +
\frac{
    \sin ((N+1/2)θ)
}{
    2 \sin(θ/2)
}\\
&=
\frac{
\sin (\frac{(N+1) θ}{2}) \cos (\frac{N θ}{2})
}{\sin (θ/2)}
\end{split}
</script>
</p>
<p>So we have</p>
<p>
<script type="math/tex; mode=display"> 
\begin{split}
1/2 + D_N(\theta) + \frac{\cos (θ/2)}{\sin(θ/2)}
\frac{
\sin (\frac{N \theta}{2}) \sin ((N+1) \frac{\theta }{2})
}{\sin ( \frac{\theta}{2} )}
\\
&= \frac{
\sin (\frac{(N+1) θ}{2}) \cos (\frac{N θ}{2})
}{\sin (θ/2)}
+
\frac{\cos (θ/2)}{\sin(θ/2)}
\frac{
\sin (\frac{N \theta}{2}) \sin ((N+1) \frac{\theta }{2})
}{\sin ( θ/2 )}
\\
&=
\left[ 
\frac{\sin ((N+1)\frac{θ}{2})}{\sin (\frac{θ}{2})}
 \right] ^ 2
\end{split}
</script>
</p>
<p>So we proved it.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-8510">Exercise 8.5.10.</h3>
<p>(a) Show that</p>
<p>
<script type="math/tex; mode=display"> 
σ_N(x) = \frac{1}{\pi }
\int_{-\pi}^{\pi} f(u+x) F_N (u) du
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
S_N(x) = 
\frac{1}{\pi } \int_{-\pi}^{\pi} f(u+x)
D_N(u) du
</script>
</p>
<p>
<script type="math/tex; mode=display"> 
S_0(x) = a_0 = \frac{1}{2 \pi } \int_{-\pi}^{\pi} f(u+x) du
</script>
</p>
<p>So </p>
<p>
<script type="math/tex; mode=display"> 
σ_N(x) = \frac{1}{\pi }
\int_{-\pi}^{\pi} f(u+x) F_N (u) du
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Graph the function <script type="math/tex">F_N(u)</script> for several values of <script type="math/tex">N</script>. Where 
is <script type="math/tex">F_N</script> large, and where is it close to zero? Compare
this function to the Dirichlet kernel <script type="math/tex">D_N(u)</script>.
Now, prove that <script type="math/tex">F_N → 0</script> uniformly on any set of the form
<script type="math/tex">\{u : |u| ≥ δ\}</script>, where <script type="math/tex">δ > 0</script> is fixed (and u is restricted to 
the interval <script type="math/tex">(−π,π]</script>).</p>
<p><strong>Proof</strong>:</p>
<p>The code to plot <script type="math/tex">F_N(u)</script>.</p>
<pre><code class="language-python">x = np.linspace(-np.pi, np.pi, 500)
N = 100
y = 1/(2*(N+1)) * (np.sin((N+1)*x/2) / np.sin(x/2)) ** 2
# Plot the function
plt.plot(x, y)
plt.title('Plot of Fejer kernel')
plt.xlabel('x')
plt.ylabel('y')
plt.grid(True)
plt.show()
</code></pre>
<p>It's big when <script type="math/tex">u</script> is close to 0. When it's away from 0,
<script type="math/tex">F_N</script> is close to 0.</p>
<p>The code to plot <script type="math/tex">D_N(u)</script>.</p>
<pre><code class="language-python">x = np.linspace(-np.pi, np.pi, 500)
N = 10
y = np.sin((N+0.5) * x) / (2 * np.sin(x/2))
# Plot the function
plt.plot(x, y)
plt.title('Plot of Dirichlet kernel')
plt.xlabel('x')
plt.ylabel('y')
plt.grid(True)
plt.show()
</code></pre>
<p>We rewrite the Fejer kernel here</p>
<p>
<script type="math/tex; mode=display">
F_N(θ) =
\frac{1}{2(N+1)}
\left[ 
\frac{\sin ((N+1)\frac{θ}{2})}{\sin (\frac{θ}{2})}
 \right] ^ 2
</script>
</p>
<p>Since <script type="math/tex">|u| \geq \delta</script>, then
<script type="math/tex">|\sin (\frac{θ}{2})| \geq \sin (\frac{\delta }{2})</script>,</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
F_N(θ) \leq \frac{1}{2(N+1)} \frac{1}{\sin ^2 (\delta/2)}
</script>
</p>
<p>So we proved.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Prove that <script type="math/tex">\int_{-\pi}^{\pi} F_N(u)du = \pi</script>
</p>
<p><strong>Proof</strong>:</p>
<p>Note that <script type="math/tex">\int_{-\pi}^{\pi} D_n(θ) dθ = \pi</script>, so</p>
<p>
<script type="math/tex; mode=display">
\int_{-\pi}^{\pi}
1/2 + D_1(θ) + D_2(θ) + D_3(θ) + \cdots + D_N(θ)
= (N+1) \pi 
</script>
</p>
<p>So <script type="math/tex">\int_{-\pi}^{\pi} F_N(u)du = \pi</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(d) To finish the proof of Fejer’s Theorem, first choose a
<script type="math/tex">δ > 0</script> so the</p>
<p>
<script type="math/tex; mode=display"> 
|u| < \delta \text{ implies } |f(x+u) - f(x)| < \epsilon
</script>
</p>
<p>Set up a single integral that represents the diﬀerence
<script type="math/tex">σ_N(x)− f(x)</script> and divide this integral into sets where
<script type="math/tex">|u| ≤ δ</script> and <script type="math/tex">|u| ≥ δ</script>. Explain why it is
possible to make each of these integrals suﬃciently small, 
independently of the choice of <script type="math/tex">x</script>.</p>
<p><strong>Proof</strong>:</p>
<p>Given <script type="math/tex">\epsilon</script>, since <script type="math/tex">f(x)</script> is continuous, we can find
<script type="math/tex">\delta</script>, for <script type="math/tex">|u| < δ</script>, then <script type="math/tex">|f(x+u) - f(x)| < \epsilon</script>.</p>
<p>Then fix <script type="math/tex">x</script>, we have</p>
<p>
<script type="math/tex; mode=display">
f(x) = \frac{1}{\pi }
\int_{-\pi}^{\pi}
f(x) F_N(u) du
</script>
</p>
<p>Then</p>
<p>
<script type="math/tex; mode=display"> 
σ_N(x)− f(x) =
\frac{1}{\pi }
\int_{-\pi}^{\pi}
(f(x+u) - f(x)) F_N(u) du
</script>
</p>
<p>Consider</p>
<p>
<script type="math/tex; mode=display">
\left|
\int_{-\delta}^{\delta} (f(x+u) - f(x)) F_N(u) du
\right| 
\\
\leq
\int_{-\delta}^{\delta}
|(f(x+u) - f(x)) F_N(u)| du \\
\leq
\int_{-\delta}^{\delta}
\epsilon F_N(u) du < \epsilon \pi
</script>
</p>
<p>Also</p>
<p>
<script type="math/tex; mode=display"> 
\left|
\int_{\delta}^{\pi} (f(x+u) - f(x)) F_N(u) du
\right| \\
\leq
\int_{\delta}^{\pi}
|(f(x+u) - f(x)) F_N(u)| du \\
\leq
2A \epsilon \pi 
</script>
</p>
<p>Same thing holds for <script type="math/tex">[-\pi, -\delta]</script>.</p>
<p>So it is possible to make each of these integrals suﬃciently 
small, independently of the choice of <script type="math/tex">x</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="exercise-8511">Exercise 8.5.11.</h3>
<p>(a) Use the fact that the Taylor series for <script type="math/tex">\sin(x)</script> and
<script type="math/tex">\cos(x)</script> converge uniformly on any compact set to prove WAT 
under the added assumption that <script type="math/tex">[a,b]</script> is <script type="math/tex">[0,π]</script>.</p>
<p><strong>Proof</strong>: For a continuous function <script type="math/tex">f(x)</script> defined on
<script type="math/tex">[0,π]</script>, and given <script type="math/tex">\epsilon</script>, we can find a Fourier partial
sum <script type="math/tex">S_N(x)</script>, such that</p>
<p>
<script type="math/tex; mode=display"> 
|f(x) - σ_N(x) | < \epsilon / 2
</script>
</p>
<p>for <script type="math/tex">[0,π]</script>.</p>
<p>Then for each <script type="math/tex">\sin (nx), \cos (nx)</script>, <script type="math/tex">n = 1, 2, 3, \cdots, N</script>,
It's possible to find a polynomial <script type="math/tex">g_n(x), h_n(x)</script> such that</p>
<p>
<script type="math/tex; mode=display"> 
|\sin (nx) - g_n(x) | < \frac{\epsilon }{2 a_n N}
\text{ and }
|\cos (nx) - h_n(x) | < \frac{\epsilon }{2 b_n N}
</script>
</p>
<p>Then we can find the polynomial.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Show how the case for an arbitrary interval [a,b] follows from this one.</p>
<p><strong>Proof</strong>:</p>
<p>Assume if <script type="math/tex">f(x)</script> is defined on <script type="math/tex">[a,b]</script>, then let
<script type="math/tex">g(u) = f(a + \frac{u}{\pi } (b-a) )</script>, then <script type="math/tex">g(u)</script> is
defined on <script type="math/tex">[0,\pi ]</script>.
Furthermore, <script type="math/tex">f(x) = g(\frac{x-a}{b-a} \pi)</script>.</p>
<p>From (a), we can find a polynomial <script type="math/tex">g_n</script> such that</p>
<p>
<script type="math/tex; mode=display"> 
|g(u) - g_n(u)| < \epsilon
</script>
</p>
<p>Then</p>
<p>
<script type="math/tex; mode=display"> 
|f(x) - g_n(\frac{x-a}{b-a} \pi) | < \epsilon 
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../ch07ex/" class="btn btn-neutral float-left" title="Chapter 07 Exercises"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../ch0802ex/" class="btn btn-neutral float-right" title="Chapter 0802 Exercises">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../ch07ex/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../ch0802ex/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
