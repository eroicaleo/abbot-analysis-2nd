<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Chapter 06 Exercises - Understanding Analysis by Stephen Abbot (2nd Ed)</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Chapter 06 Exercises";
        var mkdocs_page_input_path = "ch06ex.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Understanding Analysis by Stephen Abbot (2nd Ed)
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch03notes/">Chapter 03 Notes</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch03ex/">Chapter 03 Exercises</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch04notes/">Chapter 04 Notes</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch04ex/">Chapter 04 Exercises</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch05notes/">Chapter 05 Notes</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ch05ex/">Chapter 05 Exercises</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">Chapter 06 Exercises</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#62-uniform-convergence-of-a-sequence-of-functions">6.2 Uniform Convergence of a Sequence of Functions</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#621">6.2.1.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#622">6.2.2.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#623">6.2.3.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#624">6.2.4.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#625">6.2.5.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#626">6.2.6.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#627">6.2.7.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#628">6.2.8.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#629">6.2.9.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#6210">6.2.10.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#6211-dinis-theorem">6.2.11 (Dini’s Theorem).</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#6212-cantor-function">6.2.12 (Cantor Function).</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#6213">6.2.13.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#6214">6.2.14.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#6215-arzelaascoli-theorem">6.2.15 (Arzela–Ascoli Theorem).</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#63-uniform-convergence-and-differentiation">6.3. Uniform Convergence and Diﬀerentiation</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#631">6.3.1.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#632">6.3.2.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#633">6.3.3.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#634">6.3.4.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#635">6.3.5.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#637">6.3.7.</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#64-series-of-functions">6.4 Series of Functions</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#641">6.4.1.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#642">6.4.2.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#643">6.4.3.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#644">6.4.4.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#645">6.4.5.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#646">6.4.6.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#647">6.4.7.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#648">6.4.8.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#649">6.4.9.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#6410">6.4.10.</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#65-power-series">6.5. Power Series</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#651">6.5.1</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#652">6.5.2</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#653">6.5.3</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#654-term-by-term-antidifferentiation">6.5.4 (Term-by-term Antidiﬀerentiation).</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#655">6.5.5.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#656">6.5.6.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#657">6.5.7.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#658">6.5.8.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#659">6.5.9.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#6510">6.5.10</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#6511">6.5.11</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#66-taylor-series">6.6. Taylor Series</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#661">6.6.1.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#662">6.6.2.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#663">6.6.3.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#664">6.6.4.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#665">6.6.5.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#666">6.6.6.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#667">6.6.7.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#668">6.6.8.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#669-cauchys-remainder-theorem">6.6.9 (Cauchy’s Remainder Theorem).</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#6610">6.6.10.</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../misc/">Misc info</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../unsolved/">Unsolved Problems</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Understanding Analysis by Stephen Abbot (2nd Ed)</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a> &raquo;</li>
      <li class="breadcrumb-item active">Chapter 06 Exercises</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/eroicaleo/abbot-analysis-2nd/blob/main/docs/ch06ex.md" class="icon icon-github"> Edit on Github</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="chapter-06-sequences-and-series-of-functions">Chapter 06 Sequences and Series of Functions</h1>
<h2 id="62-uniform-convergence-of-a-sequence-of-functions">6.2 Uniform Convergence of a Sequence of Functions</h2>
<h3 id="621">6.2.1.</h3>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
f_n(x) = \frac{nx}{1+ nx^2}
</script>
</p>
<p>Anwser</p>
<p>(a) Find the pointwise limit of <script type="math/tex">(f_n)</script> for all <script type="math/tex">x ∈ (0,∞)</script>.</p>
<p>Solution:</p>
<p>
<script type="math/tex; mode=display"> 
f_n(x) = \frac{nx}{1+ nx^2} \\
= \frac{x}{1/n + x^2}
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \frac{1}{x}
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Is the convergence uniform on <script type="math/tex">(0,∞)</script>
</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
\frac{nx}{1+ nx^2} - \frac{1}{x}\\
=\frac{nx^2-1-nx^2}{x + nx^3} \\
= - \frac{1}{x + nx^3}
</script>
</p>
<p>So the convergence is not uniform.</p>
<p>(c) Is the convergence uniform on <script type="math/tex">(0,1)</script>?</p>
<p><strong>Solution</strong>: No.</p>
<p>(d) Is the convergence uniform on <script type="math/tex">(1,∞)</script>?</p>
<p><strong>Solution</strong>: Yes.</p>
<p>
<script type="math/tex; mode=display"> 
\left| \frac{1}{x + nx^3} \right|
< \left| \frac{1}{1 + n} \right| 
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="622">6.2.2.</h3>
<p>(a) Define a sequence of functions on <script type="math/tex">\mathbf{R}</script> by</p>
<p>
<script type="math/tex; mode=display"> 
f_n(x) =
\begin{cases}
    1 &\text{if } x = 1, 1/2, 1/3, \dots, 1/n \\
    0 &\text{otherwise}\\
\end{cases} 
</script>
</p>
<p>and let <script type="math/tex">f</script> be the pointwise limit of <script type="math/tex">f_n</script>.
Is each <script type="math/tex">f_n</script> continuous at zero? Does <script type="math/tex">f_n → f</script> uniformly on <script type="math/tex">\mathbf{R}</script>? Is <script type="math/tex">f</script> continuous at zero?</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
f(x) =
\begin{cases}
    1 &\text{if } x = 1, 1/2, 1/3, \dots\\
    0 &\text{otherwise}\\
\end{cases} 
</script>
</p>
<p>Each <script type="math/tex">f_n</script> is continuous at zero. <script type="math/tex">f_n</script> does not converge to
<script type="math/tex">f</script> uniformly. <script type="math/tex">f</script> is not continuous at zero.</p>
<p>(b) Repeat this exercise using the sequence of functions</p>
<p>
<script type="math/tex; mode=display"> 
g_n(x) =
\begin{cases}
    x &\text{if } x = 1, 1/2, 1/3, \dots, 1/n \\
    0 &\text{otherwise}\\
\end{cases} 
</script>
</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
g(x) =
\begin{cases}
    x &\text{if } x = 1, 1/2, 1/3, \dots\\
    0 &\text{otherwise}\\
\end{cases} 
</script>
</p>
<p>Each <script type="math/tex">g_n</script> is continuous at zero. <script type="math/tex">g_n</script> converges to
<script type="math/tex">g</script> uniformly. <script type="math/tex">g</script> is continuous at zero.</p>
<p>(c) Repeat this exercise using the sequence of functions</p>
<p>
<script type="math/tex; mode=display"> 
h_n(x) =
\begin{cases}
    1 &\text{if } x = 1/n \\
    x &\text{if } x = 1, 1/2, 1/3, \dots, 1/(n-1) \\
    0 &\text{otherwise}\\
\end{cases} 
</script>
</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
h(x) =
\begin{cases}
    x &\text{if } x = 1, 1/2, 1/3, \dots\\
    0 &\text{otherwise}\\
\end{cases} 
</script>
</p>
<p>Each <script type="math/tex">h_n</script> is continuous at zero. <script type="math/tex">h_n</script> does not converge to
<script type="math/tex">h</script> uniformly. <script type="math/tex">h</script> is continuous at zero.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="623">6.2.3.</h3>
<p>For each <script type="math/tex">n ∈ \mathbf{N}</script> and <script type="math/tex">x ∈ [0,∞)</script>, let</p>
<p>
<script type="math/tex; mode=display">
g_n(x) = \frac{x}{1 + x^n} \text{ and }
h_n(x) = 
\begin{cases}
    1  &\text{if } x \geq 1/n\\
    nx &\text{if } 0 \leq x  < 1/n\\
\end{cases} 
</script>
</p>
<p>Answer the following questions for the sequences <script type="math/tex">(g_n)</script> and <script type="math/tex">(h_n)</script>:</p>
<p>(a) Find the pointwise limit on <script type="math/tex">x ∈ [0,∞)</script>
</p>
<p>
<script type="math/tex; mode=display"> 
g(x) =
\begin{cases}
    x &\text{if } 0 \leq x < 1 \\
    1/2 &\text{if } x = 1\\
    0 &\text{if } x > 1\\
\end{cases}
\\
h(x) =
\begin{cases}
    0 &\text{if } x = 0\\
    1 &\text{if } x > 0\\
\end{cases} 
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Explain how we know that the convergence cannot be uniform on <script type="math/tex">[0,∞)</script>.</p>
<p>Proof: Both <script type="math/tex">g(x)</script> and <script type="math/tex">h(x)</script> are not continuous in <script type="math/tex">[0, \infty)</script>.
So the convergence cannot be uniform.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Choose a smaller set over which the convergence is uniform
and supply an argument to show that this is indeed the case.</p>
<p><strong>Solution</strong>: For <script type="math/tex">g_n(x)</script> choose <script type="math/tex">[0, 1/2]</script>
</p>
<p>
<script type="math/tex; mode=display"> 
|g_n(x) - g(x)| = |\frac{x}{1 + x^n} - x| \\
= \left| \frac{-x^{n+1}}{1 + x^n} \right| \\
< |x^{n+1}| \leq \frac{1}{2^{n+1}}
</script>
</p>
<p>For <script type="math/tex">h_n(x)</script>, choose <script type="math/tex">[1/2, \infty)</script>, when <script type="math/tex">n > 2</script>, <script type="math/tex">h_n(x) = h(x) = 1</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="624">6.2.4.</h3>
<p>Review Exercise 5.2.8 which includes the definition for a
uniformly diﬀerentiable function. Use the results discussed in Section 6.2 to
show that if <script type="math/tex">f</script> is uniformly diﬀerentiable, then <script type="math/tex">f'</script> is continuous.</p>
<p><strong>Proof</strong>: Given <script type="math/tex">ε > 0</script> there exists a <script type="math/tex">δ > 0</script> such that</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
\frac{f(x) - f(y)}{x - y}
-
f'(y)
 \right| < \epsilon
</script>
</p>
<p>
<script type="math/tex; mode=display"> 
|f'(x) - f'(y) |
= \left| f'(x) - \frac{f(x) - f(y)}{x - y} +
\frac{f(x) - f(y)}{x - y} - f'(y) \right| \\
\leq
\left| f'(x) - \frac{f(x) - f(y)}{x - y} \right| +
\left| \frac{f(x) - f(y)}{x - y} - f'(y) \right| \\
< 2 \epsilon
</script>
</p>
<p>So <script type="math/tex">f'(x)</script> is continuous.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="625">6.2.5.</h3>
<p>Using the Cauchy Criterion for convergent sequences of real
numbers (Theorem 2.6.4), supply a proof for Theorem 6.2.5. (First, define a candidate for <script type="math/tex">f(x)</script>, and then argue that <script type="math/tex">f_n → f</script> uniformly.)</p>
<p>Proof:</p>
<p>
<script type="math/tex">\Rightarrow</script> Since <script type="math/tex">(f_n(x)) \rightarrow f(x)</script> uniformly for <script type="math/tex">x \in A</script>.
Then given <script type="math/tex">\epsilon</script>, we can find <script type="math/tex">N</script>, for all <script type="math/tex">n > N</script> and <script type="math/tex">x \in A</script>, <script type="math/tex">|f_n(x) - f(x)| < \epsilon/2</script>. So</p>
<p>
<script type="math/tex; mode=display"> 
\left| f_n(x) - f_m(x) \right| \\
= \left| f_n(x) - f(x) + f(x) - f_m(x) \right| \\
\leq \left| f_n(x) - f(x) \right| + \left| f(x) - f_m(x) \right| \\
< \epsilon
</script>
</p>
<p>for all <script type="math/tex">m, n > N</script> and <script type="math/tex">x \in A</script>.</p>
<p>
<script type="math/tex">\Leftarrow</script> if given any <script type="math/tex">\epsilon</script>, we can find <script type="math/tex">N</script>, for all <script type="math/tex">m, n > N</script> and <script type="math/tex">x \in A</script>, <script type="math/tex">|f_n(x) - f_m(x)| < \epsilon</script>, then
<script type="math/tex">(f_n(x))</script> is a Cauchy sequence, so it must converge to some
<script type="math/tex">c_x</script>, then define <script type="math/tex">f(x) = c_x</script>.</p>
<p>We can find another <script type="math/tex">N_1</script>, for all <script type="math/tex">m, n > N_1</script> and <script type="math/tex">x \in A</script>, <script type="math/tex">|f_n(x) - f_m(x)| < \epsilon/2</script>. We can show that <script type="math/tex">|f_n(x) - f(x)| < \epsilon</script>. This is because for any given <script type="math/tex">x \in A</script>, since <script type="math/tex">(f_n(x)) \rightarrow f(x)</script>, we can find <script type="math/tex">k</script>, such that <script type="math/tex">k > N_1</script> and
<script type="math/tex">|f_k(x) - f(x)| < \epsilon/2</script>. So</p>
<p>
<script type="math/tex; mode=display"> 
\left| f_n(x) - f(x) \right| \\
\leq \left| f_n(x) - f_k(x) \right| + \left| f_k(x) - f(x) \right| \\
< \epsilon
</script>
</p>
<p>Thus, <script type="math/tex">f_n → f</script> uniformly.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="626">6.2.6.</h3>
<p>Assume <script type="math/tex">f_n → f</script> on a set <script type="math/tex">A</script>.</p>
<p>(a) If each <script type="math/tex">f_n</script> is uniformly continuous, then <script type="math/tex">f</script> is uniformly continuous.</p>
<p><strong>Solution</strong>: Consider the example of 6.2.2 (ii), each <script type="math/tex">f_n</script> is
uniformly continuous on <script type="math/tex">[0, 1]</script>, but <script type="math/tex">f</script> is not a continuous
function.</p>
<p>Now assume <script type="math/tex">(f_n) \rightarrow f</script> uniformly. We can find
<script type="math/tex">n</script> such that <script type="math/tex">|f_n(x) - f(x)| < \epsilon / 3</script> for <script type="math/tex">x \in A</script>.
For this <script type="math/tex">f_n</script>, since it's uniformly continuous, we can find <script type="math/tex">\delta</script>, if <script type="math/tex">|x - y| < \delta</script>, then <script type="math/tex">|f_n(x) - f_n(y)| < \epsilon / 3</script>. Then we have</p>
<p>
<script type="math/tex; mode=display"> 
|f(x) - f(y)| \leq \\
|f(x) - f_n(x)| + |f_n(x) - f_n(y)| + |f_n(y) - f(y)| \lt \\
\epsilon / 3 + \epsilon / 3 + \epsilon / 3 = \epsilon
</script>
</p>
<p>So <script type="math/tex">f</script> is uniformly continuous.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) If each <script type="math/tex">f_n</script> is bounded, then <script type="math/tex">f</script> is bounded.</p>
<p><strong>Solution</strong>: Consider <script type="math/tex">f_n = \frac{1}{1/n + x}</script>, <script type="math/tex">A = (0, 1]</script>. Then
<script type="math/tex">f(x) = \frac{1}{x}</script> on <script type="math/tex">A = (0, 1]</script> which is not bounded.</p>
<p>If <script type="math/tex">(f_n) \rightarrow f</script> uniformly. We can find <script type="math/tex">n</script>,
<script type="math/tex">|f_n(x) - f(x) | < 1</script>, since <script type="math/tex">|f_n(x)| \leq M</script>, then
<script type="math/tex">|f(x)| \leq M + 1</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) If each <script type="math/tex">f_n</script> has a finite number ofdiscontinuities, then <script type="math/tex">f</script> has a finite number of discontinuities.</p>
<p>Proof: If the convergence is uniform, consider the following <script type="math/tex">f_n</script>
defined on <script type="math/tex">[0, 1]</script> .</p>
<p>
<script type="math/tex; mode=display"> 
f_n(x) =
\begin{cases}
    0 &\text{if } x \not \in \mathbf{Q}  \\
    1/p - 1/n &\text{if } x = q/p, p < n \\
    0 &\text{if } x = q/p, p \geq n      \\
\end{cases} 
</script>
</p>
<p>So we have</p>
<p>
<script type="math/tex; mode=display"> 
f(x) =
\begin{cases}
    0 &\text{if } x \not \in \mathbf{Q}  \\
    1/p &\text{if } x = q/p \\
\end{cases} 
</script>
</p>
<p>each <script type="math/tex">f_n(x)</script> has a finite number of discontinuities, but <script type="math/tex">f(x)</script> is not continuous at all rational numbers.</p>
<p>Also note <script type="math/tex">|f_n(x) - f(x)| \leq 1/n</script>, so the convergence is uniform.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(d) If each <script type="math/tex">f_n</script> has fewer than <script type="math/tex">M</script> discontinuities (where <script type="math/tex">M ∈ N</script> is fixed), then
<script type="math/tex">f</script> has fewer than M discontinuities.</p>
<p><strong>Solution</strong>:</p>
<p>Consider <script type="math/tex">f_n(x) = x^n</script> defined on <script type="math/tex">[0, 1]</script>, it has no discontinuities on <script type="math/tex">[0, 1]</script>. However, <script type="math/tex">f(x)</script> is discontinueous at
<script type="math/tex">1</script>, so it has one discontinuity.</p>
<p>When <script type="math/tex">f_n(x) \rightarrow f(x)</script> uniformly, and assume <script type="math/tex">f(x)</script> has <script type="math/tex">M</script> or more than <script type="math/tex">M</script> discontinuities.</p>
<p>We first need to choose <script type="math/tex">\epsilon</script>. Since we can find at least
<script type="math/tex">M</script> discontinuities, let</p>
<p>
<script type="math/tex; mode=display"> 
\epsilon = \min
\left\{ 
\epsilon_1, \epsilon_2, \cdots, \epsilon_M
 \right\} 
</script>
</p>
<p>We then choose a fixed <script type="math/tex">n</script> such that
<script type="math/tex">|f_n(x) - f(x) | < \epsilon / 3</script> for all <script type="math/tex">x \in A</script>. 
Assume <script type="math/tex">c</script> is continuous in <script type="math/tex">f_n(x)</script>
but is discontinueous in <script type="math/tex">f(x)</script>.</p>
<p>Then we can find a <script type="math/tex">\delta</script> such that <script type="math/tex">x \in U_{\delta}(c)</script>,
<script type="math/tex">|f_n(x) - f_n(c) | < \epsilon / 3</script>.</p>
<p>Finally, since <script type="math/tex">f(x)</script> is not continuous at <script type="math/tex">c</script>, then we can find
<script type="math/tex">x_0 \in U_{\delta}(c)</script> and <script type="math/tex">|f(x) - f(c)| \geq \epsilon</script>.</p>
<p>But on the other hand,</p>
<p>
<script type="math/tex; mode=display"> 
|f(c) - f(x_0)| \\
< |f(c) - f_n(c) | + | f_n(c) - f_n(x_0) | + | f_n(x_0) - f(x_0) | \\
< \epsilon / 3 + \epsilon / 3 + \epsilon / 3 \\
= \epsilon
</script>
</p>
<p>We have a contradiction. So <script type="math/tex">f(x)</script> has fewer than M discontinuities.</p>
<p>Now looking back to (c), the arguments in (d) does not hold
because, we cannot find such <script type="math/tex">\epsilon</script>. </p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(e) If each <script type="math/tex">f_n</script> has at most a countable number of discontinuities, then <script type="math/tex">f</script> has
at most a countable number of discontinuities.</p>
<p><strong>Solution</strong>:</p>
<p>Consider the process of constructing the Cantor set, and define</p>
<p>
<script type="math/tex; mode=display"> 
f_n(x) =
\begin{cases}
    1 &\text{if } x \in C_n\\
    0 &\text{otherwise }\\
\end{cases} 
</script>
</p>
<p>Then</p>
<p>
<script type="math/tex; mode=display"> 
f(x) =
\begin{cases}
    1 &\text{if } x \in C\\
    0 &\text{otherwise}\\
\end{cases} 
</script>
</p>
<p>Each <script type="math/tex">f_n</script> has <script type="math/tex">2^n</script> discontinuities, but <script type="math/tex">f</script> is discontinueous
at all <script type="math/tex">x \in C</script> which is an uncountable set.</p>
<p>I cannot figure out the results when the convergence is uniform.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="627">6.2.7.</h3>
<p>Let <script type="math/tex">f</script> be uniformly continuous on all of <script type="math/tex">\mathbf{R}</script>, and define a sequence of functions by <script type="math/tex">f_n(x) = f(x+ 1/n)</script>. Show that <script type="math/tex">f_n → f</script> uniformly. Give an
example to show that this proposition fails if <script type="math/tex">f</script> is only assumed to be continuous and not uniformly continuous on <script type="math/tex">\mathbf{R}</script>.</p>
<p><strong>Proof</strong>: Since <script type="math/tex">f</script> is uniformly continuous on all of <script type="math/tex">\mathbf{R}</script>, then given <script type="math/tex">\epsilon</script>, we can find <script type="math/tex">\delta</script>, if <script type="math/tex">|x - y| < \delta</script>, <script type="math/tex">|f(x) - f(y)| < \epsilon</script>.</p>
<p>So take <script type="math/tex">1/n < \delta</script>, we have</p>
<p>
<script type="math/tex; mode=display"> 
|f_n(x) - f(x)| \\
= |f(x+1/n) - f(x) | < \epsilon
</script>
</p>
<p>So <script type="math/tex">f_n → f</script> uniformly.</p>
<p>Let <script type="math/tex">f(x) = x^2</script>
</p>
<p>
<script type="math/tex; mode=display"> 
(x + 1/n)^2 - x^2 = \frac{2}{n}x + \frac{1}{n^2}
</script>
</p>
<p>So <script type="math/tex">f_n → f</script> is not uniformly.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="628">6.2.8.</h3>
<p>Let <script type="math/tex">(g_n)</script> be a sequence of continuous functions that converges
uniformly to <script type="math/tex">g</script> on a compact set <script type="math/tex">K</script>. If <script type="math/tex">g(x) \not = 0</script> on <script type="math/tex">K</script>, show <script type="math/tex">(1/g_n)</script> converges uniformly on <script type="math/tex">K</script> to <script type="math/tex">1/g</script>.</p>
<p>Proof: since <script type="math/tex">(g_n) \rightarrow g</script> uniformly, and <script type="math/tex">g_n</script> is
continuous, then <script type="math/tex">g</script> is a continuous function on a compact
set <script type="math/tex">K</script>, that means we can find <script type="math/tex">c \in K</script>, such that</p>
<p>
<script type="math/tex; mode=display"> 
g(c) = \inf \left\{ |g(x)| : x \in K \right\} > 0
</script>
</p>
<p>Again, since <script type="math/tex">(g_n) \rightarrow g</script> uniformly, given <script type="math/tex">\epsilon < g(c)/2</script>, we can find <script type="math/tex">N</script>, such that <script type="math/tex">n > N</script>, <script type="math/tex">|g_n(x) - g(x)| < \epsilon</script>. That is <script type="math/tex">|g_n(x)| > g(c)/2</script>.</p>
<p>So we have</p>
<p>
<script type="math/tex; mode=display"> 
|\frac{1}{g_n(x)} - \frac{1}{g(x)}|\\
= |\frac{g(x) - g_n(x)}{g(x)g_n(x)}| < \frac{4}{g^2(c)} | g(x) - g_n(x)|
</script>
</p>
<p>So <script type="math/tex">(1/g_n)</script> converges uniformly on <script type="math/tex">K</script> to <script type="math/tex">1/g</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="629">6.2.9.</h3>
<p>Assume <script type="math/tex">(f_n)</script> and <script type="math/tex">(g_n)</script> are uniformly convergent sequences of
functions.</p>
<p>(a) Show that <script type="math/tex">(f_n +g_n)</script> is a uniformly convergent sequence of functions.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
f_n(x) + g_n(x) - (f(x) + g(x))
 \right| \\
< |f_n(x) - f(x)| + |g_n(x) - g(x)| \\
< 2 \epsilon
</script>
</p>
<p>So <script type="math/tex">(f_n +g_n)</script> is a uniformly convergent sequence of functions.</p>
<p>(b) Give an example to show that the product <script type="math/tex">(f_ng_n)</script> may not converge uniformly.</p>
<p><strong>Solution</strong>: Let <script type="math/tex">f_n(x) = g_n(x) = x + 1/n</script>,
<script type="math/tex">(f_ng_n) \rightarrow x^2</script>, but is not uniformly.</p>
<p>(c) Prove that if there exists an <script type="math/tex">M > 0</script> such that <script type="math/tex">|f_n| ≤ M</script> and <script type="math/tex">|g_n| ≤ M</script> for
all <script type="math/tex">n ∈ N</script>, then <script type="math/tex">(f_ng_n)</script> does converge uniformly.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
|f_ng_n - fg|\\
=|f_ng_n - f g_n + f g_n - fg|\\
=|f_n - f| |g_n| + |f| |g_n - g|\\
\leq M(|fn - f| + |g_n - g|)
</script>
</p>
<p>So <script type="math/tex">(f_ng_n)</script> does converge uniformly.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="6210">6.2.10.</h3>
<p>This exercise and the next explore partial converses of the
Continuous Limit Theorem (Theorem 6.2.6). Assume <script type="math/tex">f_n → f</script> pointwise on <script type="math/tex">[a,b]</script>
and the limit function <script type="math/tex">f</script> is continuous on <script type="math/tex">[a,b]</script>. If each <script type="math/tex">f_n</script> is increasing (but not necessarily continuous), show <script type="math/tex">f_n → f</script> uniformly.</p>
<p>Proof: Assume otherwise. Then we can find a <script type="math/tex">\epsilon</script>, for any
<script type="math/tex">N</script>, we can find <script type="math/tex">n > N</script> and <script type="math/tex">x_n \in [a, b]</script>, such that <script type="math/tex">|f_n(x_n) - f(x_n)| \geq \epsilon</script>. Thus we found a sequence <script type="math/tex">(x_n)</script>.
Since it's bounded, we can find a subsquence <script type="math/tex">(x_n) \rightarrow c</script>.</p>
<p>On the other hand, for <script type="math/tex">c \in [a, b]</script>, since <script type="math/tex">f(x)</script> is continuous, we can find
<script type="math/tex">[c-\delta, c+ \delta]</script>, such that <script type="math/tex">|f(x) - f(c)| < \epsilon</script> if
<script type="math/tex">x \in [c-\delta, c+ \delta]</script>.</p>
<p>We can also find <script type="math/tex">N</script>, if <script type="math/tex">n > N</script>, <script type="math/tex">|f_n(c-\delta) - f(c-\delta)| < \epsilon</script> and <script type="math/tex">|f_n(c+\delta) - f(c+\delta)| < \epsilon</script>.</p>
<p>For any <script type="math/tex">n > N</script> and <script type="math/tex">x \in [c-\delta, c+ \delta]</script>, since <script type="math/tex">f_n</script> is
increasing, we have
<script type="math/tex">|f_n(x) - f(x)| < \max (|f_n(c-\delta) - f(x)|, |f_n(c+\delta) - f(x)|)</script>.</p>
<p>
<script type="math/tex; mode=display"> 
|f_n(c-\delta) - f(x)| \leq |f_n(c-\delta) - f(c-\delta)| + |f(c-\delta) - f(x)| \\
\leq |f_n(c-\delta) - f(c-\delta)| + |f(c-\delta) - f(c)| + |f(c) - f(x)| \\
< 3 \epsilon
</script>
</p>
<p>For the same reason, we have <script type="math/tex">|f_n(c+\delta) - f(x)| < 3 \epsilon</script>.
Thus, <script type="math/tex">|f_n(x) - f(x)| < 3 \epsilon</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="6211-dinis-theorem">6.2.11 (Dini’s Theorem).</h3>
<p>Assume <script type="math/tex">f_n → f</script> pointwise on a compact
set <script type="math/tex">K</script> and assume that for each <script type="math/tex">x ∈ K</script> the sequence <script type="math/tex">f_n(x)</script> is increasing.
Follow these steps to show that if <script type="math/tex">f_n</script> and <script type="math/tex">f</script> are continuous on <script type="math/tex">K</script>, then the convergence is uniform.</p>
<p>(a) Set <script type="math/tex">g_n = f− f_n</script> and translate the preceding hypothesis into statements about the sequence <script type="math/tex">(g_n)</script>.</p>
<p>New statement: <script type="math/tex">g_n → 0</script> pointwise on a compact
set <script type="math/tex">K</script> and assume that for each <script type="math/tex">x ∈ K</script> the sequence <script type="math/tex">g_n(x)</script> is
decreasing. If <script type="math/tex">g_n</script> are continuous on <script type="math/tex">K</script>, then the convergence is uniform.</p>
<p>(b) Let <script type="math/tex">ϵ > 0</script> be arbitrary, and define <script type="math/tex">K_n = \left\{ x ∈ K : g_n(x) ≥ ϵ \right\}</script>. Argue that
<script type="math/tex">K_1 ⊇ K_2 ⊇ K_3 ⊇ ···</script>, and use this observation to finish the argument.</p>
<p>Proof: If <script type="math/tex">c \in K_n</script>, <script type="math/tex">g_n(c) \geq \epsilon</script>. Since <script type="math/tex">g_n(c)</script> is decreasing, then <script type="math/tex">g_n(c) \leq g_m(c), \forall m < n</script>. That means
<script type="math/tex">K_m \supseteq K_n</script>.</p>
<p>
<script type="math/tex">K_n = g_n^{-1}([\epsilon, \infty))</script>, so <script type="math/tex">K_n</script> is the preimage of a closed set of a continuous function. It's easy to
prove <script type="math/tex">K_n</script> is also a close set. Since it's a subset of <script type="math/tex">K</script>, it's
also bounded. Then <script type="math/tex">K_n</script> is compact.</p>
<p>If none of <script type="math/tex">K_n</script> is empty, then according to Theorem 3.3.5 (Nested Compact Set Property), the intersection of <script type="math/tex">K_n</script> is not empty.
Assume <script type="math/tex">c \in \cap K_n</script>, then <script type="math/tex">g_n(c) \geq \epsilon</script>. So <script type="math/tex">g(c) \geq \epsilon</script>. We have a contradiction.</p>
<p>This means for some <script type="math/tex">N</script>, as long as <script type="math/tex">n > N</script>, <script type="math/tex">K_n = \emptyset</script>, i.e. <script type="math/tex">0 < g_n(x) < \epsilon, x \in K</script>, i.e. the convergence is continuous.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="6212-cantor-function">6.2.12 (Cantor Function).</h3>
<p>Review the construction of the Cantor
set <script type="math/tex">C ⊆ [0,1]</script> from Section 3.1. This exercise makes use of results and notation from this discussion.</p>
<p>(a) Define <script type="math/tex">f_0(x) = x</script> for all <script type="math/tex">x \in [0,1]</script>. Now, let</p>
<p>
<script type="math/tex; mode=display">
f_1(x) =
\begin{cases}
    (3/2)x       &\text{for } 0 \leq x \leq 1/3\\
    1/2          &\text{for } 1/3 < x < 2/3    \\
    (3/2)x - 1/2 &\text{for } 2/3 \leq x \leq 1\\
\end{cases} 
</script>
</p>
<p>Sketch <script type="math/tex">f_0</script> and <script type="math/tex">f_1</script> over <script type="math/tex">[0,1]</script> and observe that <script type="math/tex">f_1</script> is continuous, increasing,
and constant on the middle third <script type="math/tex">(1/3,2/3)= [0,1] / C_1</script>.</p>
<p>(b) Construct <script type="math/tex">f_2</script> by imitating this process of flattening out the middle third
of each nonconstant segment of <script type="math/tex">f_1</script> . Specifically, let</p>
<p>
<script type="math/tex; mode=display">
f_2(x) =
\begin{cases}
    (1/2)f_1(3x) &\text{for } 0 \leq x \leq 1/3\\
    f_1(x)       &\text{for } 1/3 < x < 2/3    \\
    (1/2)f_1(3x-2) + 1/2 &\text{for } 2/3 \leq x \leq 1\\
\end{cases} 
</script>
</p>
<p>If we continue this process,show that the resulting sequence
<script type="math/tex">(f_n)</script> converges uniformly on <script type="math/tex">[0,1]</script>.</p>
<p>Proof: For <script type="math/tex">f_n</script>, each vertical non-flat jump is <script type="math/tex">1/2^n</script>.
Then:
* if <script type="math/tex">x \not \in C_n</script>, <script type="math/tex">f_n(x) = f(x)</script>.
* if <script type="math/tex">x \in C_n</script>, <script type="math/tex">|f_n(x) - f(x)| \leq 1/2^n</script>.</p>
<p>So <script type="math/tex">(f_n)</script> converges uniformly on <script type="math/tex">[0,1]</script>.</p>
<p>(c) Let <script type="math/tex">f = \lim f_n</script>. Prove that <script type="math/tex">f</script> is a continuous, increasing function on <script type="math/tex">[0,1]</script>
with <script type="math/tex">f(0) = 0</script> and <script type="math/tex">f(1) = 1</script> that satisfies <script type="math/tex">f'(x) = 0</script> for all <script type="math/tex">x</script> in the open
set <script type="math/tex">[0,1]/C</script>. Recall that the “length” of the Cantor set <script type="math/tex">C</script> is <script type="math/tex">0</script>. Somehow,
<script type="math/tex">f</script> manages to increase from <script type="math/tex">0</script> to <script type="math/tex">1</script> while remaining constant on a set of “length <script type="math/tex">1</script>.”</p>
<p>Proof: Each <script type="math/tex">f_n</script> is continuous and <script type="math/tex">(f_n) \rightarrow f</script> uniformly, according to Theorem 6.2.6 (Continuous Limit Theorem),
<script type="math/tex">f</script> is continuous. <script type="math/tex">f_n</script> is increasing, so is <script type="math/tex">f</script>.</p>
<p>
<script type="math/tex">f_n(0) = 0</script> and <script type="math/tex">f_n(1) = 1</script>, so <script type="math/tex">f(0) = 0, f(1) = 1</script>.</p>
<p>If <script type="math/tex">x \in [0,1]/C</script>, then <script type="math/tex">f(x)</script> is a constant in <script type="math/tex">U_{\delta}(x)</script>,
so <script type="math/tex">f'(x) = 0</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="6213">6.2.13.</h3>
<p>Let <script type="math/tex">A= \left\{x_1,x_2,x_3,...\right\}</script> be a countable set. For each <script type="math/tex">n ∈ N</script>, let <script type="math/tex">f_n</script> be
defined on <script type="math/tex">A</script> and assume there exists an <script type="math/tex">M > 0</script> such that <script type="math/tex">|f_n(x)| ≤ M</script> for all
<script type="math/tex">n ∈ N</script> and <script type="math/tex">x ∈ A</script>. Follow these steps to show that there exists a subsequence
of <script type="math/tex">(f_n)</script> that converges pointwise on <script type="math/tex">A</script>.</p>
<p>(a) Why does the sequence of real numbers <script type="math/tex">f_n(x_1)</script> necessarily contain a convergent subsequence <script type="math/tex">(f_{n_k})</script>? To indicate that the subsequence of functions
<script type="math/tex">(f_{n_k})</script> is generated by considering the values of the functions at <script type="math/tex">x_1</script>, we will use the notation <script type="math/tex">(f_{n_k}) = f_{1,k}</script>.</p>
<p>Proof: <script type="math/tex">f_n(x_1)</script> is a bounded sequence, from Bolzano–Weierstrass Theorem, it must have a convergent subsequence <script type="math/tex">(f_{n_k})</script>.</p>
<p>(b) Now,explain why the sequence <script type="math/tex">f_{1,k}(x2)</script> contains a convergent subsequence.</p>
<p>Proof: Because <script type="math/tex">f_{1,k}(x2)</script> is also bounded. And use Bolzano–Weierstrass Theorem again.</p>
<p>(c) Carefully construct a nested family of subsequences <script type="math/tex">(f_{m,k})</script>, and show how this can be used to produce a single subsequence of <script type="math/tex">(f_n)</script> that converges at every point of <script type="math/tex">A</script>.</p>
<p>Proof: Note that <script type="math/tex">f_{p,k} \subseteq f_{q,k}</script> if <script type="math/tex">p > q</script>, and
<script type="math/tex">f_{p, k} (x_q)</script> converges. So we can pick <script type="math/tex">f_1</script> from <script type="math/tex">f_{1, k}</script>,
<script type="math/tex">f_2</script> from <script type="math/tex">f_{2, k}</script> and so on.</p>
<p>For any <script type="math/tex">x_n \in A</script>, <script type="math/tex">f_n(x_n), f_{n+1}(x_n), \dots</script> converges.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="6214">6.2.14.</h3>
<p>A sequence of functions <script type="math/tex">(f_n)</script> defined on a set <script type="math/tex">E ⊆ R</script> is called
equicontinuous if for every <script type="math/tex">ϵ > 0</script> there exists a <script type="math/tex">δ > 0</script> such that <script type="math/tex">|f_n(x)−f_n(y)| < ϵ</script> for all <script type="math/tex">n ∈ N</script> and <script type="math/tex">|x−y| < δ</script> in <script type="math/tex">E</script>.</p>
<p>(a) What is the diﬀerence between saying that a sequence of functions <script type="math/tex">(f_n)</script> is
equicontinuous and just asserting that each <script type="math/tex">f_n</script> in the sequence is individually uniformly continuous?</p>
<p>Solution: the <script type="math/tex">\delta</script> might be depending on <script type="math/tex">n</script> if
each <script type="math/tex">f_n</script> in the sequence is individually uniformly continuous.</p>
<p>(b) Give a qualitative explanation for why the sequence
<script type="math/tex">g_n(x) = x^n</script> is not
equicontinuous on <script type="math/tex">[0,1]</script>.
Is each <script type="math/tex">g_n</script> uniformly continuous on <script type="math/tex">[0,1]</script>?</p>
<p>Solution: let <script type="math/tex">\epsilon = 0.1</script>
* when <script type="math/tex">n = 1</script>, <script type="math/tex">\delta = 0.1</script>.
* when <script type="math/tex">n = 2</script>, <script type="math/tex">1 - x^2 < 0.1, x < \sqrt[2]{1 - 0.1}</script>,  <script type="math/tex">\delta < 0.051</script>.
* when <script type="math/tex">n = 4</script>, <script type="math/tex">1 - x^4 < 0.1, x < \sqrt[4]{1 - 0.1}</script>,<script type="math/tex">\delta < 0.026</script>.
* when <script type="math/tex">n = 100</script>, <script type="math/tex">1 - x^{100} < 0.1, x < \sqrt[100]{1 - 0.1}</script>,<script type="math/tex">\delta < 0.0011</script>.</p>
<p>But each <script type="math/tex">g_n</script> is indeed uniformly continuous.</p>
<h3 id="6215-arzelaascoli-theorem">6.2.15 (Arzela–Ascoli Theorem).</h3>
<p>For each <script type="math/tex">n ∈ \mathbf{N}</script>, let <script type="math/tex">f_n</script> be a
function defined on <script type="math/tex">[0,1]</script>. If <script type="math/tex">(f_n)</script> is bounded on <script type="math/tex">[0,1]</script>—that is, there exists an
<script type="math/tex">M > 0</script> such that <script type="math/tex">|f_n(x)| ≤ M</script> for all <script type="math/tex">n ∈ \mathbf{N}</script> and <script type="math/tex">x ∈ [0,1]</script>—and if the collection
of functions <script type="math/tex">(f_n)</script> is equicontinuous (Exercise 6.2.14), follow these steps to show
that <script type="math/tex">(f_n)</script> contains a uniformly convergent subsequence.</p>
<p>(a) Use Exercise 6.2.13 to produce a subsequence <script type="math/tex">(f_{n,k})</script> that converges at every
rational point in <script type="math/tex">[0,1]</script>. To simplify the notation, set <script type="math/tex">g_k = f_{n,k}</script>. It remains
to show that <script type="math/tex">(g_k)</script> converges uniformly on all of <script type="math/tex">[0,1]</script>.</p>
<p>Proof: We can just directly apply Exercise 6.2.13. <script type="math/tex">\square</script>
</p>
<p>(b) Let <script type="math/tex">ϵ > 0</script>. By equicontinuity, there exists a <script type="math/tex">δ > 0</script> such that</p>
<p>
<script type="math/tex; mode=display">
|g_k(x) - g_k(y)| < \epsilon / 3
</script>
</p>
<p>for all <script type="math/tex">|x− y| < δ</script> and <script type="math/tex">k ∈ \mathbf{N}</script>. Using this <script type="math/tex">δ</script>, let <script type="math/tex">r_1,r_2,...,r_m</script> be a
finite collection of rational points with the property that the union of the neighborhoods <script type="math/tex">V_δ(r_i)</script> contains <script type="math/tex">[0,1]</script>.
Explain why there must exist an <script type="math/tex">N ∈ \mathbf{N}</script> such that</p>
<p>
<script type="math/tex; mode=display">
|g_s(r_i) - g_t(r_i)| < \epsilon / 3
</script>
</p>
<p>for all <script type="math/tex">s,t ≥ N</script> and <script type="math/tex">r_i</script> in the finite subset of <script type="math/tex">[0,1]</script> just described.</p>
<p>Why does having the set <script type="math/tex">\left\{r_1,r_2,...,r_m\right\}</script> be finite matter?</p>
<p><strong>Proof</strong>: This is because <script type="math/tex">g_k(r_i) \rightarrow g(r_i)</script>, according to
Cauchy criterion, we can find <script type="math/tex">N_i</script> such that <script type="math/tex">s, t > N_i</script>
</p>
<p>
<script type="math/tex; mode=display">
|g_s(r_i) - g_t(r_i)| < \epsilon / 3
</script>
</p>
<p>Let <script type="math/tex">N = \max \left\{ r_1,r_2,...,r_m  \right\}</script>.</p>
<p>If <script type="math/tex">\left\{r_1,r_2,...,\right\}</script> is infinite, <script type="math/tex">\max \left\{ r_1,r_2,... \right\}</script> can be infinite. <script type="math/tex">\square</script>
</p>
<p>(c) Finish the argument by showing that, for an arbitrary <script type="math/tex">x ∈ [0,1]</script>,</p>
<p>
<script type="math/tex; mode=display">
|g_s(x) - g_t(x)| < \epsilon
</script>
</p>
<p>for all <script type="math/tex">s,t ≥ N</script>.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
|g_s(x) - g_t(x)| =
|g_s(x) - g_s(r_i) + g_s(r_i) - g_t(r_i) + g_t(r_i) - g_t(x)|\\
\leq |g_s(x) - g_s(r_i)|
+ |g_s(r_i) - g_t(r_i)| + |g_t(r_i) - g_t(x)| \\
< 3 \times \epsilon / 3 = \epsilon 
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h2 id="63-uniform-convergence-and-differentiation">6.3. Uniform Convergence and Diﬀerentiation</h2>
<h3 id="631">6.3.1.</h3>
<p>Consider the sequence of functions defined by</p>
<p>
<script type="math/tex; mode=display">
g_n(x) = \frac{x^n}{n}
</script>
</p>
<p>Anwser:</p>
<p>(a) Show <script type="math/tex">(g_n)</script> converges uniformly on <script type="math/tex">[0,1]</script> and find <script type="math/tex">g = \lim g_n</script>. Show that <script type="math/tex">g</script> is diﬀerentiable and compute <script type="math/tex">g'(x)</script> for all <script type="math/tex">x ∈ [0,1]</script>.</p>
<p><strong>Solution</strong>: Given <script type="math/tex">x \in [0, 1]</script>,</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{n \to \infty} \frac{x^n}{n} = 0
</script>
</p>
<p>So <script type="math/tex">g(x) = 0</script>.</p>
<p>
<script type="math/tex; mode=display"> 
|g_n(x) - g(x)| =
\left| \frac{x^n}{n} \right| < \left| 1/n \right|
</script>
</p>
<p>So <script type="math/tex">(g_n) \rightarrow g</script> uniformly.</p>
<p>
<script type="math/tex">g</script> is a constant function so it's differentiable and <script type="math/tex">g'(x) = 0</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Now, show that <script type="math/tex">(g_n')</script> converges on <script type="math/tex">[0,1]</script>.
Is the convergence uniform? Set <script type="math/tex">h = \lim g_n'</script> and compare <script type="math/tex">h</script> and <script type="math/tex">g'</script>. Are they the same?</p>
<p><strong>Solution</strong>:</p>
<p>We have</p>
<p>
<script type="math/tex; mode=display"> 
g'_n(x) = x^{n-1} \\
h(x) = \begin{cases}
    0 &\text{if } x < 1\\
    1 &\text{if } x = 1\\
\end{cases} 
</script>
</p>
<p>The converge is not uniform. <script type="math/tex">h</script> and <script type="math/tex">g'(x)</script> are not the same.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="632">6.3.2.</h3>
<p>Consider the sequence of functions</p>
<p>
<script type="math/tex; mode=display"> 
h_n(x) = \sqrt[]{x^2 + \frac{1}{n}}
</script>
</p>
<p>Answer:</p>
<p>(a) Compute the pointwise limit of <script type="math/tex">(h_n)</script> and then prove that the convergence is uniform on <script type="math/tex">\mathbf{R}</script>.</p>
<p><strong>Solution</strong>: Given <script type="math/tex">x</script>
</p>
<p>
<script type="math/tex; mode=display"> 
h(x) = \lim_{n \to \infty} h_n(x) = \sqrt[]{x^2} = |x|
</script>
</p>
<p>And also</p>
<p>
<script type="math/tex; mode=display"> 
|h_n(x) - h(x)| =\\
\left| 
\frac{1/n}{\sqrt[]{x^2 + \frac{1}{n}} + |x|}
\right| <
\left| \frac{1/n}{\sqrt[]{1/n}} \right| =
\left| \frac{1}{\sqrt[]{n}} \right|
</script>
</p>
<p>So the convergence is uniform.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Note that each <script type="math/tex">h_n</script> is diﬀerentiable. Show <script type="math/tex">g(x) = \lim h'_
n(x)</script> exists for all <script type="math/tex">x</script>, and explain how we can be certain that the convergence is not uniform on any neighborhood of zero.</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
h_n'(x) = \left(  \sqrt[]{x^2 + \frac{1}{n}} \right) ' \\
= \frac{1}{2} \frac{1}{\sqrt[]{x^2 + \frac{1}{n}}} 2x \\
= \frac{x}{\sqrt[]{x^2 + \frac{1}{n}}}
</script>
</p>
<p>Then we have</p>
<p>
<script type="math/tex; mode=display"> 
g(x) =
\begin{cases}
    0  &\text{if } x = 0\\
    1  &\text{if } x > 0\\
    -1 &\text{if } x < 0\\
\end{cases} 
</script>
</p>
<p>If the convergence is uniform on a neighborhood of zero,
then we must have</p>
<p>
<script type="math/tex; mode=display"> 
h'(x) = g(x)
</script>
</p>
<p>But <script type="math/tex">h(x)</script> is not differentiable at <script type="math/tex">0</script>. So the convergence
is not uniform.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="633">6.3.3.</h3>
<p>Consider the sequence of functions</p>
<p>
<script type="math/tex; mode=display"> 
f_n(x) =
\frac{x}{1 + nx^2}
</script>
</p>
<p>Answer:</p>
<p>(a) Find the points on <script type="math/tex">\mathbf{R}</script> where each <script type="math/tex">f_n(x)</script> attains its maximum and minimum value. Use this to prove <script type="math/tex">(f_n)</script> converges uniformly on <script type="math/tex">\mathbf{R}</script>. What is the limit function?</p>
<p><strong>Solution</strong>:</p>
<p>Fix <script type="math/tex">n</script>, and assume <script type="math/tex">x > 0</script>. </p>
<p>
<script type="math/tex; mode=display"> 
f_n(x) =
\frac{1}{\frac{1}{x} + nx} \\
= \frac{1}{(\frac{1}{\sqrt[]{x}} - \sqrt[]{nx})^2 + 2 \sqrt[]{n}} \\
\leq \frac{1}{2 \sqrt[]{n}}
</script>
</p>
<p>When <script type="math/tex">x = 1/\sqrt[]{n}</script>. Since <script type="math/tex">f_n(x)</script> is odd function, it
attains it's minimum value at <script type="math/tex">x = -1/\sqrt[]{n}</script>.</p>
<p>The limit function is <script type="math/tex">f(x) = 0</script>.</p>
<p>
<script type="math/tex; mode=display"> 
|f_n(x) - f(x)| =
\left| \frac{1}{\frac{1}{x} + nx} - 0 \right| \leq \frac{1}{2 \sqrt[]{n}}
</script>
</p>
<p>So the convergence is uniform.</p>
<p>(b) Let <script type="math/tex">f = \lim f_n</script>. Compute <script type="math/tex">f'_n(x)</script> and find all the values of <script type="math/tex">x</script> for which <script type="math/tex">f'(x) = \lim f'_n(x)</script>.</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display">
f_n(x) = \frac{x}{1 + nx^2} \\
f_n'(x) = \frac{
(1+nx^2) - x(2nx)
}{
(1 + nx^2)^2
} \\
= \frac{1 - nx^2}{(1 + nx^2)^2} \\
= \frac{1}{1 + nx^2} \frac{1 - nx^2}{1+nx^2}
</script>
</p>
<p>Let <script type="math/tex">g(x) = \lim_{n \to \infty} f_n'(x)</script>,</p>
<p>
<script type="math/tex; mode=display"> 
g(x) =
\begin{cases}
    1 &\text{if } x \not = 0 \\
    0 &\text{if } x = 0 \\
\end{cases}
</script>
</p>
<p>So <script type="math/tex">f'(x) = g(x)</script> when <script type="math/tex">x \not = 0</script>.</p>
<h3 id="634">6.3.4.</h3>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
h_n(x) = 
\frac{\sin (nx)}{\sqrt[]{n}}
</script>
</p>
<p>Show that <script type="math/tex">h_n → 0</script> uniformly on <script type="math/tex">\mathbf{R}</script> but that the sequence of derivatives <script type="math/tex">(h_n')</script> diverges for every
<script type="math/tex">x ∈ \mathbf{R}</script>.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
|h_n(x) - 0| \leq \frac{1}{\sqrt[]{n}}
</script>
</p>
<p>So the converge is uniform.</p>
<p>
<script type="math/tex; mode=display"> 
h_n'(x) = \frac{n \cos (nx)}{\sqrt[]{n}} = \sqrt[]{n} \cos (nx)
</script>
</p>
<p>Since <script type="math/tex">\cos (nx)</script> can be either positive or negtive, then
<script type="math/tex">h_n'(x)</script> diverges for every <script type="math/tex">x \in \mathbf{R}</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="635">6.3.5.</h3>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
g_n(x) = \frac{nx + x^2}{2n}
</script>
</p>
<p>and set <script type="math/tex">g(x) = \lim g_n(x)</script>.
Show that <script type="math/tex">g</script> is diﬀerentiable in two ways:</p>
<p>(a) Compute <script type="math/tex">g(x)</script> by algebraically taking the limit as <script type="math/tex">n → ∞</script> and then find <script type="math/tex">g'(x)</script>.</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
g(x) = \lim g_n(x) = \frac{x}{2} \\
g'(x) = \frac{1}{2}
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Compute <script type="math/tex">g'_n(x)</script> for each <script type="math/tex">n ∈ N</script> and show that the sequence of derivatives <script type="math/tex">(g'_n)</script> converges uniformly on every interval <script type="math/tex">[−M,M]</script>.</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
g_n'(x) = \frac{n + 2x}{2n} = \frac{1}{2} + \frac{x}{n}
</script>
</p>
<p>We can see <script type="math/tex">\lim_{n \to \infty} g_n'(x) = \frac{1}{2}</script> for <script type="math/tex">x \in \mathbf{R}</script>.</p>
<p>
<script type="math/tex; mode=display"> 
|g_n'(x) - \frac{1}{2}| = |x/n| \leq M/n.
</script>
</p>
<p>So it converges uniformly on every interval <script type="math/tex">[−M,M]</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Repeat parts (a) and (b) for the sequence
<script type="math/tex">f_n(x) = (nx^2 +1)/(2n+x)</script>.</p>
<p><strong>Solution</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \lim_{n \to \infty} f_n(x) = \frac{x^2}{2}
</script>
</p>
<p>Then we have <script type="math/tex">f'(x) = x</script>.</p>
<p>Then we compute <script type="math/tex">f_n'(x)</script>.</p>
<p>
<script type="math/tex; mode=display"> 
f_n(x) = \frac{nx^2 +1}{2n + x} \\
f_n'(x) = \frac{(2n+x)(2nx) - (nx^2+1)}{(2n+x)^2} \\
= \frac{nx^2 + 4n^2x - 1}{(2n+x)^2} \\
= \frac{nx^2 + 4n^2x - 1}{x^2 + 4nx + 4n^2}
</script>
</p>
<p>Let <script type="math/tex">h(x) = \lim_{n \to \infty} f_n'(x)</script>, then <script type="math/tex">h(x) = x</script>.</p>
<p>
<script type="math/tex; mode=display"> 
|f_n'(x) - h(x)| =\\
\left| \frac{
(nx^2 + 4n^2x - 1) - (x^2 + 4nx + 4n^2)x
}{
x^2 + 4nx + 4n^2
} \right| = \\
\left| \frac{
3nx^2 + x^3 + 1
}{
x^2 + 4nx + 4n^2
} \right| <
\frac{3nM^2 + M^3 + 1}{(2n - M)^2}
</script>
</p>
<p>So it converges uniformly on every interval <script type="math/tex">[−M,M]</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="637">6.3.7.</h3>
<p>Use the Mean Value Theorem to supply a proof for Theorem 6.3.2. To get started, observe that the triangle inequality implies that, for any <script type="math/tex">x ∈ [a,b]</script> and <script type="math/tex">m,n ∈ \mathbf{N}</script>,</p>
<p>
<script type="math/tex; mode=display"> 
|f_n(x) - f_m(x)| \leq 
|(f_n(x) - f_m(x)) - (f_n(x_0) - f_m(x_0))|
+ |(f_n(x_0) - f_m(x_0))|
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>Fix <script type="math/tex">x</script>, since <script type="math/tex">f_n</script> are all differentiable, from MVT,
we can find <script type="math/tex">c \in (x, x_0)</script> such that</p>
<p>
<script type="math/tex; mode=display"> 
|(f_n(x) - f_m(x)) - (f_n(x_0) - f_m(x_0))| =\\
|(f_n'(c) - f_m'(c))(x - x_0)| \\
\leq |(f_n'(c) - f_m'(c))| (b-a)
</script>
</p>
<p>Let <script type="math/tex">g(x) = \lim_{n \to \infty} f_n'(x)</script>, since we <script type="math/tex">(f'_n) \rightarrow g</script> uniformly, we can find <script type="math/tex">N_1</script>, for <script type="math/tex">n, m > N_1</script>,
<script type="math/tex">|f_n'(x) - f_m'(x)| < \frac{\epsilon}{2 (b-a)}</script>.</p>
<p>We can also find <script type="math/tex">N_2</script>, for <script type="math/tex">n, m > N_2</script>, <script type="math/tex">|f_n(x_0) - f_m(x_0)| < \epsilon /2</script>.</p>
<p>Let <script type="math/tex">N = \max \left\{ N_1, N_2 \right\}</script>, then
<script type="math/tex">|f_n(x) - f_m(x)| < \epsilon</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h2 id="64-series-of-functions">6.4 Series of Functions</h2>
<h3 id="641">6.4.1.</h3>
<p>Supply the details for the proof of the Weierstrass M-Test
(Corollary 6.4.5):</p>
<p>For each <script type="math/tex">n ∈ N</script>, let <script type="math/tex">f_n</script> be a function
defined on a set <script type="math/tex">A ⊆ R</script>, and let <script type="math/tex">M_n > 0</script> be a real
number satisfying</p>
<p>
<script type="math/tex; mode=display"> 
|f_n(x)| \leq M_n
</script>
</p>
<p>for all <script type="math/tex">x \in A</script>. If <script type="math/tex">\sum_{n = 1}^{\infty}M_n</script> converges,
then <script type="math/tex">\sum_{n = 1}^{\infty}f_n(x)</script> converges uniformly on
<script type="math/tex">A</script>.</p>
<p><strong>Proof</strong>: Given <script type="math/tex">\epsilon</script>, since <script type="math/tex">\sum_{n = 1}^{\infty}M_n</script> converges, based on Cauchy Criterion, we can find <script type="math/tex">N</script>, if
<script type="math/tex">n > m > N</script>, then</p>
<p>
<script type="math/tex; mode=display"> 
\left| M_{m+1} + \cdots + M_{n} \right| =\\
M_{m+1} + \cdots + M_{n} < \epsilon
</script>
</p>
<p>We also have</p>
<p>
<script type="math/tex; mode=display"> 
\left| f_{m+1} + \cdots + f_{n} \right| \leq
\left| M_{m+1} \right| + \cdots + \left| M_{n} \right| =\\
M_{m+1} + \cdots + M_{n} < \epsilon
</script>
</p>
<p>So based on Theorem 6.4.4 (Cauchy Criterion for Uniform Convergence of Series),
<script type="math/tex">\sum_{n = 1}^{\infty}f_n(x)</script> converges uniformly on
<script type="math/tex">A</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="642">6.4.2.</h3>
<p>Decide whether each proposition is true or false, providing a
short justification or counterexample as appropriate.</p>
<p>(a) If <script type="math/tex">\sum_{n = 1}^{\infty} g_n</script> converges uniformly,
then <script type="math/tex">(g_n)</script> converges uniformly to zero.</p>
<p><strong>Proof</strong>: True. Based on Theorem 6.4.4 (Cauchy Criterion for Uniform Convergence of Series), we know
<script type="math/tex">\left| g_n(x) \right| < \epsilon</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) If <script type="math/tex">0 \leq f_n(x) \leq g_n(x)</script> and <script type="math/tex">\sum_{n = 1}^{\infty}g_n</script>
converges uniformly, then <script type="math/tex">\sum_{n = 1}^{\infty}f_n(x)</script> converges uniformly.</p>
<p><strong>Proof</strong>: True, again, use Theorem 6.4.4 (Cauchy Criterion for Uniform Convergence of Series)</p>
<p>
<script type="math/tex; mode=display"> 
\left| 
f_{m+1} (x) + \cdots + f_n(x)
 \right| =\\
f_{m+1} (x) + \cdots + f_n(x) \\
\leq 
g_{m+1} (x) + \cdots + g_n(x) \\
= | g_{m+1} (x) + \cdots + g_n(x) | < \epsilon
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) If <script type="math/tex">\sum_{n = 1}^{\infty} f_n</script> converges uniformly on <script type="math/tex">A</script>,
then there exist constants <script type="math/tex">M_n</script> such that
<script type="math/tex">|f_n(x)| \leq M_n</script> for all <script type="math/tex">x \in A</script> and <script type="math/tex">\sum_{n = 1}^{\infty}M_n</script> converges.</p>
<p><strong>Solution</strong>: Let <script type="math/tex">f_1(x) = x</script>, for <script type="math/tex">n > 1, f_n(x) = 0</script>.
<script type="math/tex">\sum_{n = 1}^{\infty} f_n</script> converges to <script type="math/tex">x</script>, but we cannot
find <script type="math/tex">M_1</script> such that <script type="math/tex">|f_1(x)| \leq M_1</script> for all <script type="math/tex">x \in A</script>.</p>
<p>This is a boring example, a more interested example is presented
<a href="https://solverer.com/library/stephen_abbott/understanding_analysis/exercise_6-4-2">here</a>.</p>
<p>It constructs <script type="math/tex">M_n</script> like this:</p>
<p>
<script type="math/tex; mode=display"> 
M_1 = 1 \\
M_2 = M_3 = 1/2 \\
M_4 = M_5 = M_6 = M_7 = 1/4 \\
\cdots
</script>
</p>
<p>Then <script type="math/tex">\sum_{n = 1}^{\infty}M_n</script> does not converge.</p>
<h3 id="643">6.4.3.</h3>
<p>(a) Show that</p>
<p>
<script type="math/tex; mode=display"> 
g(x) = \sum_{n = 0}^{\infty}
\frac{\cos (2^nx)}{2^n}
</script>
</p>
<p>is continuous on all of <script type="math/tex">\mathbf{R}</script>.</p>
<p><strong>Proof</strong>: Given any <script type="math/tex">[-M, M]</script>, apply Theorem 6.4.4 (Cauchy Criterion for Uniform Convergence of Series),</p>
<p>
<script type="math/tex; mode=display"> 
\left| g_{m+1} + \cdots + g_{n} \right| \leq
\frac{1}{2^{m+1}} + \cdots + \frac{1}{2^n} \\
< \frac{1}{2^m}
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) The function <script type="math/tex">g</script> was cited in Section 5.4 as an example of a continuous
nowhere diﬀerentiable function. What happens if we try to use Theorem
6.4.3 to explore whether <script type="math/tex">g</script> is diﬀerentiable?</p>
<p><strong>Solution</strong>: Let</p>
<p>
<script type="math/tex; mode=display"> 
h_n(x) = g_n'(x) = - \sin (2^n x).
</script>
</p>
<p>We can see <script type="math/tex">\sum_{n = 1}^{\infty} h_n(x)</script> is not uniformly converging.</p>
<p>Because <script type="math/tex">|h_n(1/2^{n+1}\pi)| = \sin (\pi / 2) = 1</script>.
Then apply Theorem 6.4.4 (Cauchy Criterion for Uniform Convergence of Series), we prove this.</p>
<p>So we cannot use Theorem 6.4.3 to explore whether <script type="math/tex">g</script> is diﬀerentiable.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="644">6.4.4.</h3>
<p>Define</p>
<p>
<script type="math/tex; mode=display"> 
g(x) = \sum_{n = 1}^{\infty}
\frac{x^{2n}}{1 + x^{2n}}
</script>
</p>
<p>Find the values of <script type="math/tex">x</script> where the series converges and show that we get a continuous function on this set.</p>
<p><strong>Solution</strong>: Let</p>
<p>
<script type="math/tex; mode=display"> 
g_n(x) = \frac{x^{2n}}{1 + x^{2n}}
</script>
</p>
<p>When <script type="math/tex">|x| \geq 1</script>, <script type="math/tex">g_n(x) \geq \frac{1}{2}</script>, so <script type="math/tex">g(x)</script> does
not converge.</p>
<p>When <script type="math/tex">|x| < 1</script>, <script type="math/tex">g_n(x) < x^{2n}</script>. Then given <script type="math/tex">x</script>,</p>
<p>
<script type="math/tex; mode=display"> 
\left| g_{m+1} + \cdots + g_{n} \right| < \\
x^{2(m+1)} + x^{2n} = \\
\frac{x^{2(m+1)} - x^{2(n+1)}}{1 - x^2} < \\
\frac{x^{2(m+1)}}{1 - x^2} \rightarrow 0
</script>
</p>
<p>For any <script type="math/tex">|x| < 1</script>, we can get <script type="math/tex">|x| < M < 1</script>. Then we have</p>
<p>
<script type="math/tex; mode=display"> 
\frac{x^{2(m+1)}}{1 - x^2} \leq \frac{M^{2(m+1)}}{1-M^2}
</script>
</p>
<p>So <script type="math/tex">g(x)</script> converges uniformly on <script type="math/tex">[-M, M]</script>. <script type="math/tex">g(x)</script> is continuous
at <script type="math/tex">x</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="645">6.4.5.</h3>
<p>(a) Prove that</p>
<p>
<script type="math/tex; mode=display"> 
h(x) = \sum_{n = 1}^{\infty} \frac{x^n}{n^2}
</script>
</p>
<p>is continuous on <script type="math/tex">[-1, 1]</script>.</p>
<p><strong>Proof</strong>: <script type="math/tex">\left| \frac{x^n}{n^2} \right| \leq \frac{1}{n^2}</script>
and <script type="math/tex">\sum_{n = 1}^{\infty} \frac{1}{n^2}</script> converges.
So based on Corollary 6.4.5 (Weierstrass M-Test), <script type="math/tex">h(x)</script> converges
uniformly. So <script type="math/tex">h(x)</script> is continuous.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) The series</p>
<p>
<script type="math/tex; mode=display"> 
h(x) = \sum_{n = 1}^{\infty} \frac{x^n}{n}
</script>
</p>
<p>converges for every <script type="math/tex">x</script> in the half-open interval <script type="math/tex">[−1,1)</script> but does not converge when <script type="math/tex">x = 1</script>. For a fixed <script type="math/tex">x_0 ∈ (−1,1)</script>, explain how we can still use the Weierstrass M-Test to
prove that <script type="math/tex">f</script> is continuous at <script type="math/tex">x_0</script>.</p>
<p><strong>Proof</strong>:</p>
<p>Given <script type="math/tex">x_0 \in (-1, 1)</script>, we can find <script type="math/tex">0 < M < 1</script> such that
<script type="math/tex">x_0 \in [-M, M]</script>, we prove <script type="math/tex">h(x)</script> converges uniformly on
this interval.</p>
<p>
<script type="math/tex; mode=display"> 
|h_n(x)| = |\frac{x^n}{n}| \leq |x|^n \leq M^n
</script>
</p>
<p>And <script type="math/tex">\sum_{n = 1}^{\infty} M^n = \frac{M}{1 - M}</script>.
So <script type="math/tex">h(x)</script> converges uniformly on <script type="math/tex">[-M, M]</script>. Then <script type="math/tex">h(x)</script> is
continuous at <script type="math/tex">x_0</script>.</p>
<h3 id="646">6.4.6.</h3>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \frac{1}{x} - \frac{1}{x + 1} + \frac{1}{x + 2}
- \frac{1}{x + 3} + \frac{1}{x + 4} - \cdots
</script>
</p>
<p>Show <script type="math/tex">f</script> is defined for all <script type="math/tex">x > 0</script>. Is <script type="math/tex">f</script> continuous on
<script type="math/tex">(0, +\infty)</script>? How about diﬀerentiable?</p>
<p><strong>Proof</strong>:</p>
<p>Let</p>
<p>
<script type="math/tex; mode=display">
f_1(x) = \frac{1}{x} - \frac{1}{x + 1} \\
f_2(x) = \frac{1}{x + 2} - \frac{1}{x + 3} \\
f_3(x) = \frac{1}{x + 4} - \frac{1}{x + 5} \\
\cdots \\
f_n(x) = \frac{1}{x + 2n - 2} - \frac{1}{x + 2n - 1} \\
\cdots \\
</script>
</p>
<p>Given <script type="math/tex">x</script>, <script type="math/tex">\sum_{i = 0}^{n} f_i(x)</script> is increasing, and we have</p>
<p>
<script type="math/tex; mode=display"> 
\sum_{i = 0}^{n} f_i(x) <
\sum_{i = 0}^{n} \frac{1}{x + i - 1} - \frac{1}{x + i}\\
< \frac{1}{x} - \frac{1}{x + n} < \frac{1}{x}
</script>
</p>
<p>So it's upper bounded. So <script type="math/tex">f(x)</script> converges.</p>
<p>Then let's check</p>
<p>
<script type="math/tex; mode=display"> 
|f_{m+1}(x) + \cdots + f_n(x)| \\
= 
\sum_{i = m+1}^{n}\frac{1}{x + 2i - 2} - \frac{1}{x + 2i - 1} \\
< \sum_{i = m+1}^{n} \frac{1}{x + i - 1} - \frac{1}{x + i} \\
= \frac{1}{x + m} - \frac{1}{x + n} < \frac{1}{m}
</script>
</p>
<p>That means <script type="math/tex">\sum_{n = 0}^{\infty} f_n(x)</script> converges uniformly
from Theorem 6.4.4. So <script type="math/tex">f(x)</script> is continuous.</p>
<p>Now, let's examine the if it's differentiable.</p>
<p>
<script type="math/tex; mode=display"> 
f_n'(x) =
\frac{1}{(x+2n-1)^2} - \frac{1}{(x + 2n - 2)^2}
</script>
</p>
<p>Then we have</p>
<p>
<script type="math/tex; mode=display"> 
|\sum_{i = m+1}^{n} f_i'(x)| \\
= \left| \sum_{i = m+1}^{n} \frac{1}{(x+2i-2)^2} - \frac{1}{(x + 2i - 1)^2} \right| \\
< \left| \sum_{i = m+1}^{n} \frac{1}{(x+2i-2)^2} + \frac{1}{(x + 2i - 1)^2} \right| \\
< \left| \sum_{i = m+1}^{n} \frac{1}{x + 2i - 2} - \frac{1}{x + 2i} \right| \\
= \left| \frac{1}{x + 2m} - \frac{1}{x + 2n} \right| \\
< \frac{1}{2m}
</script>
</p>
<p>That means <script type="math/tex">\sum_{n = 0}^{\infty} f_n'(x)</script> converges uniformly
from Theorem 6.4.4. So <script type="math/tex">f(x)</script> is differentiable.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="647">6.4.7.</h3>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \sum_{k = 1}^{\infty } \frac{\sin (kx)}{k^3} 
</script>
</p>
<p>Anwser:</p>
<p>(a) Show that <script type="math/tex">f(x)</script> is diﬀerentiable and that the
derivative <script type="math/tex">f'(x)</script> is continuous.</p>
<p><strong>Proof</strong>: We have</p>
<p>
<script type="math/tex; mode=display"> 
f_k(x) = \frac{\sin (kx)}{k^3} \\
f_k'(x) = \frac{\cos (kx)}{k^2}
</script>
</p>
<p>Then we have <script type="math/tex">|f_k'(x)| \leq \frac{1}{k^2}</script>, and
<script type="math/tex">\sum_{k = 1}^{\infty} \frac{1}{k^2}</script> converges. So
based on Corollary 6.4.5, <script type="math/tex">\sum_{k = 1}^{\infty} f_k'(x) \rightarrow g(x)</script> converges uniformly. That means <script type="math/tex">f</script> is differentiable, and <script type="math/tex">f'(x) = g(x)</script>.
Each <script type="math/tex">\sum_{k = 1}^{n} f_k'(x)</script> is continuous, so <script type="math/tex">g(x)</script> is
also continuous.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Can we determine if f is twice-diﬀerentiable?</p>
<p><strong>Solution</strong>: Consider</p>
<p>
<script type="math/tex; mode=display"> 
g_k(x) = -f_k''(x) = \frac{\sin (kx)}{k}
</script>
</p>
<p>Consider <script type="math/tex">x = \pi / 2</script>
</p>
<p>
<script type="math/tex; mode=display"> 
\sum_{n = 1}^{\infty}
\frac{\sin (n \frac{pi}{2})}{n} \\
= 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \cdots
</script>
</p>
<p>I cannot evne figure out if
<script type="math/tex">\sum_{n = 1}^{\infty} g_k(x)</script> converges. </p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="648">6.4.8.</h3>
<p>Consider the function</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \sum_{k = 1}^{\infty } \frac{\sin (x/k)}{k} 
</script>
</p>
<p>Where is <script type="math/tex">f</script> defined? Continuous? Diﬀerentiable? Twice-diﬀerentiable?</p>
<p><strong>Solution</strong>:</p>
<p>We will need this fact: <script type="math/tex">\sin x \leq x</script> for <script type="math/tex">x \geq 0</script>.
Let <script type="math/tex">g(x) = x - \sin x</script>, <script type="math/tex">g'(x) = 1 - \cos x \geq 0</script>.
Therefore, <script type="math/tex">g(x) - g(0) = g(x) = g'(c)x \geq 0</script>.
So <script type="math/tex">x \geq \sin x</script>.</p>
<p>Let <script type="math/tex">f_n(x) = \frac{\sin (x/k)}{k}</script>. Given <script type="math/tex">x</script>, consider</p>
<p>
<script type="math/tex; mode=display"> 
|f_{m+1}(x) + \cdots + f_n(x)| \leq \\
|f_{m+1}(x)| + \cdots + |f_n(x)| \leq \\
\frac{|x|}{(m+1)^2} + \cdots \frac{|x|}{n^2} < \\
\frac{|x|}{m} - \frac{|x|}{n} < \frac{|x|}{m}
</script>
</p>
<p>So <script type="math/tex">\sum_{n = 1}^{\infty}f_n(x)</script> converges for all <script type="math/tex">x \in \mathbf{R}</script>.
So <script type="math/tex">f(x)</script> is defined for <script type="math/tex">x \in \mathbf{R}</script>.</p>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
g_n(x) = f_n'(x) = \frac{\cos (x/n)}{n^2} \\
</script>
</p>
<p>Then we have</p>
<p>
<script type="math/tex; mode=display"> 
|g_{m+1}(x) + \cdots + g_n(x)| \leq \\
|g_{m+1}(x)| + \cdots + |g_n(x)| \leq \\
\frac{1}{(m+1)^2} + \cdots \frac{1}{n^2} < \\
\frac{1}{m} - \frac{1}{n} < \frac{1}{m}
</script>
</p>
<p>That means <script type="math/tex">\sum_{n = 1}^{\infty} g_n(x) \rightarrow g(x)</script>
uniformly. We also know <script type="math/tex">\sum_{n = 1}^{\infty}f_n(x)</script> converges for all <script type="math/tex">x \in \mathbf{R}</script>. Then <script type="math/tex">f</script> is differentiable,
and <script type="math/tex">f' = g</script>.</p>
<p>Since it's differentiable, it has to be continuous.</p>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
h_n(x) = g_n'(x) = -\frac{\sin (x/n)}{n^3}
</script>
</p>
<p>Since <script type="math/tex">|h_n(x)| < \frac{1}{n^2}</script> and <script type="math/tex">\sum_{n = 1}^{\infty}\frac{1}{n^2}</script> converges, then <script type="math/tex">\sum_{n = 1}^{\infty}h_n(x)</script> converges uniformly. </p>
<p>Also since <script type="math/tex">\sum_{n = 1}^{\infty}g_n(0)</script> converges, then we know
<script type="math/tex">g(x)</script> is differentiable and <script type="math/tex">g'(x) = h(x)</script>. So <script type="math/tex">f</script> is Twice-diﬀerentiable everywhere.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="649">6.4.9.</h3>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
h(x) = \sum_{n = 1}^{\infty}
\frac{1}{x^2 + n^2}
</script>
</p>
<p>Answer:</p>
<p>(a) Show that <script type="math/tex">h</script> is a continuous function defined on all of <script type="math/tex">\mathbf{R}</script>.</p>
<p><strong>Proof</strong>: let</p>
<p>
<script type="math/tex; mode=display"> 
h_n(x) = \frac{1}{x^2 + n^2}
</script>
</p>
<p>Then <script type="math/tex">h_n(x)</script> is continuous. Also <script type="math/tex">h_n(x) \leq \frac{1}{n^2}</script>,
and we know <script type="math/tex">\sum_{n = 1}^{\infty} \frac{1}{n^2}</script> converges.</p>
<p>So <script type="math/tex">h</script> converges uniformly on <script type="math/tex">\mathbf{R}</script>. Based on Theorem 6.4.2, <script type="math/tex">h</script> is continuous on <script type="math/tex">\mathbf{R}</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Is <script type="math/tex">h</script> diﬀerentiable? If so, is the derivative function <script type="math/tex">h'</script> continuous?</p>
<p><strong>Proof</strong>: Let</p>
<p>
<script type="math/tex; mode=display"> 
g_n(x) = -h_n'(x) = \frac{2x}{(x^2 + n^2)^2}
</script>
</p>
<p>If we plot the <script type="math/tex">g_n(x)</script>, we can see <script type="math/tex">g_n(x)</script> reaches its
maximum value some where. We want to find this maximum value.
So we get derivative of <script type="math/tex">g_n(x)</script>.</p>
<p>
<script type="math/tex; mode=display"> 
g_n'(x) = \frac{2(x^2 + n^2)^2 - 2x2(x^2+n^2)2x}{(x^2 + n^2)^2}\\
= \frac{(2x^4 + 4x^2n^2+2n^4) - (8x^4+8x^2n^2)}{(x^2 + n^2)^2}\\
= \frac{-6x^4 - 4x^2n^2 + 2n^4}{(x^2 + n^2)^2}
</script>
</p>
<p>If we set <script type="math/tex">g_n'(x) = 0</script>, we have <script type="math/tex">x^2 = \frac{1}{3}n^2</script>.
And then</p>
<p>
<script type="math/tex; mode=display"> 
\sup g_n(x) = g_n(\sqrt[]{1/3}n) \\
= \frac{\frac{2}{\sqrt[]{3}}n}{\frac{16}{9}n^4} < \frac{1}{n^3}
</script>
</p>
<p>Then we can see <script type="math/tex">\sum_{n = 1}^{\infty}g_n'(x)</script> converges
uniformly. So <script type="math/tex">h</script> is differentiable and since each <script type="math/tex">g_n(x)</script> is
continuous, <script type="math/tex">h'</script> is continuous.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="6410">6.4.10.</h3>
<p>Let <script type="math/tex">\{r_1,r_2,r_3,...\}</script> be an enumeration of the set of
rational numbers. For each <script type="math/tex">r_n ∈ \mathbf{Q}</script>, define</p>
<p>
<script type="math/tex; mode=display"> 
u_n(x) =
\begin{cases}
    1/2^n &\text{for } x > r_n   \\
    0     &\text{for } x \leq r_n\\
\end{cases}
</script>
</p>
<p>Now let <script type="math/tex">h(x) = \sum_{n = 1}^{\infty}u_n(x)</script>.
Prove that <script type="math/tex">h</script> is a monotone function defined on
all of <script type="math/tex">\mathbf{R}</script> that is continuous at every irrational point.</p>
<p>Proof: First <script type="math/tex">u_n(x) \leq 1/2^n</script>, based on Corollary 6.4.5 (Weierstrass M-Test), <script type="math/tex">\sum_{n = 1}^{\infty}u_n(x)</script> converges
to <script type="math/tex">h(x)</script> uniformly. So <script type="math/tex">h(x)</script> is well-defined.</p>
<p>Assume <script type="math/tex">x < y</script>, then <script type="math/tex">u_n(x) < u_n(y)</script> for all <script type="math/tex">n</script>.
Thus <script type="math/tex">h(x) \leq h(y)</script>.</p>
<p>Given <script type="math/tex">x \not \in \mathbf{Q}</script>, and <script type="math/tex">\epsilon > 0</script>.
We want to find <script type="math/tex">\delta</script>, if <script type="math/tex">|x - y| < \delta</script>, then
<script type="math/tex">|h(y) - h(x)| < \epsilon</script>.</p>
<p>Let <script type="math/tex">h_n(x) = \sum_{k = 1}^{n}u_n(x)</script>. We can find <script type="math/tex">N</script>, such that <script type="math/tex">|h_n(x) - h(x)| < \epsilon / 2</script>
for <script type="math/tex">n > N</script>.</p>
<p>Pick any <script type="math/tex">n > N</script>. Since <script type="math/tex">x</script> is
an irrational number, we can find <script type="math/tex">U_{\delta}(x)</script>, such that
<script type="math/tex">r_1, r_2, \cdots, r_n \notin U_{\delta}(x)</script>.</p>
<p>Let <script type="math/tex">y \in U_{\delta}(x)</script>, note <script type="math/tex">u_k(x) = u_k(y)</script> for
all <script type="math/tex">k \leq n</script>. </p>
<p>
<script type="math/tex; mode=display"> 
h_n(x) - h_n(y) =
\sum_{k = 1}^{n} u_k(x) - u_k(y) = 0
</script>
</p>
<p>Finally we have</p>
<p>
<script type="math/tex; mode=display"> 
|h(x) - h(y)| =
|h(x) - h_n(x)| + |h_n(x) - h_n(y)| + |h_n(y) - h(y)| <
\epsilon / 2 + 0 + \epsilon / 2 = \epsilon
</script>
</p>
<p>So <script type="math/tex">h(x)</script> is continuous at every irrational point.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h2 id="65-power-series">6.5. Power Series</h2>
<h3 id="651">6.5.1</h3>
<p>Consider the function <script type="math/tex">g</script> defined by the power series</p>
<p>
<script type="math/tex; mode=display"> 
g(x) = x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4}
</script>
</p>
<h3 id="652">6.5.2</h3>
<p>Find suitable coeﬃcients <script type="math/tex">(a_n)</script> so that the resulting power
series <script type="math/tex">\sum_{n = 0}^{\infty}a_n x^n</script> has the given
properties, or explain why such a request is impossible</p>
<p>(a) Converges for every value of <script type="math/tex">x ∈ R</script>.</p>
<p><strong>Solution</strong>: Let <script type="math/tex">a_n = 0</script> for all <script type="math/tex">n</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Diverges for every value of <script type="math/tex">x ∈ R</script>.</p>
<p><strong>Solution</strong>: It converges at 0.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Converges absolutely for all <script type="math/tex">x ∈ [−1,1]</script> and diverges oﬀ of this set.</p>
<p><strong>Solution</strong>: Consider</p>
<p>
<script type="math/tex; mode=display"> 
\sum_{n = 1}^{\infty} \frac{x^n}{n^2}
</script>
</p>
<p>Because <script type="math/tex">\lim_{n \to \infty} \frac{x^n}{n^2} = \infty</script> so it is
not bounded.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(d) Converges conditionally at <script type="math/tex">x =−1</script> and converges absolutely
at <script type="math/tex">x = 1</script>.</p>
<p><strong>Proof</strong>: This is not impossible. Because
<script type="math/tex">|a_n(-1)^n| = |a_n (1)^n|</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(e) Converges conditionally at both <script type="math/tex">x =−1</script> and <script type="math/tex">x = 1</script>.</p>
<p><strong>Solution</strong>: Consider</p>
<p>
<script type="math/tex; mode=display"> 
\sum_{n = 0}^{\infty} a_n x^n = 1 - \frac{x^2}{2} + \frac{x^4}{4}
-\frac{x^6}{6} + \cdots 
</script>
</p>
<p>When <script type="math/tex">x =−1</script> and <script type="math/tex">x = 1</script>, the power series becomes</p>
<p>
<script type="math/tex; mode=display"> 
1 - \frac{1}{2} + \frac{1}{4} -\frac{1}{6} + \cdots
</script>
</p>
<p>Using Cauchy Criterion, we can see it converges.
But is is not absolute converging, because</p>
<p>
<script type="math/tex; mode=display"> 
1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{6} + \cdots
</script>
</p>
<p>does not converge.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="653">6.5.3</h3>
<p>Use the Weierstrass M-Test to prove Theorem 6.5.2.</p>
<p>Theorem 6.5.2 states If a power series <script type="math/tex">\sum_{n = 0}^{\infty}a_nx^n</script> converges absolutely at a point
<script type="math/tex">x_0</script>, then it converges uniformly on the closed interval <script type="math/tex">[−c,c]</script>, where <script type="math/tex">c = |x_0|</script>.</p>
<p><strong>Proof</strong>: Let <script type="math/tex">M_n = |a_nc^n|</script>, and <script type="math/tex">\sum M_n</script> converges.</p>
<p>For <script type="math/tex">x \in [-c, c]</script>, <script type="math/tex">|a_nx^n| < |a_nc^n|</script>. So
it converges uniformly on the closed interval <script type="math/tex">[−c,c]</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="654-term-by-term-antidifferentiation">6.5.4 (Term-by-term Antidiﬀerentiation).</h3>
<p>Assume <script type="math/tex">f(x) = \sum_{n = 0}^{\infty}a_{n} x^{n}</script> converges on
<script type="math/tex">(-R, R)</script>.</p>
<p>(a) Show</p>
<p>
<script type="math/tex; mode=display"> 
F(x) = \sum_{n = 0}^{\infty}\frac{a_{n}}{n+1} x^{n+1}
</script>
</p>
<p>is defined on <script type="math/tex">(-R, R)</script> and satisfies <script type="math/tex">F'(x) = f(x)</script>.</p>
<p>Proof: Given <script type="math/tex">x \in (-R, R)</script>, <script type="math/tex">\sum_{n = 0}^{\infty}a_{n} x^{n}</script>
converges absolutely. We can find <script type="math/tex">n</script> such that <script type="math/tex">n+1 > x</script>.
So</p>
<p>
<script type="math/tex; mode=display"> 
\left| \frac{a_n}{n+1} x^{n+1} \right| =
\left| \frac{x}{n+1} a_{n}x^n\right| <
\left| a_{n} x^n \right|
</script>
</p>
<p>So <script type="math/tex">F(x)</script> is defined on <script type="math/tex">(-R, R)</script>.</p>
<p>Given <script type="math/tex">c \in (-R, R)</script>, <script type="math/tex">f(c)</script> converges. From Abel's theorem,
<script type="math/tex">f(x)</script> converges uniformly on <script type="math/tex">[0,c]</script>.
From Theorem 6.3.1, <script type="math/tex">F(x)</script> is differentiable on <script type="math/tex">[0, c]</script> and
<script type="math/tex">F'(x) = f(x)</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Antiderivatives are not unique. If <script type="math/tex">g</script> is an arbitrary
function satisfying <script type="math/tex">g'(x) = f(x)</script> on <script type="math/tex">(-R, R)</script>.
Find a power series representation for <script type="math/tex">g</script>.</p>
<p><strong>Proof</strong>: Consider <script type="math/tex">h(x) = g(x) - F(x)</script>.</p>
<p>See the exercise 6.5.8, we can prove <script type="math/tex">g(x) = F(x) + c</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="655">6.5.5.</h3>
<p>(a) If <script type="math/tex">s</script> satisfies <script type="math/tex">0 < s < 1</script>, show <script type="math/tex">ns^{n−1}</script> is bounded for
all <script type="math/tex">n ≥ 1</script>.</p>
<p><strong>Proof</strong>: </p>
<p>We compare <script type="math/tex">ns^{n-1}</script> and <script type="math/tex">(n+1)s^n</script> and we have <script type="math/tex">ns^{n-1} > (n+1)s^n</script>, when <script type="math/tex">\frac{n}{n+1} > s</script>. So <script type="math/tex">ns^{n-1}</script> is bounded.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Given an arbitrary <script type="math/tex">x ∈ (−R,R)</script>, pick <script type="math/tex">t</script> to satisfy <script type="math/tex">|x| < t < R</script>. Use this start to construct a proof for Theorem 6.5.6.</p>
<p><strong>Proof</strong>:</p>
<p>Consider</p>
<p>
<script type="math/tex; mode=display"> 
\sum_{n = 1}^{\infty} n a_n x^{n-1} =
\sum_{n = 1}^{\infty}
n \left( \frac{x}{t} \right) ^ {n-1} a_n t^{n-1}
</script>
</p>
<p>Since <script type="math/tex">t < R</script>, then <script type="math/tex">\sum_{n = 1}^{\infty} a_n t^{n-1}</script> converges
absolutely. Let <script type="math/tex">|n \left( \frac{x}{t} \right) ^ {n-1}| \leq M</script>,</p>
<p>
<script type="math/tex; mode=display">
\left| 
(m+1) \left( \frac{x}{t} \right) ^ {m} a_{m+1} t^{m} + \cdots +
n \left( \frac{x}{t} \right) ^ {n-1} a_n t^{n-1}
\right|
< \\ 
\left| 
(m+1) \left( \frac{x}{t} \right) ^ {m} a_{m+1} t^{m}
\right| + \cdots +
\left| 
n \left( \frac{x}{t} \right) ^ {n-1} a_n t^{n-1}
\right|
< \\
M (|a_{m+1} t^{m}| + \cdots + |a_n t^{n-1}|) < \epsilon
</script>
</p>
<p>So <script type="math/tex">\sum_{n = 1}^{\infty}na_n x^{n-1}</script> converges at each
<script type="math/tex">x ∈ (−R,R)</script> as well.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="656">6.5.6.</h3>
<p>Previous work on geometric series (Example 2.7.5) justifies
the formula</p>
<p>
<script type="math/tex; mode=display"> 
\frac{1}{1 - x} =
1 + x + x^2 + x^3 + x^4 + \cdots , \text{ for all } |x| < 1.
</script>
</p>
<p>Find the following 2 sums:</p>
<p>(a) <script type="math/tex">\sum_{n = 1}^{\infty} n/2^n</script>
</p>
<p><strong>Solution</strong>: we take derivative on the right side</p>
<p>
<script type="math/tex; mode=display"> 
1 + 2x + 3x^2 + \cdots =\\
(1 + x + x^2 + x^3 + \cdots ) + \sum_{n = 1}^{\infty} n/2^n
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\sum_{n = 1}^{\infty} n/2^n = \frac{1}{(1-x)^2} - \frac{1}{1-x}\\
=\frac{x}{(1-x)^2} = 2
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) <script type="math/tex">\sum_{n = 1}^{\infty} n^2/2^n</script>
</p>
<p><strong>Solution</strong>: Consider</p>
<p>
<script type="math/tex; mode=display"> 
\sum_{n = 1}^{\infty} (nx^n)' =
\sum_{n = 1}^{\infty} n^2 x^{n-1} = \\
1 + \sum_{n = 1}^{\infty} (n+1)^2x^n = \\
1 + \sum_{n = 1}^{\infty} n^2 x^n + 2 \sum_{n = 1}^{\infty} nx^n
+ \sum_{n = 1}^{\infty}x^n
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
\frac{(1-x)^2 +2 x (1-x)}{(1-x)^4} =\\
\frac{1+x}{(1-x)^3} =\\
1 + S + \frac{2x}{(1-x)^2} + \frac{x}{1 - x}\\
S = 12 - 1 - 4 - 1 = 6
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="657">6.5.7.</h3>
<p>Let <script type="math/tex">\sum_{n = 1}^{\infty} a_nx_n</script> be a power series with
<script type="math/tex">a_n  \not = 0</script>, and assume</p>
<p>
<script type="math/tex; mode=display"> 
L = \lim_{n \to \infty} 
\left| \frac{a_{n+1}}{a_n} \right|
</script>
</p>
<p>exists.</p>
<p>(a) Show that if <script type="math/tex">L \not = 0</script>, then the series converges for
all <script type="math/tex">x</script> in <script type="math/tex">(-1/L, 1/L)</script>.
(The advice in Exercise 2.7.9 may be helpful.)</p>
<p><strong>Proof</strong>: fix <script type="math/tex">x \in (-1/L, 1/L)</script>, we can find <script type="math/tex">\epsilon, r > 0</script> such that
<script type="math/tex">0 \leq |x| < r < \frac{1}{L + \epsilon}</script>.</p>
<p>So when <script type="math/tex">n</script> is large enough, we have</p>
<p>
<script type="math/tex; mode=display"> 
|x| < r  < \frac{1}{L + \epsilon} < \left| \frac{a_n}{a_{n+1}} \right| \leq 1/L \\
|a_{n+1} x^{n+1}| = |\frac{a_{n+1}}{a_{n}} x | | a_n x^n | \\
< r (L +\epsilon) |a_n x^n|
</script>
</p>
<p>And note <script type="math/tex">r (L + \epsilon ) < 1</script>, so the series converges at <script type="math/tex">x</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Show that if <script type="math/tex">L = 0</script>, then the series converges for all
<script type="math/tex">x ∈ \mathbf{R}</script>.</p>
<p><strong>Proof</strong>: Given any <script type="math/tex">x \in \mathbf{R}</script>, we can find <script type="math/tex">|x| < M</script>.
When <script type="math/tex">n</script> is large enough, <script type="math/tex">\left| \frac{a_{n+1}}{a_n} \right| < \frac{1}{2M}</script>. So</p>
<p>
<script type="math/tex; mode=display"> 
|a_{n+1} x^{n+1}| = |\frac{a_{n+1}}{a_{n}} x | | a_n x^n |\\
< \frac{1}{2} |a_{n} x|
</script>
</p>
<p>the series converges for all <script type="math/tex">x ∈ \mathbf{R}</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Show that (a) and (b) continue to hold if <script type="math/tex">L</script> is replaced by the limit</p>
<p>
<script type="math/tex; mode=display"> 
L' = \lim_{n \to \infty} s_n \text{ when }
s_n = \sup \left\{
\left| 
    \frac{a_{k+1}}{a_k}
\right| : k \geq n
\right\}.
</script>
</p>
<p><strong>Proof</strong>: if <script type="math/tex">L' = 0</script>, then <script type="math/tex">L = 0</script>, it becomes (b).
If <script type="math/tex">L' > 0</script>, let <script type="math/tex">L_n = \left| \frac{a_{n+1}}{a_n} \right|</script>
</p>
<p>fix <script type="math/tex">x \in (-1/L', 1/L')</script>, we can find <script type="math/tex">N, r > 0</script>
such that <script type="math/tex">0 \leq |x| < r < \frac{1}{L'_N} \leq \frac{1}{L}</script>.</p>
<p>So, for <script type="math/tex">n > N</script>,</p>
<p>
<script type="math/tex; mode=display"> 
|a_{n+1} x^{n+1}| = |\frac{a_{n+1}}{a_{n}} x | | a_n x^n | \\
< r L_N |a_n x^n|
</script>
</p>
<p>And note <script type="math/tex">r L_N < 1</script>, so the series converges at <script type="math/tex">x</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="658">6.5.8.</h3>
<p>(a) Show that power series representations are unique.
If we have</p>
<p>
<script type="math/tex; mode=display"> 
\sum_{n = 0}^{\infty} a_n x^n = 
\sum_{n = 0}^{\infty} b_n x^n
</script>
</p>
<p>for all <script type="math/tex">x</script> in an interval <script type="math/tex">(−R,R)</script>, prove that <script type="math/tex">a_n = b_n</script> for
all <script type="math/tex">n = 0,1,2, \cdots</script>
</p>
<p><strong>Proof</strong>: Set <script type="math/tex">x = 0</script>, then we have <script type="math/tex">a_0 = b_0</script>.
Consider</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \sum_{n = 0}^{\infty} (a_n - b_n) x^n
</script>
</p>
<p>
<script type="math/tex">f(x)</script> converges to <script type="math/tex">0</script> in the interval <script type="math/tex">(−R,R)</script>.
From Theorem 6.5.7, <script type="math/tex">f</script> is infinitely diﬀerentiable on <script type="math/tex">(−R,R)</script>.
Also note <script type="math/tex">f^{(n)}(x) = 0</script>.</p>
<p>On the other hand</p>
<p>
<script type="math/tex; mode=display"> 
f^{(n)}(0) = a_n - b_n 
</script>
</p>
<p>So <script type="math/tex">a_n = b_n</script> for all <script type="math/tex">n = 0,1,2, \cdots</script>.</p>
<p>(b) Let <script type="math/tex">f(x) = \sum_{n = 0}^{\infty}a_nx^n</script>, converge on <script type="math/tex">(−R,R)</script>, and assume <script type="math/tex">f'(x) = f(x)</script> for all <script type="math/tex">x ∈ (−R,R)</script> and <script type="math/tex">f(0) = 1</script>. Deduce the values of <script type="math/tex">a_n</script>.</p>
<p><strong>Solution</strong>: <script type="math/tex">a_0 = f(0) = 1</script>.</p>
<p>
<script type="math/tex; mode=display"> 
f'(x) = \sum_{n = 1}^{\infty} na_n x^{n-1}
</script>
</p>
<p>Based on (a), we have</p>
<p>
<script type="math/tex; mode=display"> 
na_n = a_{n-1}
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="659">6.5.9.</h3>
<p>Review the definitions and results from Section 2.8 concerning
products of series and Cauchy products in particular.
At the end of Section 2.9, we mentioned the following result:
If <script type="math/tex">\sum_{}^{}a_n</script> and <script type="math/tex">\sum_{}^{}b_n</script> converge conditionally
to <script type="math/tex">A</script> and <script type="math/tex">B</script> respectively, then it is possible for the Cauchy product,</p>
<p>
<script type="math/tex; mode=display"> 
\sum_{}^{}d_n \text{ where } d_n = a_0 b_n + a_1 b_{n-1} +
\cdots + a_n b_0,
</script>
</p>
<p>to diverge. However, if <script type="math/tex">\sum_{}^{}d_n</script> does converge, then
it must converge to <script type="math/tex">AB</script>. To prove this, set</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \sum a_n x^n, 
g(x) = \sum b_n x^n,
\text{ and }
h(x) = \sum d_n x^n
</script>
</p>
<p>Use Abel’s Theorem and the result in Exercise 2.8.7 to establish this result.</p>
<p><strong>Proof</strong>: Let <script type="math/tex">x_m = \frac{m}{m+1}</script>, since <script type="math/tex">f(1), g(1)</script> 
converges.
<script type="math/tex">\sum a_n x^n_m</script> and <script type="math/tex">\sum b_n x^n_m</script> converges absolutely.
From Exercise 2.8.7, we have <script type="math/tex">f(x_m)g(x_m) = h(x_m)</script>.</p>
<p>Since <script type="math/tex">f(1), g(1), h(1)</script> converges, these 3 functions are
continuous at <script type="math/tex">1</script>.</p>
<p>Then we have</p>
<p>
<script type="math/tex; mode=display"> 
AB = f(1)g(1) = \lim_{m \to \infty} f(x_m)g(x_m) =
\lim_{m \to \infty} h(x_m) = h(1) = \sum d_n
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="6510">6.5.10</h3>
<p>Let <script type="math/tex">g(x) = \sum_{n = 0}^{\infty}b_nx^n</script> converge on <script type="math/tex">(−R,R)</script>, and assume <script type="math/tex">(x_n) \rightarrow 0</script> with <script type="math/tex">x_n \not = 0</script>. If <script type="math/tex">g(x_n) = 0</script> for all <script type="math/tex">n ∈ \mathbf{N}</script>, show that <script type="math/tex">g(x)</script> must be
identically zero on all of <script type="math/tex">(−R,R)</script>.</p>
<p><strong>Proof</strong>: <script type="math/tex">g(x)</script> is continuous, so <script type="math/tex">g(0)</script> = 0, that means <script type="math/tex">b_0 = 0</script>.
Compare to exercise 5.3.4 and with Mean value theorem, we know
we can find <script type="math/tex">(y_n) \rightarrow 0</script> such that <script type="math/tex">g'(y_n) = 0</script>.
So <script type="math/tex">g'(0) = 0</script>, that means <script type="math/tex">b_1</script>.</p>
<p>For the same reason, <script type="math/tex">b_2 = b_3 = \cdots = 0</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="6511">6.5.11</h3>
<p>A series <script type="math/tex">\sum_{n = 0}^{\infty}a_n</script> is said to be Abel-summable
to <script type="math/tex">L</script> if the power series</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \sum_{n = 0}^{\infty}a_n x^n
</script>
</p>
<p>converges for all <script type="math/tex">x \in [0, 1)</script> and <script type="math/tex">L = \lim_{x \to 1^{-1}} f(x)</script>.</p>
<p>(a) Show that any series that converges to a limit <script type="math/tex">L</script> is also Abel-summable to <script type="math/tex">L</script>.</p>
<p><strong>Proof</strong>: <script type="math/tex">\sum_{n = 0}^{\infty}a_n = L</script>, then we can directly
apply Abel's theorem, <script type="math/tex">f(x)</script> is continuous at <script type="math/tex">1</script>, and
<script type="math/tex">L = \lim_{x \to 1^{-1}} f(x)</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Show that <script type="math/tex">\sum_{n = 0}^{\infty} (-1)^n</script> is Abel-summable and find the sum.</p>
<p><strong>Proof</strong>: Let</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \sum_{n = 0}^{\infty} (-x)^n
</script>
</p>
<p>
<script type="math/tex">f(x)</script> converges for all <script type="math/tex">x \in [0, 1)</script> and it converges to</p>
<p>
<script type="math/tex; mode=display"> 
\frac{1}{1 + x}
</script>
</p>
<p>So the Abel sum is <script type="math/tex">1/2</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h2 id="66-taylor-series">6.6. Taylor Series</h2>
<h3 id="661">6.6.1.</h3>
<p>The derivation in Example 6.6.1 shows the Taylor series for
<script type="math/tex">\arctan(x)</script> is valid for all <script type="math/tex">x ∈ (−1,1)</script>. Notice, however,
that the series also
converges when <script type="math/tex">x = 1</script>. Assuming that <script type="math/tex">\arctan(x)</script> is continuous, explain why the value of the series at <script type="math/tex">x = 1</script> must necessarily
be <script type="math/tex">\arctan(1)</script>. What interesting identity do we get in this
case?</p>
<p>Proof: When <script type="math/tex">x \in (-1, 1)</script>, <script type="math/tex">1 - x^2 + x^4 - x^6 + x^8 - \cdots</script>
converges to <script type="math/tex">\frac{1}{1 + x^2}</script>. Then based on Exercise 6.5.4 (Term-by-term Antidiﬀerentiation).</p>
<p>
<script type="math/tex; mode=display">
F(x) = x - \frac{x^3}{3} + \frac{x^5}{5} - \frac{x^7}{7} + \cdots
</script>
</p>
<p>is defined on <script type="math/tex">(-1, 1)</script> and <script type="math/tex">F'(x) = \frac{1}{1 + x^2}</script>.</p>
<p>So <script type="math/tex">F(x) = c + \arctan x</script> for some <script type="math/tex">c</script>. Then since <script type="math/tex">F(0) = 0</script>
we have <script type="math/tex">c = 0</script>. So <script type="math/tex">F(x) = \arctan x, x \in (-1, 1)</script>.</p>
<p>Since <script type="math/tex">F(x)</script> converges, then based on Abel's theorem,
<script type="math/tex">F(x)</script> is uniformly converging on <script type="math/tex">[0, 1]</script>, then <script type="math/tex">F(x)</script> is
continuous at <script type="math/tex">1</script>. Since we assume <script type="math/tex">\arctan (x)</script> is also
continuous, we have</p>
<p>
<script type="math/tex; mode=display"> 
F(1) = \lim_{x \to 1} F(x) = \lim_{x \to 1} \arctan (x) = 
\arctan (1) = \frac{\pi }{4}
</script>
</p>
<p>So the interesting part is <script type="math/tex">F(x)</script> is defined at <script type="math/tex">1</script>, but
<script type="math/tex">f(x)</script> is not. </p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="662">6.6.2.</h3>
<p>Starting from one of the previously generated series in this
section, use manipulations similar to those in Example 6.6.1 to find Taylor
series representations for each of the following functions. For precisely what
values of x is each series representation valid?</p>
<p>(a) <script type="math/tex">x \cos(x^2)</script>
</p>
<p><strong>Solution</strong>: We stard from <script type="math/tex">\sin x</script>
</p>
<p>
<script type="math/tex; mode=display"> 
\sin x = x - \frac{x^3}{3!}  + \frac{x^5}{5!} - \frac{x^7}{7!}
</script>
</p>
<p>First we get derivative on both side</p>
<p>
<script type="math/tex; mode=display"> 
\cos x = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!}
+ \cdots
</script>
</p>
<p>Then we replace <script type="math/tex">x</script> with <script type="math/tex">x^2</script> and multiply by <script type="math/tex">x</script>,</p>
<p>
<script type="math/tex; mode=display"> 
x \cos x^2 = x - \frac{x^5}{2!} + \frac{x^9}{4!} - \frac{x^{13}}{6!}
</script>
</p>
<p>The Lagrange Remainder of it is</p>
<p>
<script type="math/tex; mode=display"> 
\frac{f^{(N+1)}(c) x^{N+1}}{(N+1)!}
</script>
</p>
<p>We can compute <script type="math/tex">f^{(n)}</script>
</p>
<p>
<script type="math/tex; mode=display"> 
f'(x) = \cos x^2 - 2 x^2 \sin x^2 \\
f''(x) = 2x \cos x^2 - 4x \sin x^2 -4x^3 \cos x^2 \\
f^{(n)} = 2^nx^{n+1} + \delta
</script>
</p>
<p>The Taylor series converges for <script type="math/tex">\mathbf{R}</script>.</p>
<p>(b) <script type="math/tex">x/(1+4x^2)^2</script>
</p>
<p><strong>Solution</strong>: We start with</p>
<p>
<script type="math/tex; mode=display"> 
\frac{1}{1-x} = 1 + x + x^2 + x^3 + \cdots
</script>
</p>
<p>Replace <script type="math/tex">x</script> with <script type="math/tex">-4x^2</script>
</p>
<p>
<script type="math/tex; mode=display"> 
\frac{1}{1 + 4x^2} = 
1 - 4x^2 + 4^2x^4 - 4^3x^{6} + \cdots
</script>
</p>
<p>Then we take derivative on both sides</p>
<p>
<script type="math/tex; mode=display"> 
-\frac{8x}{(1 + 4x^2)^2} = 0 - 2 \cdot 4 x + 4 \cdot 4^2x^3
- 6 \cdot 4^3 x^5 + \cdots \\
x/(1+4x^2)^2 = x - 2 \cdot 4 x^3 + 3 \cdot 4^2 x^5 + \cdots
= \sum_{n = 0}^{\infty} (-1)^n (n+1) 2^{2n} x^{2n+1}
</script>
</p>
<p>If <script type="math/tex">|x| \geq \frac{1}{2}</script>,</p>
<p>
<script type="math/tex; mode=display"> 
\left| (-1)^n (n+1) 2^{2n} x^{2n+1} \right| \geq 
\left| (n+1)2^{2n} (\frac{1}{2})^{2n+1} \right| = \frac{n+1}{2}
</script>
</p>
<p>So it's not bounded. So it converges on <script type="math/tex">(-1/2, 1/2)</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) <script type="math/tex">\log(1+x^2)</script>
</p>
<p>Solution:</p>
<p>First take derivative we get <script type="math/tex">\frac{2x}{1 + x^2}</script>.</p>
<p>
<script type="math/tex; mode=display"> 
\frac{2x}{1 + x^2} = 2x(1 - x^2 + x^4 - x^6 + \cdots)
= 2x - 2x^3 + 2x^5 - 2x^7 + \cdots = g(x)
</script>
</p>
<p>Then we take antiderivatives</p>
<p>
<script type="math/tex; mode=display"> 
\frac{x^2}{1} - \frac{x^4}{2} + \frac{x^6}{3}
- \frac{x^8}{4} + \cdots
</script>
</p>
<p>We can see this series converges on <script type="math/tex">[-1, 1]</script>, but
we are not sure about if it converges to <script type="math/tex">f(x)</script>.</p>
<p>We can use the same argument in the 6.6.1, <script type="math/tex">g(x)</script> is defined
in <script type="math/tex">(-1, 1)</script>, so <script type="math/tex">G(x) = f(x)</script> for <script type="math/tex">x \in (-1, 1)</script>. Also
<script type="math/tex">G(1)</script> is defined, so <script type="math/tex">G(x)</script> is continuous at <script type="math/tex">1</script>, also
<script type="math/tex">f(x)</script> is continuous at <script type="math/tex">1</script>, so <script type="math/tex">G(1) = f(1)</script>, same thing
for <script type="math/tex">G(-1) = f(-1)</script>.</p>
<p>If We want to calculate the Lagrange Remainder, it's complex.</p>
<p>The first derivatives is
<script type="math/tex; mode=display"> 
f'(x) = \frac{2x}{1 + x^2}
</script>
</p>
<p>The 2nd derivative is
<script type="math/tex; mode=display">
f''(x) = \frac{- 2x^2 + 2}{(1 + x^2)^2}
</script>
</p>
<p>The 3rd derivative is</p>
<p>
<script type="math/tex; mode=display">
f'''(x) = \frac{-4x(1+x^2)^2 - 2(1-x^2)2(1+x^2)2x}{(1 + x^2)^4} \\
= \frac{-4x(1+x^2) - 8x(1-x^2)}{(1 + x^2)^3} \\
= \frac{4x^3 - 12x}{(1 + x^2)^3} \\
</script>
</p>
<p>
<script type="math/tex; mode=display">
f^{(4)}(x) = 
\frac{(12x^2-12)(1+x^2)^3 - (4x^3-12x)3(1+x^2)^22x}{(1 + x^2)^6}\\
\\
\frac{12(x^2-1)(x^2+1)-(4x^3-12x)6x}{(1+x^2)^4} \\
\frac{12(x^2-1)(x^2+1)-(4x^3-12x)6x}{(1+x^2)^4} \\
\frac{-12x^4 + 72x^2 - 12}{(1+x^2)^4} \\
</script>
</p>
<p>In genenal, assume</p>
<p>
<script type="math/tex; mode=display"> 
f^{(n)} = \frac{f_n(x)}{(1+x^2)^n} \text{ and } \\
f_n(x) = a^{(n)}_n x^n + a^{(n)}_{n-2} x^{n-2} +
a^{(n)}_{n-4} x^{n-4} + \cdots \\
</script>
</p>
<p>We want to compute</p>
<p>
<script type="math/tex; mode=display"> 
f_{n+1}(x) = a^{(n+1)}_{n+1} x^{n+1}
+ a^{(n+1)}_{n-1} x^{n-1} +
a^{(n+1)}_{n-3} x^{n-3} + \cdots 
</script>
</p>
<p>We have</p>
<p>
<script type="math/tex; mode=display"> 
f_{n+1}(x) = f'_n(x) (1 + x^2) - 2nxf_n(x)
</script>
</p>
<p>So we have</p>
<p>
<script type="math/tex; mode=display"> 
a^{(n+1)}_{n+1} = n a^{(n)}_n - 2n a^{(n)}_n = - na^{(n)}_n \\
a^{(n+1)}_{n-1} = n a^{(n)}_n + (n-2)a^{(n)}_{n-2} - 2n a^{(n)}_{n-2} = n a^{(n)}_n - (n+2) a^{(n)}_{n-2} \\
a^{(n+1)}_{n-3} = (n-2)a^{(n)}_{n-2} + (n-4)a^{(n)}_{n-4} -
2n a^{(n)}_{n-4} = (n-2)a^{(n)}_{n-2} - (n+4) a^{(n)}_{n-4} 
</script>
</p>
<p>So we cannot tell from Lagrange Remainder theorem.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="663">6.6.3.</h3>
<p>Derive the formula for the Taylor coeﬃcients given in
Theorem 6.6.2.</p>
<p>Proof: First note, <script type="math/tex">a_0 = f(0) = 0 = \frac{f^{(1)}}{0!}</script>.</p>
<p>Since <script type="math/tex">\sum_{n = 0}^{\infty}a_{n} x^{n}</script> converges on <script type="math/tex">(-R, R)</script> to
<script type="math/tex">f(x)</script>, then based on Theorem 6.5.7, we have</p>
<p>
<script type="math/tex; mode=display"> 
f'(x) = a_1 + 2 a_2 x + 3 a_3 x^2 + \cdots \\
f^{(2)}(x) = 2 a_2  + 6 a_3 x + \cdots \\
f^{(3)}(x) = 6 a_3 + (4!) a_4 x + \cdots \\
</script>
</p>
<p>Then set <script type="math/tex">x = 0</script>, we have</p>
<p>
<script type="math/tex; mode=display"> 
a_1 = \frac{f^{(1)}}{1!} (0)\\
a_2 = \frac{f^{(2)}}{2!} (0)\\
a_3 = \frac{f^{(3)}}{3!} (0)\\
\cdots
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="664">6.6.4.</h3>
<p>Explain how Lagrange’s Remainder Theorem can be modified
to prove</p>
<p>
<script type="math/tex; mode=display"> 
1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} +
\frac{1}{5} - \frac{1}{6} + \cdots = \log_{} (2)
</script>
</p>
<p><strong>Proof</strong>: Consider <script type="math/tex">f(x) = \log_{} (x)</script>.</p>
<p>
<script type="math/tex; mode=display"> 
S_N(x) = f(1) + \frac{f'(1)}{1} (x - 1) + \frac{f''(1)}{2!}(x-1)^2
+ \cdots + \frac{f^{(N)}(x)}{N!} (x - 1)^N
</script>
</p>
<p>Let <script type="math/tex">E_N(x) = f(x) - S_N(x)</script>.</p>
<p>
<script type="math/tex; mode=display"> 
E_N(1) = f(1) - S_N(1) = 0 \\
E_N^{(1)}(1) = f'(1) - f'(1) = 0 \\
\cdots \\
E_N^{(N)}(1) = f^{(N)}(1) - f^{(N)}(1) = 0 \\
</script>
</p>
<p>Then we have</p>
<p>
<script type="math/tex; mode=display"> 
\frac{E_N(x) - E_N(1)}{(x - 1)^{N+1} - 0} =\\
\frac{E_N(x) - E_N(1)}{(x - 1)^{N+1} - 0} =\\
\frac{f^{(N+1)}(c)}{(N+1)!}(x-1)^{N+1} =\\
\pm \frac{(x-1)^{N+1}}{c^{N+1}(N+1)!}
</script>
</p>
<p>Plug <script type="math/tex">x = 2</script>, then note <script type="math/tex">c \in (1, 2)</script>
</p>
<p>
<script type="math/tex; mode=display"> 
E_N(2) = \frac{1}{c^{N+1} (N+1)!} \rightarrow 0
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="665">6.6.5.</h3>
<p>(a) Generate the Taylor coeﬃcients for the exponential
function <script type="math/tex">f(x) = e^x</script>, and then prove that the corresponding Taylor series converges uniformly to <script type="math/tex">e^x</script> on any interval of the form <script type="math/tex">[−R,R]</script>.</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display"> 
f^{(1)}(0) = e^0 = 1 \\
f^{(2)}(0) = e^0 = 1 \\
\cdots \\
f^{(N+1)}(0) = e^0 = 1 \\
</script>
</p>
<p>So we have</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = 1 + \frac{1}{1} x + \frac{1}{2!} x^2 + \frac{1}{3!} x^3 +
\cdots
</script>
</p>
<p>Based on theorem 6.6.3 (Lagrange’s Remainder Theorem),</p>
<p>
<script type="math/tex; mode=display"> 
E_N(x) = \frac{f^{(N+1)}(c) x^{N+1}}{(N+1)!} 
</script>
</p>
<p>So </p>
<p>
<script type="math/tex; mode=display">
\left| \frac{f^{(N+1)}(c) x^{N+1}}{(N+1)!} \right| \leq
\frac{e^R R^{N+1}}{(N+1)!} \rightarrow 0
</script>
</p>
<p>So <script type="math/tex">E_N(R) \rightarrow 0</script>, then based on Abel's theorem,
Taylor series converges uniformly to <script type="math/tex">e^x</script> on any interval of the form <script type="math/tex">[−R,R]</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Verify the formula <script type="math/tex">f'(x) = e^x</script>.</p>
<p><strong>Proof</strong>: If we take derivative item by item, we get</p>
<p>
<script type="math/tex; mode=display"> 
f'(x) = 1 + x + \frac{1}{2!}x^2 + \frac{1}{3!}x^3 + \cdots
= f(x) = e^x
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Use a substitution to generate the series for <script type="math/tex">e^{−x}</script>, and then informally calculate <script type="math/tex">e^x \cdot e^{−x}</script> by multiplying 
together the two series and collecting common powers of <script type="math/tex">x</script>.</p>
<p>Proof:</p>
<p>
<script type="math/tex; mode=display"> 
e^{-x} = 1 - x + \frac{1}{2!}x^2 - \frac{1}{3!}x^3 + \cdots
</script>
</p>
<p>So the coeﬃcient for <script type="math/tex">x^4</script> is</p>
<p>
<script type="math/tex; mode=display">
\frac{1}{4!} - \frac{1}{3!} + \frac{1}{(2!)^2} - \frac{1}{3!}
+\frac{1}{4!} = \frac{1 - 4 + 6 - 4 + 1}{24} = 0
</script>
</p>
<p>So the coeﬃcient for <script type="math/tex">x^5</script> is</p>
<p>
<script type="math/tex; mode=display"> 
\frac{1}{5!} - \frac{1}{4!1!} + \frac{1}{3!2!} - \frac{1}{2!3!}
+ \frac{1}{1!4!} - \frac{1}{0!5!}
</script>
</p>
<p>So the coeﬃcient for <script type="math/tex">x^6</script> is</p>
<p>
<script type="math/tex; mode=display"> 
\frac{1}{6!0!} - \frac{1}{5!1!} + \frac{1}{4!2!} - \frac{1}{3!3!}
+\frac{1}{2!4!} - \frac{1}{1!5!} + \frac{1}{0!6!}
</script>
</p>
<p>To summarize, the coefficient is the following when <script type="math/tex">n</script> is even</p>
<p>
<script type="math/tex; mode=display"> 
a_n = \frac{1}{n!} ( C_n^0-C_n^{1} + ... - C_n^{n-1} + C_n^n)
</script>
</p>
<p>So positive item in the above equation is to choose even number
of elements from <script type="math/tex">n</script> elements. Consider when <script type="math/tex">n</script> is odd,
then the number of ways to choose even number of elements is
the same as the ways to choose odd number of elements.</p>
<p>Now when <script type="math/tex">n</script> is even, if want to choose even number of elements,
there are 2 ways:
* Choose odd number of elements then plus the new element.
* Choose even number of elements from previous <script type="math/tex">n-1</script> elements.</p>
<p>So the above equation is still <script type="math/tex">0</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="666">6.6.6.</h3>
<p>Review the proof that <script type="math/tex">g'(0) = 0</script> for the function</p>
<p>
<script type="math/tex; mode=display"> 
g(x) =
\begin{cases}
    e^{-1/x^2} &\text{for } x \not = 0 \\
    0 &\text{for } x = 0\\
\end{cases} 
</script>
</p>
<p>introduced at the end of this section.</p>
<p>(a) Compute <script type="math/tex">g'(x)</script> for <script type="math/tex">x \not = 0</script>. Then use the definition of the derivative to find <script type="math/tex">g''(0)</script>.</p>
<p><strong>Solution</strong>: </p>
<p>
<script type="math/tex; mode=display"> 
g'(x) = e^{-1/x^2} \cdot \frac{2}{x^3}
</script>
</p>
<p>Then we have</p>
<p>
<script type="math/tex; mode=display"> 
g''(0) = \lim_{x \to 0} \frac{e^{-1/x^2} \cdot \frac{2}{x^3} - 0}
{x - 0} =\\
\lim_{x \to 0} e^{-1/x^2} \cdot \frac{2}{x^4} = \\
\lim_{x \to 0}
\frac{
1/x^4
}{
e^{1/x^2}
} =
\lim_{x \to 0} \frac{
-4/x^5
}{
e^{1/x^2} \cdot \frac{-2}{x^3}
} = \\
\lim_{x \to 0} \frac{
2/x^2
}{e^{1/x^2}} = \\
\lim_{x \to 0} \frac{
-4/x^3
}{e^{1/x^2} \cdot \frac{-2}{x^3} } = \\
\lim_{x \to 0} \frac{
2
}{e^{1/x^2}} = 0
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Compute <script type="math/tex">g''(x)</script> and <script type="math/tex">g'''(x)</script> for <script type="math/tex">x \not = 0</script>. Use these observations and invent whatever notation is needed to give a general description for the nth derivative <script type="math/tex">g^{(n)}(x)</script>
at points diﬀerent from zero.</p>
<p>
<script type="math/tex; mode=display"> 
g'(x) = e^{-1/x^2} \cdot \frac{2}{x^3} \\
g''(x) = e^{-1/x^2} \cdot \frac{2}{x^6} - e^{-1/x^2} \frac{6}{x^4} \\
g'''(x) = e^{-1/x^2} \frac{4}{x^9} - e^{-1/x^2} \frac{12}{x^7} -
e^{-1/x^2} \frac{12}{x^7} + e^{-1/x^2} \frac{24}{x^5} =\\
e^{-1/x^2} \frac{4}{x^9} - e^{-1/x^2} \frac{24}{x^7} +
e^{-1/x^2} \frac{24}{x^5}
</script>
</p>
<p>The general description is </p>
<p>
<script type="math/tex; mode=display"> 
g^{(n)}(x) = e^{-1/x^2}
(
\frac{a_n}{x^{3n}} + \frac{a_{n-1}}{x^{3n-2}} + \cdots 
+ \frac{a_1}{x^{n+2}}
)
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Construct a general argument for why <script type="math/tex">g^{(n)}(0) = 0</script> for
all <script type="math/tex">n \in \mathbf{N}</script>.</p>
<p><strong>Solution</strong>: In general</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{x \to 0} \frac{1/x^n}{e^{1/x^2}} = \\
\lim_{x \to 0} \frac{n/x^{n-2}}{2e^{1/x^2}} = \\
\lim_{x \to 0} \frac{n(n-2)/x^{n-4}}{2^2e^{1/x^2}} = \\
\cdots \\
= 0
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="667">6.6.7.</h3>
<p>Find an example of each of the following or explain why no
such function exists.</p>
<p>(a) An infinitely diﬀerentiable function <script type="math/tex">g(x)</script> on all of <script type="math/tex">\mathbf{R}</script> with a Taylor series that converges to
<script type="math/tex">g(x)</script> only for <script type="math/tex">x ∈ (−1,1)</script>.</p>
<p><strong>Solution</strong>: Consider</p>
<p>
<script type="math/tex; mode=display"> 
\frac{1}{1 + x^2} = 1 - x^2 + x^4 - x^6 + \cdots
</script>
</p>
<p>It only converges on <script type="math/tex">(-1, 1)</script>.</p>
<p>(b) An infinitely diﬀerentiable function <script type="math/tex">h(x)</script> with the same Taylor series as
<script type="math/tex">\sin(x)</script> but such that <script type="math/tex">h(x) \not = \sin(x)</script> for all <script type="math/tex">x \not = 0</script>.</p>
<p><strong>Solution</strong>: Yes, it's possible. Consider the <script type="math/tex">g(x)</script> defined
in exercise 6.6.6. And let <script type="math/tex">h(x) = \sin (x) + g(x)</script>.
Since <script type="math/tex">h^{(n)}(0) = \sin ^{(n)} (0) + g^{(n)} (0) = \sin ^{(n)} (0)</script>, but <script type="math/tex">g(x) \not = 0</script> for <script type="math/tex">x \not = 0</script>.
So <script type="math/tex">h(x) \not = \sin (x), x \not = 0</script>.</p>
<p>(c) An infinitely diﬀerentiable function <script type="math/tex">f(x)</script> on all of <script type="math/tex">\mathbf{R}</script> with a Taylor series
that converges to <script type="math/tex">f(x)</script> if and only if <script type="math/tex">x ≤ 0</script>.</p>
<p><strong>Solution</strong>: consider</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = \begin{cases}
    g(x) &\text{if } x > 0 \\
    0    &\text{if } x \leq 0 \\
\end{cases} 
</script>
</p>
<p>Its Taylor series converges to <script type="math/tex">0</script>, which equals to <script type="math/tex">f(x)</script> for
<script type="math/tex">x \leq 0</script>. But when <script type="math/tex">f(x) \not = 0</script> when <script type="math/tex">x > 0</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="668">6.6.8.</h3>
<p>Here is a weaker form of Lagrange’s Remainder Theorem whose
proof is arguably more illuminating than the one for the stronger result.</p>
<p>(a) First establish a lemma: If <script type="math/tex">g</script> and <script type="math/tex">h</script> are diﬀerentiable on <script type="math/tex">[0,x]</script> with <script type="math/tex">g(0) = h(0)</script> and <script type="math/tex">g'(h) \leq h'(x)</script> for all
<script type="math/tex">g(t) ≤ h(t)</script> for all <script type="math/tex">t \in [0, x]</script>.</p>
<p><strong>Proof</strong>:</p>
<p>Let</p>
<p>
<script type="math/tex; mode=display"> 
f(x) = h(x) - g(x)
</script>
</p>
<p>Then <script type="math/tex">f(x) - f(0) = f'(c)x</script>, since <script type="math/tex">f'(c) = h'(c) - g'(c) \geq 0</script>,
<script type="math/tex">f(x) = f(0) + f'(c)x = f'(c) x \geq 0</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Let <script type="math/tex">f</script>, <script type="math/tex">S_N</script>, and <script type="math/tex">E_N</script> be as Theorem 6.6.3,
and take 0 &lt; x &lt; R. If <script type="math/tex">\left| f^{(N+1)} (t) \right| \leq M</script>
for all <script type="math/tex">t \in [0, x]</script>, show</p>
<p>
<script type="math/tex; mode=display"> 
|E_N(x)| \leq \frac{M x^{N+1}}{(N+1)!}
</script>
</p>
<p><strong>Proof</strong>: based on (a), <script type="math/tex">E_N^{(N)}(0) = M 0 = 0</script>, and
<script type="math/tex">E_N^{(N+1)} = f^{(N+1)}(x)</script> and 
<script type="math/tex">-M \leq f^{(N+1)}(x) \leq M</script>, so</p>
<p>
<script type="math/tex; mode=display">
-Mx \leq E_N^{(N)}(x) \leq Mx \\
\text{i.e. }, |E_N^{(N)}(x)| \leq Mx
</script>
</p>
<p>Furthermore <script type="math/tex">E_N^{(N-1)}(0) = \frac{1}{2} M 0^2 = 0</script>,
So</p>
<p>
<script type="math/tex; mode=display"> 
-\frac{1}{2}M x^2 \leq E_N^{(N-1)}(x) \leq \frac{1}{2} M x^2
</script>
</p>
<p>We continue this process for <script type="math/tex">N-2, N-3, \cdots, 0</script>, we have</p>
<p>
<script type="math/tex; mode=display">
-\frac{1}{(N+1)!}M x^{N+1} \leq
E_N(x) \leq
\frac{1}{(N+1)!}M x^{N+1}
</script>
</p>
<p>So we proved (b).</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="669-cauchys-remainder-theorem">6.6.9 (Cauchy’s Remainder Theorem).</h3>
<p>Let <script type="math/tex">f</script> be diﬀerentiable
<script type="math/tex">N+1</script> times on <script type="math/tex">(−R,R)</script>. For each <script type="math/tex">a ∈ (−R,R)</script>, let <script type="math/tex">S_N(x,a)</script> be the partial sum
of the Taylor series for <script type="math/tex">f</script> centered at <script type="math/tex">a</script>; in other words, define</p>
<p>
<script type="math/tex; mode=display"> 
S_N(x, a) = \sum_{n = 0}^{N}c_{n} (x - a)^{n} \text{ where }
c_n = \frac{f^{(n)}(a)}{n!}
</script>
</p>
<p>Let <script type="math/tex">E_N(x, a) = f(x) - S_N(x, a)</script>. Now fix <script type="math/tex">x \not = 0</script> in
<script type="math/tex">(-R, R)</script> and consider <script type="math/tex">E_N(x, a)</script> as a function of <script type="math/tex">a</script>.</p>
<p>(a) Find <script type="math/tex">E_N(x, x)</script>.</p>
<p><strong>Solution</strong>: <script type="math/tex">E_N(x, x) = f(x) - S_N(x, x) = f(x) - f(x) = 0</script>.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Explain why <script type="math/tex">E_N(x,a)</script> is differentiable with respect to
<script type="math/tex">a</script>, and show</p>
<p>
<script type="math/tex; mode=display"> 
E_N(x, a)' = \frac{-f^{(N+1)}(a)}{N!}(x - a)^N
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>
<script type="math/tex; mode=display">
E_N'(x, a) = f'(x) - S_N'(x, a) = - S_N'(x, a) \\
S_N'(x, a) = c_0' + (c_1'(c-a) - c_1) + (c_2'(c-a)^2 - 2 c_2 (c -a)) + \cdots \\
= f'(a) + (f''(a)(x-a)-f'(a)) +
(\frac{1}{2!}f'''(a)(x-a) -f''(a)(x-a)) + \cdots +
(\frac{1}{N!}f^{(N+1)}(x-a)^N - \frac{1}{(N-1)!}f^{(N)}(x-a)^{N-1}) \\
= \frac{1}{N!}f^{(N+1)}(x-a)^N \\
</script>
</p>
<p>So</p>
<p>
<script type="math/tex; mode=display"> 
S_N'(x, a) = \frac{-f^{(N+1)}(a)}{N!}(x - a)^N
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(c) Show</p>
<p>
<script type="math/tex; mode=display"> 
E_N(x) = E_N(x, 0) = \frac{f^{(N+1)}(c)}{N!}(x - c)^N x
</script>
</p>
<p><strong>Proof</strong>:</p>
<p>First</p>
<p>
<script type="math/tex; mode=display"> 
E_N(x, 0) = f(x) - S_N(x, 0) =
\sum_{n = 0}^{N}c_{n} (x-0)^{n} = E_N(x)
</script>
</p>
<p>
<script type="math/tex; mode=display"> 
\frac{
    E_N(x, x) - E(x, 0)
}{x - 0}
= E'(x, c) = \frac{-f^{(N+1)}(c)}{N!}(x - c)^N
</script>
</p>
<p>So we have</p>
<p>
<script type="math/tex; mode=display"> 
E_N(x, 0) = \frac{f^{(N+1)}(c)}{N!}(x - c)^N x
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
<h3 id="6610">6.6.10.</h3>
<p>Consider <script type="math/tex">f(x) = 1/ \sqrt[]{1−x}</script>.</p>
<p>Generate the Taylor series for <script type="math/tex">f</script> centered at zero, and use Lagrange’s
Remainder Theorem to show the series converges to <script type="math/tex">f</script> on <script type="math/tex">[0,1/2]</script>. (The
case <script type="math/tex">x < 1/2</script> is more straightforward while <script type="math/tex">x = 1/2</script> requires some extra
care.) What happens when we attempt this with <script type="math/tex">x > 1/2</script>?</p>
<p>
<script type="math/tex; mode=display"> 
f'(0) = \frac{1}{2} (1 - x)^{-3/2} = \frac{1}{2} \\
f''(0) = \frac{3}{4} (1-x)^{-5/2} = \frac{3}{4} \\
\cdots \\
f^{(n)}(0) = \frac{1 \cdot 3 \cdots(2n-1)}{2^n}
(1 - x)^{-\frac{2n+1}{2}}
</script>
</p>
<p>Then the Lagrange's Remainder is</p>
<p>
<script type="math/tex; mode=display"> 
\frac{f^{(N+1)}(c)}{(N+1)!}x^{N+1} =
\frac{1 \cdot 3 \cdots (2N+1) }{2^{N+1} (N+1)!}
\frac{x^{N+1}}{(1-c)^{N+1} \sqrt[]{1-c}}
</script>
</p>
<p>Because <script type="math/tex">c < x \leq 1/2</script>, then <script type="math/tex">1 - c > 1/2 \geq x</script>, so</p>
<p>
<script type="math/tex; mode=display"> 
\frac{x}{1 - c} < 1
</script>
</p>
<p>Then the Lagrange's Remainder converges to 0.</p>
<p>When <script type="math/tex">x > 1/2</script>, we cannot establish <script type="math/tex">\frac{x}{1 - c} < 1</script>.
So Lagrange's Remainder theorem is not applicable in this case.</p>
<p>
<script type="math/tex">\square</script>
</p>
<p>(b) Use Cauchy’s Remainder Theorem proved in Exercise 6.6.9 to show the series representation for <script type="math/tex">f</script> holds on <script type="math/tex">[0,1)</script>.</p>
<p><strong>Proof</strong>: the Cauchy’s Remainder</p>
<p>
<script type="math/tex; mode=display"> 
E_N(x) = \frac{f^{(N+1)}(c)}{N!}(x - c)^N x \\
= \frac{1 \cdot 3 \cdots (2N+1) }{2^{N+1} N!}
\frac{(x-c)^{N}x}{(1-c)^{N+1} \sqrt[]{1-c}}
</script>
</p>
<p>Given any <script type="math/tex">0 < c < x < 1</script>, so <script type="math/tex">x-c < 1-c</script>, so</p>
<p>
<script type="math/tex; mode=display"> 
\lim_{N \to \infty} \frac{(2N+1)(x-c)^N}{(1-c)^{N+1}} \rightarrow 0
</script>
</p>
<p>
<script type="math/tex">\square</script>
</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../ch05ex/" class="btn btn-neutral float-left" title="Chapter 05 Exercises"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../misc/" class="btn btn-neutral float-right" title="Misc info">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../ch05ex/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../misc/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
